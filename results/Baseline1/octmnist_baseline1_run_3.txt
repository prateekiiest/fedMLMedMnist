
Experimental details:
    Model     : cnn
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 3

    Federated parameters:
   IID
    Number of users  : 2
    Local Batch size   : 10
    Local Epochs       : 5

CNNOCTMnist(
  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): Dropout2d(p=0.5, inplace=False)
  (fc1): Linear(in_features=100820, out_features=50, bias=True)
  (fc2): Linear(in_features=50, out_features=2, bias=True)
)

 | Global Training Round : 1 |

| Global Round : 0 | Local Epoch : 0 | [0/6382 (0%)]	Loss: 0.733980
| Global Round : 0 | Local Epoch : 0 | [100/6382 (2%)]	Loss: 0.717539
| Global Round : 0 | Local Epoch : 0 | [200/6382 (3%)]	Loss: 0.702561
| Global Round : 0 | Local Epoch : 0 | [300/6382 (5%)]	Loss: 0.632592
| Global Round : 0 | Local Epoch : 0 | [400/6382 (6%)]	Loss: 0.791215
| Global Round : 0 | Local Epoch : 0 | [500/6382 (8%)]	Loss: 0.684650
| Global Round : 0 | Local Epoch : 0 | [600/6382 (9%)]	Loss: 0.682671
| Global Round : 0 | Local Epoch : 0 | [700/6382 (11%)]	Loss: 0.708334
| Global Round : 0 | Local Epoch : 0 | [800/6382 (13%)]	Loss: 0.674164
| Global Round : 0 | Local Epoch : 0 | [900/6382 (14%)]	Loss: 0.694659
| Global Round : 0 | Local Epoch : 0 | [1000/6382 (16%)]	Loss: 0.691729
| Global Round : 0 | Local Epoch : 0 | [1100/6382 (17%)]	Loss: 0.655622
| Global Round : 0 | Local Epoch : 0 | [1200/6382 (19%)]	Loss: 0.705928
| Global Round : 0 | Local Epoch : 0 | [1300/6382 (20%)]	Loss: 0.696275
| Global Round : 0 | Local Epoch : 0 | [1400/6382 (22%)]	Loss: 0.801034
| Global Round : 0 | Local Epoch : 0 | [1500/6382 (23%)]	Loss: 0.757476
| Global Round : 0 | Local Epoch : 0 | [1600/6382 (25%)]	Loss: 0.653117
| Global Round : 0 | Local Epoch : 0 | [1700/6382 (27%)]	Loss: 0.699257
| Global Round : 0 | Local Epoch : 0 | [1800/6382 (28%)]	Loss: 0.699316
| Global Round : 0 | Local Epoch : 0 | [1900/6382 (30%)]	Loss: 0.766809
| Global Round : 0 | Local Epoch : 0 | [2000/6382 (31%)]	Loss: 0.800645
| Global Round : 0 | Local Epoch : 0 | [2100/6382 (33%)]	Loss: 0.653404
| Global Round : 0 | Local Epoch : 0 | [2200/6382 (34%)]	Loss: 0.689416
| Global Round : 0 | Local Epoch : 0 | [2300/6382 (36%)]	Loss: 0.728172
| Global Round : 0 | Local Epoch : 0 | [2400/6382 (38%)]	Loss: 0.804192
| Global Round : 0 | Local Epoch : 0 | [2500/6382 (39%)]	Loss: 0.821694
| Global Round : 0 | Local Epoch : 0 | [2600/6382 (41%)]	Loss: 0.763205
| Global Round : 0 | Local Epoch : 0 | [2700/6382 (42%)]	Loss: 0.673411
| Global Round : 0 | Local Epoch : 0 | [2800/6382 (44%)]	Loss: 0.653957
| Global Round : 0 | Local Epoch : 0 | [2900/6382 (45%)]	Loss: 0.650519
| Global Round : 0 | Local Epoch : 0 | [3000/6382 (47%)]	Loss: 0.710508
| Global Round : 0 | Local Epoch : 0 | [3100/6382 (49%)]	Loss: 0.737247
| Global Round : 0 | Local Epoch : 0 | [3200/6382 (50%)]	Loss: 0.678833
| Global Round : 0 | Local Epoch : 0 | [3300/6382 (52%)]	Loss: 0.641381
| Global Round : 0 | Local Epoch : 0 | [3400/6382 (53%)]	Loss: 0.731690
| Global Round : 0 | Local Epoch : 0 | [3500/6382 (55%)]	Loss: 0.645467
| Global Round : 0 | Local Epoch : 0 | [3600/6382 (56%)]	Loss: 0.637897
| Global Round : 0 | Local Epoch : 0 | [3700/6382 (58%)]	Loss: 0.657615
| Global Round : 0 | Local Epoch : 0 | [3800/6382 (59%)]	Loss: 0.666817
| Global Round : 0 | Local Epoch : 0 | [3900/6382 (61%)]	Loss: 0.857632
| Global Round : 0 | Local Epoch : 0 | [4000/6382 (63%)]	Loss: 1.018227
| Global Round : 0 | Local Epoch : 0 | [4100/6382 (64%)]	Loss: 0.622903
| Global Round : 0 | Local Epoch : 0 | [4200/6382 (66%)]	Loss: 0.698632
| Global Round : 0 | Local Epoch : 0 | [4300/6382 (67%)]	Loss: 0.577205
| Global Round : 0 | Local Epoch : 0 | [4400/6382 (69%)]	Loss: 0.647747
| Global Round : 0 | Local Epoch : 0 | [4500/6382 (70%)]	Loss: 0.709736
| Global Round : 0 | Local Epoch : 0 | [4600/6382 (72%)]	Loss: 0.646426
| Global Round : 0 | Local Epoch : 0 | [4700/6382 (74%)]	Loss: 0.553222
| Global Round : 0 | Local Epoch : 0 | [4800/6382 (75%)]	Loss: 0.644345
| Global Round : 0 | Local Epoch : 0 | [4900/6382 (77%)]	Loss: 0.693520
| Global Round : 0 | Local Epoch : 0 | [5000/6382 (78%)]	Loss: 0.672368
| Global Round : 0 | Local Epoch : 0 | [5100/6382 (80%)]	Loss: 0.681101
| Global Round : 0 | Local Epoch : 0 | [5200/6382 (81%)]	Loss: 0.688122
| Global Round : 0 | Local Epoch : 0 | [5300/6382 (83%)]	Loss: 0.542221
| Global Round : 0 | Local Epoch : 0 | [5400/6382 (85%)]	Loss: 0.792620
| Global Round : 0 | Local Epoch : 0 | [5500/6382 (86%)]	Loss: 0.672667
| Global Round : 0 | Local Epoch : 0 | [5600/6382 (88%)]	Loss: 0.632957
| Global Round : 0 | Local Epoch : 0 | [5700/6382 (89%)]	Loss: 0.628045
| Global Round : 0 | Local Epoch : 0 | [5800/6382 (91%)]	Loss: 0.614909
| Global Round : 0 | Local Epoch : 0 | [5900/6382 (92%)]	Loss: 0.637287
| Global Round : 0 | Local Epoch : 0 | [6000/6382 (94%)]	Loss: 0.588234
| Global Round : 0 | Local Epoch : 0 | [6100/6382 (95%)]	Loss: 0.763966
| Global Round : 0 | Local Epoch : 0 | [6200/6382 (97%)]	Loss: 0.673804
| Global Round : 0 | Local Epoch : 0 | [6300/6382 (99%)]	Loss: 0.676746
| Global Round : 0 | Local Epoch : 1 | [0/6382 (0%)]	Loss: 0.651532
| Global Round : 0 | Local Epoch : 1 | [100/6382 (2%)]	Loss: 0.670411
| Global Round : 0 | Local Epoch : 1 | [200/6382 (3%)]	Loss: 0.637381
| Global Round : 0 | Local Epoch : 1 | [300/6382 (5%)]	Loss: 0.791101
| Global Round : 0 | Local Epoch : 1 | [400/6382 (6%)]	Loss: 0.671721
| Global Round : 0 | Local Epoch : 1 | [500/6382 (8%)]	Loss: 0.667801
| Global Round : 0 | Local Epoch : 1 | [600/6382 (9%)]	Loss: 0.674173
| Global Round : 0 | Local Epoch : 1 | [700/6382 (11%)]	Loss: 0.614401
| Global Round : 0 | Local Epoch : 1 | [800/6382 (13%)]	Loss: 0.706511
| Global Round : 0 | Local Epoch : 1 | [900/6382 (14%)]	Loss: 0.561560
| Global Round : 0 | Local Epoch : 1 | [1000/6382 (16%)]	Loss: 0.623510
| Global Round : 0 | Local Epoch : 1 | [1100/6382 (17%)]	Loss: 0.773212
| Global Round : 0 | Local Epoch : 1 | [1200/6382 (19%)]	Loss: 0.602789
| Global Round : 0 | Local Epoch : 1 | [1300/6382 (20%)]	Loss: 0.777225
| Global Round : 0 | Local Epoch : 1 | [1400/6382 (22%)]	Loss: 0.671279
| Global Round : 0 | Local Epoch : 1 | [1500/6382 (23%)]	Loss: 0.714724
| Global Round : 0 | Local Epoch : 1 | [1600/6382 (25%)]	Loss: 0.655861
| Global Round : 0 | Local Epoch : 1 | [1700/6382 (27%)]	Loss: 0.748093
| Global Round : 0 | Local Epoch : 1 | [1800/6382 (28%)]	Loss: 0.713458
| Global Round : 0 | Local Epoch : 1 | [1900/6382 (30%)]	Loss: 0.587943
| Global Round : 0 | Local Epoch : 1 | [2000/6382 (31%)]	Loss: 0.550814
| Global Round : 0 | Local Epoch : 1 | [2100/6382 (33%)]	Loss: 0.697110
| Global Round : 0 | Local Epoch : 1 | [2200/6382 (34%)]	Loss: 0.667836
| Global Round : 0 | Local Epoch : 1 | [2300/6382 (36%)]	Loss: 0.679451
| Global Round : 0 | Local Epoch : 1 | [2400/6382 (38%)]	Loss: 0.587558
| Global Round : 0 | Local Epoch : 1 | [2500/6382 (39%)]	Loss: 0.583359
| Global Round : 0 | Local Epoch : 1 | [2600/6382 (41%)]	Loss: 0.616460
| Global Round : 0 | Local Epoch : 1 | [2700/6382 (42%)]	Loss: 0.595694
| Global Round : 0 | Local Epoch : 1 | [2800/6382 (44%)]	Loss: 0.626071
| Global Round : 0 | Local Epoch : 1 | [2900/6382 (45%)]	Loss: 0.847077
| Global Round : 0 | Local Epoch : 1 | [3000/6382 (47%)]	Loss: 0.629195
| Global Round : 0 | Local Epoch : 1 | [3100/6382 (49%)]	Loss: 0.606941
| Global Round : 0 | Local Epoch : 1 | [3200/6382 (50%)]	Loss: 0.610486
| Global Round : 0 | Local Epoch : 1 | [3300/6382 (52%)]	Loss: 0.669491
| Global Round : 0 | Local Epoch : 1 | [3400/6382 (53%)]	Loss: 0.738065
| Global Round : 0 | Local Epoch : 1 | [3500/6382 (55%)]	Loss: 0.694337
| Global Round : 0 | Local Epoch : 1 | [3600/6382 (56%)]	Loss: 0.455654
| Global Round : 0 | Local Epoch : 1 | [3700/6382 (58%)]	Loss: 0.442383
| Global Round : 0 | Local Epoch : 1 | [3800/6382 (59%)]	Loss: 0.619518
| Global Round : 0 | Local Epoch : 1 | [3900/6382 (61%)]	Loss: 0.551767
| Global Round : 0 | Local Epoch : 1 | [4000/6382 (63%)]	Loss: 0.701475
| Global Round : 0 | Local Epoch : 1 | [4100/6382 (64%)]	Loss: 0.580005
| Global Round : 0 | Local Epoch : 1 | [4200/6382 (66%)]	Loss: 0.589480
| Global Round : 0 | Local Epoch : 1 | [4300/6382 (67%)]	Loss: 0.762506
| Global Round : 0 | Local Epoch : 1 | [4400/6382 (69%)]	Loss: 0.625749
| Global Round : 0 | Local Epoch : 1 | [4500/6382 (70%)]	Loss: 0.634717
| Global Round : 0 | Local Epoch : 1 | [4600/6382 (72%)]	Loss: 0.549054
| Global Round : 0 | Local Epoch : 1 | [4700/6382 (74%)]	Loss: 0.278720
| Global Round : 0 | Local Epoch : 1 | [4800/6382 (75%)]	Loss: 0.775878
| Global Round : 0 | Local Epoch : 1 | [4900/6382 (77%)]	Loss: 0.476643
| Global Round : 0 | Local Epoch : 1 | [5000/6382 (78%)]	Loss: 0.623136
| Global Round : 0 | Local Epoch : 1 | [5100/6382 (80%)]	Loss: 0.902727
| Global Round : 0 | Local Epoch : 1 | [5200/6382 (81%)]	Loss: 0.679716
| Global Round : 0 | Local Epoch : 1 | [5300/6382 (83%)]	Loss: 0.741731
| Global Round : 0 | Local Epoch : 1 | [5400/6382 (85%)]	Loss: 0.609835
| Global Round : 0 | Local Epoch : 1 | [5500/6382 (86%)]	Loss: 0.591082
| Global Round : 0 | Local Epoch : 1 | [5600/6382 (88%)]	Loss: 0.773166
| Global Round : 0 | Local Epoch : 1 | [5700/6382 (89%)]	Loss: 0.584578
| Global Round : 0 | Local Epoch : 1 | [5800/6382 (91%)]	Loss: 0.539836
| Global Round : 0 | Local Epoch : 1 | [5900/6382 (92%)]	Loss: 0.720100
| Global Round : 0 | Local Epoch : 1 | [6000/6382 (94%)]	Loss: 0.921920
| Global Round : 0 | Local Epoch : 1 | [6100/6382 (95%)]	Loss: 0.549796
| Global Round : 0 | Local Epoch : 1 | [6200/6382 (97%)]	Loss: 0.525149
| Global Round : 0 | Local Epoch : 1 | [6300/6382 (99%)]	Loss: 0.716691
| Global Round : 0 | Local Epoch : 2 | [0/6382 (0%)]	Loss: 0.528744
| Global Round : 0 | Local Epoch : 2 | [100/6382 (2%)]	Loss: 0.573053
| Global Round : 0 | Local Epoch : 2 | [200/6382 (3%)]	Loss: 0.656983
| Global Round : 0 | Local Epoch : 2 | [300/6382 (5%)]	Loss: 0.631747
| Global Round : 0 | Local Epoch : 2 | [400/6382 (6%)]	Loss: 0.668077
| Global Round : 0 | Local Epoch : 2 | [500/6382 (8%)]	Loss: 0.537256
| Global Round : 0 | Local Epoch : 2 | [600/6382 (9%)]	Loss: 0.378066
| Global Round : 0 | Local Epoch : 2 | [700/6382 (11%)]	Loss: 0.510765
| Global Round : 0 | Local Epoch : 2 | [800/6382 (13%)]	Loss: 0.709737
| Global Round : 0 | Local Epoch : 2 | [900/6382 (14%)]	Loss: 0.682666
| Global Round : 0 | Local Epoch : 2 | [1000/6382 (16%)]	Loss: 0.539413
| Global Round : 0 | Local Epoch : 2 | [1100/6382 (17%)]	Loss: 0.510975
| Global Round : 0 | Local Epoch : 2 | [1200/6382 (19%)]	Loss: 0.443590
| Global Round : 0 | Local Epoch : 2 | [1300/6382 (20%)]	Loss: 0.562479
| Global Round : 0 | Local Epoch : 2 | [1400/6382 (22%)]	Loss: 0.410659
| Global Round : 0 | Local Epoch : 2 | [1500/6382 (23%)]	Loss: 0.862324
| Global Round : 0 | Local Epoch : 2 | [1600/6382 (25%)]	Loss: 0.521060
| Global Round : 0 | Local Epoch : 2 | [1700/6382 (27%)]	Loss: 0.449720
| Global Round : 0 | Local Epoch : 2 | [1800/6382 (28%)]	Loss: 0.562827
| Global Round : 0 | Local Epoch : 2 | [1900/6382 (30%)]	Loss: 0.599355
| Global Round : 0 | Local Epoch : 2 | [2000/6382 (31%)]	Loss: 0.420658
| Global Round : 0 | Local Epoch : 2 | [2100/6382 (33%)]	Loss: 0.498378
| Global Round : 0 | Local Epoch : 2 | [2200/6382 (34%)]	Loss: 0.732014
| Global Round : 0 | Local Epoch : 2 | [2300/6382 (36%)]	Loss: 0.628796
| Global Round : 0 | Local Epoch : 2 | [2400/6382 (38%)]	Loss: 0.709052
| Global Round : 0 | Local Epoch : 2 | [2500/6382 (39%)]	Loss: 0.486002
| Global Round : 0 | Local Epoch : 2 | [2600/6382 (41%)]	Loss: 0.519593
| Global Round : 0 | Local Epoch : 2 | [2700/6382 (42%)]	Loss: 0.598878
| Global Round : 0 | Local Epoch : 2 | [2800/6382 (44%)]	Loss: 0.573147
| Global Round : 0 | Local Epoch : 2 | [2900/6382 (45%)]	Loss: 0.818126
| Global Round : 0 | Local Epoch : 2 | [3000/6382 (47%)]	Loss: 0.504572
| Global Round : 0 | Local Epoch : 2 | [3100/6382 (49%)]	Loss: 0.397572
| Global Round : 0 | Local Epoch : 2 | [3200/6382 (50%)]	Loss: 0.875683
| Global Round : 0 | Local Epoch : 2 | [3300/6382 (52%)]	Loss: 0.505022
| Global Round : 0 | Local Epoch : 2 | [3400/6382 (53%)]	Loss: 0.610311
| Global Round : 0 | Local Epoch : 2 | [3500/6382 (55%)]	Loss: 0.330608
| Global Round : 0 | Local Epoch : 2 | [3600/6382 (56%)]	Loss: 1.024846
| Global Round : 0 | Local Epoch : 2 | [3700/6382 (58%)]	Loss: 0.732529
| Global Round : 0 | Local Epoch : 2 | [3800/6382 (59%)]	Loss: 0.769817
| Global Round : 0 | Local Epoch : 2 | [3900/6382 (61%)]	Loss: 0.442289
| Global Round : 0 | Local Epoch : 2 | [4000/6382 (63%)]	Loss: 0.648032
| Global Round : 0 | Local Epoch : 2 | [4100/6382 (64%)]	Loss: 0.603208
| Global Round : 0 | Local Epoch : 2 | [4200/6382 (66%)]	Loss: 0.566706
| Global Round : 0 | Local Epoch : 2 | [4300/6382 (67%)]	Loss: 0.519450
| Global Round : 0 | Local Epoch : 2 | [4400/6382 (69%)]	Loss: 0.717796
| Global Round : 0 | Local Epoch : 2 | [4500/6382 (70%)]	Loss: 0.348535
| Global Round : 0 | Local Epoch : 2 | [4600/6382 (72%)]	Loss: 0.520083
| Global Round : 0 | Local Epoch : 2 | [4700/6382 (74%)]	Loss: 0.591478
| Global Round : 0 | Local Epoch : 2 | [4800/6382 (75%)]	Loss: 0.552128
| Global Round : 0 | Local Epoch : 2 | [4900/6382 (77%)]	Loss: 0.916924
| Global Round : 0 | Local Epoch : 2 | [5000/6382 (78%)]	Loss: 0.503803
| Global Round : 0 | Local Epoch : 2 | [5100/6382 (80%)]	Loss: 0.783062
| Global Round : 0 | Local Epoch : 2 | [5200/6382 (81%)]	Loss: 0.422978
| Global Round : 0 | Local Epoch : 2 | [5300/6382 (83%)]	Loss: 0.775308
| Global Round : 0 | Local Epoch : 2 | [5400/6382 (85%)]	Loss: 0.588566
| Global Round : 0 | Local Epoch : 2 | [5500/6382 (86%)]	Loss: 0.485852
| Global Round : 0 | Local Epoch : 2 | [5600/6382 (88%)]	Loss: 0.412248
| Global Round : 0 | Local Epoch : 2 | [5700/6382 (89%)]	Loss: 0.404897
| Global Round : 0 | Local Epoch : 2 | [5800/6382 (91%)]	Loss: 0.559054
| Global Round : 0 | Local Epoch : 2 | [5900/6382 (92%)]	Loss: 0.666340
| Global Round : 0 | Local Epoch : 2 | [6000/6382 (94%)]	Loss: 0.468253
| Global Round : 0 | Local Epoch : 2 | [6100/6382 (95%)]	Loss: 0.833561
| Global Round : 0 | Local Epoch : 2 | [6200/6382 (97%)]	Loss: 0.415415
| Global Round : 0 | Local Epoch : 2 | [6300/6382 (99%)]	Loss: 0.358330
| Global Round : 0 | Local Epoch : 3 | [0/6382 (0%)]	Loss: 0.430383
| Global Round : 0 | Local Epoch : 3 | [100/6382 (2%)]	Loss: 0.699164
| Global Round : 0 | Local Epoch : 3 | [200/6382 (3%)]	Loss: 0.462042
| Global Round : 0 | Local Epoch : 3 | [300/6382 (5%)]	Loss: 0.587710
| Global Round : 0 | Local Epoch : 3 | [400/6382 (6%)]	Loss: 0.618331
| Global Round : 0 | Local Epoch : 3 | [500/6382 (8%)]	Loss: 0.440209
| Global Round : 0 | Local Epoch : 3 | [600/6382 (9%)]	Loss: 0.321133
| Global Round : 0 | Local Epoch : 3 | [700/6382 (11%)]	Loss: 0.629638
| Global Round : 0 | Local Epoch : 3 | [800/6382 (13%)]	Loss: 0.227213
| Global Round : 0 | Local Epoch : 3 | [900/6382 (14%)]	Loss: 0.655323
| Global Round : 0 | Local Epoch : 3 | [1000/6382 (16%)]	Loss: 0.606371
| Global Round : 0 | Local Epoch : 3 | [1100/6382 (17%)]	Loss: 1.136999
| Global Round : 0 | Local Epoch : 3 | [1200/6382 (19%)]	Loss: 0.552094
| Global Round : 0 | Local Epoch : 3 | [1300/6382 (20%)]	Loss: 0.449779
| Global Round : 0 | Local Epoch : 3 | [1400/6382 (22%)]	Loss: 0.601193
| Global Round : 0 | Local Epoch : 3 | [1500/6382 (23%)]	Loss: 0.404371
| Global Round : 0 | Local Epoch : 3 | [1600/6382 (25%)]	Loss: 0.464137
| Global Round : 0 | Local Epoch : 3 | [1700/6382 (27%)]	Loss: 0.246205
| Global Round : 0 | Local Epoch : 3 | [1800/6382 (28%)]	Loss: 0.421398
| Global Round : 0 | Local Epoch : 3 | [1900/6382 (30%)]	Loss: 0.470591
| Global Round : 0 | Local Epoch : 3 | [2000/6382 (31%)]	Loss: 0.441698
| Global Round : 0 | Local Epoch : 3 | [2100/6382 (33%)]	Loss: 0.308208
| Global Round : 0 | Local Epoch : 3 | [2200/6382 (34%)]	Loss: 0.537813
| Global Round : 0 | Local Epoch : 3 | [2300/6382 (36%)]	Loss: 0.393421
| Global Round : 0 | Local Epoch : 3 | [2400/6382 (38%)]	Loss: 0.341180
| Global Round : 0 | Local Epoch : 3 | [2500/6382 (39%)]	Loss: 0.449983
| Global Round : 0 | Local Epoch : 3 | [2600/6382 (41%)]	Loss: 0.432222
| Global Round : 0 | Local Epoch : 3 | [2700/6382 (42%)]	Loss: 0.456475
| Global Round : 0 | Local Epoch : 3 | [2800/6382 (44%)]	Loss: 0.146536
| Global Round : 0 | Local Epoch : 3 | [2900/6382 (45%)]	Loss: 0.417827
| Global Round : 0 | Local Epoch : 3 | [3000/6382 (47%)]	Loss: 0.285933
| Global Round : 0 | Local Epoch : 3 | [3100/6382 (49%)]	Loss: 0.509307
| Global Round : 0 | Local Epoch : 3 | [3200/6382 (50%)]	Loss: 0.495295
| Global Round : 0 | Local Epoch : 3 | [3300/6382 (52%)]	Loss: 0.204439
| Global Round : 0 | Local Epoch : 3 | [3400/6382 (53%)]	Loss: 0.503454
| Global Round : 0 | Local Epoch : 3 | [3500/6382 (55%)]	Loss: 0.416771
| Global Round : 0 | Local Epoch : 3 | [3600/6382 (56%)]	Loss: 0.538422
| Global Round : 0 | Local Epoch : 3 | [3700/6382 (58%)]	Loss: 0.797719
| Global Round : 0 | Local Epoch : 3 | [3800/6382 (59%)]	Loss: 0.162071
| Global Round : 0 | Local Epoch : 3 | [3900/6382 (61%)]	Loss: 0.578589
| Global Round : 0 | Local Epoch : 3 | [4000/6382 (63%)]	Loss: 0.544432
| Global Round : 0 | Local Epoch : 3 | [4100/6382 (64%)]	Loss: 0.614777
| Global Round : 0 | Local Epoch : 3 | [4200/6382 (66%)]	Loss: 0.302422
| Global Round : 0 | Local Epoch : 3 | [4300/6382 (67%)]	Loss: 0.494196
| Global Round : 0 | Local Epoch : 3 | [4400/6382 (69%)]	Loss: 0.404649
| Global Round : 0 | Local Epoch : 3 | [4500/6382 (70%)]	Loss: 0.587947
| Global Round : 0 | Local Epoch : 3 | [4600/6382 (72%)]	Loss: 0.294866
| Global Round : 0 | Local Epoch : 3 | [4700/6382 (74%)]	Loss: 0.415313
| Global Round : 0 | Local Epoch : 3 | [4800/6382 (75%)]	Loss: 0.544069
| Global Round : 0 | Local Epoch : 3 | [4900/6382 (77%)]	Loss: 0.504433
| Global Round : 0 | Local Epoch : 3 | [5000/6382 (78%)]	Loss: 0.350966
| Global Round : 0 | Local Epoch : 3 | [5100/6382 (80%)]	Loss: 0.841562
| Global Round : 0 | Local Epoch : 3 | [5200/6382 (81%)]	Loss: 0.395419
| Global Round : 0 | Local Epoch : 3 | [5300/6382 (83%)]	Loss: 0.322829
| Global Round : 0 | Local Epoch : 3 | [5400/6382 (85%)]	Loss: 0.497692
| Global Round : 0 | Local Epoch : 3 | [5500/6382 (86%)]	Loss: 0.454440
| Global Round : 0 | Local Epoch : 3 | [5600/6382 (88%)]	Loss: 0.372551
| Global Round : 0 | Local Epoch : 3 | [5700/6382 (89%)]	Loss: 0.942762
| Global Round : 0 | Local Epoch : 3 | [5800/6382 (91%)]	Loss: 1.142765
| Global Round : 0 | Local Epoch : 3 | [5900/6382 (92%)]	Loss: 0.659240
| Global Round : 0 | Local Epoch : 3 | [6000/6382 (94%)]	Loss: 0.326172
| Global Round : 0 | Local Epoch : 3 | [6100/6382 (95%)]	Loss: 0.367153
| Global Round : 0 | Local Epoch : 3 | [6200/6382 (97%)]	Loss: 0.437143
| Global Round : 0 | Local Epoch : 3 | [6300/6382 (99%)]	Loss: 0.503140
| Global Round : 0 | Local Epoch : 4 | [0/6382 (0%)]	Loss: 0.310942
| Global Round : 0 | Local Epoch : 4 | [100/6382 (2%)]	Loss: 0.363967
| Global Round : 0 | Local Epoch : 4 | [200/6382 (3%)]	Loss: 0.568641
| Global Round : 0 | Local Epoch : 4 | [300/6382 (5%)]	Loss: 0.477103
| Global Round : 0 | Local Epoch : 4 | [400/6382 (6%)]	Loss: 0.328434
| Global Round : 0 | Local Epoch : 4 | [500/6382 (8%)]	Loss: 0.410040
| Global Round : 0 | Local Epoch : 4 | [600/6382 (9%)]	Loss: 0.344184
| Global Round : 0 | Local Epoch : 4 | [700/6382 (11%)]	Loss: 0.719689
| Global Round : 0 | Local Epoch : 4 | [800/6382 (13%)]	Loss: 0.621225
| Global Round : 0 | Local Epoch : 4 | [900/6382 (14%)]	Loss: 0.376650
| Global Round : 0 | Local Epoch : 4 | [1000/6382 (16%)]	Loss: 0.483283
| Global Round : 0 | Local Epoch : 4 | [1100/6382 (17%)]	Loss: 0.496394
| Global Round : 0 | Local Epoch : 4 | [1200/6382 (19%)]	Loss: 0.489583
| Global Round : 0 | Local Epoch : 4 | [1300/6382 (20%)]	Loss: 0.262308
| Global Round : 0 | Local Epoch : 4 | [1400/6382 (22%)]	Loss: 0.366089
| Global Round : 0 | Local Epoch : 4 | [1500/6382 (23%)]	Loss: 0.482305
| Global Round : 0 | Local Epoch : 4 | [1600/6382 (25%)]	Loss: 0.652801
| Global Round : 0 | Local Epoch : 4 | [1700/6382 (27%)]	Loss: 0.200658
| Global Round : 0 | Local Epoch : 4 | [1800/6382 (28%)]	Loss: 0.550283
| Global Round : 0 | Local Epoch : 4 | [1900/6382 (30%)]	Loss: 0.406739
| Global Round : 0 | Local Epoch : 4 | [2000/6382 (31%)]	Loss: 0.548179
| Global Round : 0 | Local Epoch : 4 | [2100/6382 (33%)]	Loss: 0.485055
| Global Round : 0 | Local Epoch : 4 | [2200/6382 (34%)]	Loss: 0.244387
| Global Round : 0 | Local Epoch : 4 | [2300/6382 (36%)]	Loss: 0.658179
| Global Round : 0 | Local Epoch : 4 | [2400/6382 (38%)]	Loss: 0.347935
| Global Round : 0 | Local Epoch : 4 | [2500/6382 (39%)]	Loss: 0.528130
| Global Round : 0 | Local Epoch : 4 | [2600/6382 (41%)]	Loss: 0.625310
| Global Round : 0 | Local Epoch : 4 | [2700/6382 (42%)]	Loss: 0.665929
| Global Round : 0 | Local Epoch : 4 | [2800/6382 (44%)]	Loss: 0.536571
| Global Round : 0 | Local Epoch : 4 | [2900/6382 (45%)]	Loss: 0.514664
| Global Round : 0 | Local Epoch : 4 | [3000/6382 (47%)]	Loss: 0.264636
| Global Round : 0 | Local Epoch : 4 | [3100/6382 (49%)]	Loss: 0.387219
| Global Round : 0 | Local Epoch : 4 | [3200/6382 (50%)]	Loss: 0.306996
| Global Round : 0 | Local Epoch : 4 | [3300/6382 (52%)]	Loss: 0.505431
| Global Round : 0 | Local Epoch : 4 | [3400/6382 (53%)]	Loss: 0.436207
| Global Round : 0 | Local Epoch : 4 | [3500/6382 (55%)]	Loss: 0.382265
| Global Round : 0 | Local Epoch : 4 | [3600/6382 (56%)]	Loss: 0.448361
| Global Round : 0 | Local Epoch : 4 | [3700/6382 (58%)]	Loss: 0.527497
| Global Round : 0 | Local Epoch : 4 | [3800/6382 (59%)]	Loss: 0.298147
| Global Round : 0 | Local Epoch : 4 | [3900/6382 (61%)]	Loss: 0.202048
| Global Round : 0 | Local Epoch : 4 | [4000/6382 (63%)]	Loss: 0.308740
| Global Round : 0 | Local Epoch : 4 | [4100/6382 (64%)]	Loss: 0.373276
| Global Round : 0 | Local Epoch : 4 | [4200/6382 (66%)]	Loss: 0.396300
| Global Round : 0 | Local Epoch : 4 | [4300/6382 (67%)]	Loss: 0.399087
| Global Round : 0 | Local Epoch : 4 | [4400/6382 (69%)]	Loss: 0.515234
| Global Round : 0 | Local Epoch : 4 | [4500/6382 (70%)]	Loss: 0.372957
| Global Round : 0 | Local Epoch : 4 | [4600/6382 (72%)]	Loss: 0.155024
| Global Round : 0 | Local Epoch : 4 | [4700/6382 (74%)]	Loss: 0.363997
| Global Round : 0 | Local Epoch : 4 | [4800/6382 (75%)]	Loss: 0.534288
| Global Round : 0 | Local Epoch : 4 | [4900/6382 (77%)]	Loss: 0.450042
| Global Round : 0 | Local Epoch : 4 | [5000/6382 (78%)]	Loss: 0.535128
| Global Round : 0 | Local Epoch : 4 | [5100/6382 (80%)]	Loss: 0.636147
| Global Round : 0 | Local Epoch : 4 | [5200/6382 (81%)]	Loss: 0.252743
| Global Round : 0 | Local Epoch : 4 | [5300/6382 (83%)]	Loss: 0.308425
| Global Round : 0 | Local Epoch : 4 | [5400/6382 (85%)]	Loss: 0.251805
| Global Round : 0 | Local Epoch : 4 | [5500/6382 (86%)]	Loss: 0.645771
| Global Round : 0 | Local Epoch : 4 | [5600/6382 (88%)]	Loss: 1.807209
| Global Round : 0 | Local Epoch : 4 | [5700/6382 (89%)]	Loss: 0.594807
| Global Round : 0 | Local Epoch : 4 | [5800/6382 (91%)]	Loss: 0.197385
| Global Round : 0 | Local Epoch : 4 | [5900/6382 (92%)]	Loss: 0.473900
| Global Round : 0 | Local Epoch : 4 | [6000/6382 (94%)]	Loss: 0.645262
| Global Round : 0 | Local Epoch : 4 | [6100/6382 (95%)]	Loss: 0.301740
| Global Round : 0 | Local Epoch : 4 | [6200/6382 (97%)]	Loss: 0.743407
| Global Round : 0 | Local Epoch : 4 | [6300/6382 (99%)]	Loss: 0.986765
----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.85      0.84        40
         DME       0.84      0.82      0.83        39

    accuracy                           0.84        79
   macro avg       0.84      0.84      0.84        79
weighted avg       0.84      0.84      0.84        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.80      0.82        46
         DME       0.74      0.79      0.76        33

    accuracy                           0.80        79
   macro avg       0.79      0.80      0.79        79
weighted avg       0.80      0.80      0.80        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.83      0.88        48
         DME       0.78      0.90      0.84        31

    accuracy                           0.86        79
   macro avg       0.85      0.87      0.86        79
weighted avg       0.87      0.86      0.86        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.81      0.86        43
         DME       0.80      0.92      0.86        36

    accuracy                           0.86        79
   macro avg       0.86      0.87      0.86        79
weighted avg       0.87      0.86      0.86        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.77      0.84        48
         DME       0.72      0.90      0.80        31

    accuracy                           0.82        79
   macro avg       0.82      0.84      0.82        79
weighted avg       0.84      0.82      0.82        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.78      0.85        45
         DME       0.76      0.94      0.84        34

    accuracy                           0.85        79
   macro avg       0.85      0.86      0.85        79
weighted avg       0.87      0.85      0.85        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.84      0.83        31
         DME       0.89      0.88      0.88        48

    accuracy                           0.86        79
   macro avg       0.85      0.86      0.85        79
weighted avg       0.86      0.86      0.86        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.87      0.89        38
         DME       0.88      0.93      0.90        41

    accuracy                           0.90        79
   macro avg       0.90      0.90      0.90        79
weighted avg       0.90      0.90      0.90        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.78      0.83        45
         DME       0.75      0.88      0.81        34

    accuracy                           0.82        79
   macro avg       0.82      0.83      0.82        79
weighted avg       0.83      0.82      0.82        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.82      0.81        38
         DME       0.82      0.80      0.81        41

    accuracy                           0.81        79
   macro avg       0.81      0.81      0.81        79
weighted avg       0.81      0.81      0.81        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.80      0.80         5
         DME       0.67      0.67      0.67         3

    accuracy                           0.75         8
   macro avg       0.73      0.73      0.73         8
weighted avg       0.75      0.75      0.75         8

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.85      0.84        40
      DRUSEN       0.84      0.82      0.83        39

    accuracy                           0.84        79
   macro avg       0.84      0.84      0.84        79
weighted avg       0.84      0.84      0.84        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.80      0.82        46
      DRUSEN       0.74      0.79      0.76        33

    accuracy                           0.80        79
   macro avg       0.79      0.80      0.79        79
weighted avg       0.80      0.80      0.80        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.83      0.88        48
      DRUSEN       0.78      0.90      0.84        31

    accuracy                           0.86        79
   macro avg       0.85      0.87      0.86        79
weighted avg       0.87      0.86      0.86        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.81      0.86        43
      DRUSEN       0.80      0.92      0.86        36

    accuracy                           0.86        79
   macro avg       0.86      0.87      0.86        79
weighted avg       0.87      0.86      0.86        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.77      0.84        48
      DRUSEN       0.72      0.90      0.80        31

    accuracy                           0.82        79
   macro avg       0.82      0.84      0.82        79
weighted avg       0.84      0.82      0.82        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.78      0.85        45
      DRUSEN       0.76      0.94      0.84        34

    accuracy                           0.85        79
   macro avg       0.85      0.86      0.85        79
weighted avg       0.87      0.85      0.85        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.84      0.83        31
      DRUSEN       0.89      0.88      0.88        48

    accuracy                           0.86        79
   macro avg       0.85      0.86      0.85        79
weighted avg       0.86      0.86      0.86        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.87      0.89        38
      DRUSEN       0.88      0.93      0.90        41

    accuracy                           0.90        79
   macro avg       0.90      0.90      0.90        79
weighted avg       0.90      0.90      0.90        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.78      0.83        45
      DRUSEN       0.75      0.88      0.81        34

    accuracy                           0.82        79
   macro avg       0.82      0.83      0.82        79
weighted avg       0.83      0.82      0.82        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.82      0.81        38
      DRUSEN       0.82      0.80      0.81        41

    accuracy                           0.81        79
   macro avg       0.81      0.81      0.81        79
weighted avg       0.81      0.81      0.81        79

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.80      0.80         5
      DRUSEN       0.67      0.67      0.67         3

    accuracy                           0.75         8
   macro avg       0.73      0.73      0.73         8
weighted avg       0.75      0.75      0.75         8

----------------------

Training accuracy [0.8408521303258145]

 | Global Training Round : 2 |

| Global Round : 1 | Local Epoch : 0 | [0/6417 (0%)]	Loss: 0.727313
| Global Round : 1 | Local Epoch : 0 | [100/6417 (2%)]	Loss: 0.636063
| Global Round : 1 | Local Epoch : 0 | [200/6417 (3%)]	Loss: 0.395757
| Global Round : 1 | Local Epoch : 0 | [300/6417 (5%)]	Loss: 0.426897
| Global Round : 1 | Local Epoch : 0 | [400/6417 (6%)]	Loss: 0.376596
| Global Round : 1 | Local Epoch : 0 | [500/6417 (8%)]	Loss: 0.884111
| Global Round : 1 | Local Epoch : 0 | [600/6417 (9%)]	Loss: 0.539628
| Global Round : 1 | Local Epoch : 0 | [700/6417 (11%)]	Loss: 0.606835
| Global Round : 1 | Local Epoch : 0 | [800/6417 (12%)]	Loss: 0.458516
| Global Round : 1 | Local Epoch : 0 | [900/6417 (14%)]	Loss: 0.630032
| Global Round : 1 | Local Epoch : 0 | [1000/6417 (16%)]	Loss: 0.297597
| Global Round : 1 | Local Epoch : 0 | [1100/6417 (17%)]	Loss: 0.672727
| Global Round : 1 | Local Epoch : 0 | [1200/6417 (19%)]	Loss: 0.917751
| Global Round : 1 | Local Epoch : 0 | [1300/6417 (20%)]	Loss: 0.507254
| Global Round : 1 | Local Epoch : 0 | [1400/6417 (22%)]	Loss: 0.707409
| Global Round : 1 | Local Epoch : 0 | [1500/6417 (23%)]	Loss: 0.438285
| Global Round : 1 | Local Epoch : 0 | [1600/6417 (25%)]	Loss: 0.678734
| Global Round : 1 | Local Epoch : 0 | [1700/6417 (26%)]	Loss: 0.336621
| Global Round : 1 | Local Epoch : 0 | [1800/6417 (28%)]	Loss: 0.595396
| Global Round : 1 | Local Epoch : 0 | [1900/6417 (30%)]	Loss: 0.598140
| Global Round : 1 | Local Epoch : 0 | [2000/6417 (31%)]	Loss: 0.575724
| Global Round : 1 | Local Epoch : 0 | [2100/6417 (33%)]	Loss: 0.385179
| Global Round : 1 | Local Epoch : 0 | [2200/6417 (34%)]	Loss: 0.426322
| Global Round : 1 | Local Epoch : 0 | [2300/6417 (36%)]	Loss: 1.271001
| Global Round : 1 | Local Epoch : 0 | [2400/6417 (37%)]	Loss: 0.464530
| Global Round : 1 | Local Epoch : 0 | [2500/6417 (39%)]	Loss: 0.569175
| Global Round : 1 | Local Epoch : 0 | [2600/6417 (40%)]	Loss: 0.470205
| Global Round : 1 | Local Epoch : 0 | [2700/6417 (42%)]	Loss: 0.262362
| Global Round : 1 | Local Epoch : 0 | [2800/6417 (44%)]	Loss: 0.622163
| Global Round : 1 | Local Epoch : 0 | [2900/6417 (45%)]	Loss: 0.694615
| Global Round : 1 | Local Epoch : 0 | [3000/6417 (47%)]	Loss: 0.215704
| Global Round : 1 | Local Epoch : 0 | [3100/6417 (48%)]	Loss: 0.609008
| Global Round : 1 | Local Epoch : 0 | [3200/6417 (50%)]	Loss: 0.326384
| Global Round : 1 | Local Epoch : 0 | [3300/6417 (51%)]	Loss: 0.246707
| Global Round : 1 | Local Epoch : 0 | [3400/6417 (53%)]	Loss: 0.839033
| Global Round : 1 | Local Epoch : 0 | [3500/6417 (55%)]	Loss: 0.598205
| Global Round : 1 | Local Epoch : 0 | [3600/6417 (56%)]	Loss: 0.432647
| Global Round : 1 | Local Epoch : 0 | [3700/6417 (58%)]	Loss: 0.418260
| Global Round : 1 | Local Epoch : 0 | [3800/6417 (59%)]	Loss: 0.371151
| Global Round : 1 | Local Epoch : 0 | [3900/6417 (61%)]	Loss: 0.564617
| Global Round : 1 | Local Epoch : 0 | [4000/6417 (62%)]	Loss: 0.693136
| Global Round : 1 | Local Epoch : 0 | [4100/6417 (64%)]	Loss: 0.673893
| Global Round : 1 | Local Epoch : 0 | [4200/6417 (65%)]	Loss: 0.597555
| Global Round : 1 | Local Epoch : 0 | [4300/6417 (67%)]	Loss: 0.314816
| Global Round : 1 | Local Epoch : 0 | [4400/6417 (69%)]	Loss: 0.447181
| Global Round : 1 | Local Epoch : 0 | [4500/6417 (70%)]	Loss: 0.420953
| Global Round : 1 | Local Epoch : 0 | [4600/6417 (72%)]	Loss: 0.354677
| Global Round : 1 | Local Epoch : 0 | [4700/6417 (73%)]	Loss: 0.268305
| Global Round : 1 | Local Epoch : 0 | [4800/6417 (75%)]	Loss: 0.412497
| Global Round : 1 | Local Epoch : 0 | [4900/6417 (76%)]	Loss: 0.677217
| Global Round : 1 | Local Epoch : 0 | [5000/6417 (78%)]	Loss: 0.456319
| Global Round : 1 | Local Epoch : 0 | [5100/6417 (79%)]	Loss: 0.466992
| Global Round : 1 | Local Epoch : 0 | [5200/6417 (81%)]	Loss: 0.398570
| Global Round : 1 | Local Epoch : 0 | [5300/6417 (83%)]	Loss: 0.195792
| Global Round : 1 | Local Epoch : 0 | [5400/6417 (84%)]	Loss: 0.076333
| Global Round : 1 | Local Epoch : 0 | [5500/6417 (86%)]	Loss: 0.757864
| Global Round : 1 | Local Epoch : 0 | [5600/6417 (87%)]	Loss: 0.371501
| Global Round : 1 | Local Epoch : 0 | [5700/6417 (89%)]	Loss: 0.887103
| Global Round : 1 | Local Epoch : 0 | [5800/6417 (90%)]	Loss: 0.396872
| Global Round : 1 | Local Epoch : 0 | [5900/6417 (92%)]	Loss: 0.412305
| Global Round : 1 | Local Epoch : 0 | [6000/6417 (93%)]	Loss: 0.426424
| Global Round : 1 | Local Epoch : 0 | [6100/6417 (95%)]	Loss: 0.156053
| Global Round : 1 | Local Epoch : 0 | [6200/6417 (97%)]	Loss: 0.746428
| Global Round : 1 | Local Epoch : 0 | [6300/6417 (98%)]	Loss: 0.308304
| Global Round : 1 | Local Epoch : 0 | [6400/6417 (100%)]	Loss: 1.212098
| Global Round : 1 | Local Epoch : 1 | [0/6417 (0%)]	Loss: 0.299033
| Global Round : 1 | Local Epoch : 1 | [100/6417 (2%)]	Loss: 0.626456
| Global Round : 1 | Local Epoch : 1 | [200/6417 (3%)]	Loss: 0.345758
| Global Round : 1 | Local Epoch : 1 | [300/6417 (5%)]	Loss: 0.572533
| Global Round : 1 | Local Epoch : 1 | [400/6417 (6%)]	Loss: 0.510968
| Global Round : 1 | Local Epoch : 1 | [500/6417 (8%)]	Loss: 0.410079
| Global Round : 1 | Local Epoch : 1 | [600/6417 (9%)]	Loss: 0.155038
| Global Round : 1 | Local Epoch : 1 | [700/6417 (11%)]	Loss: 0.467074
| Global Round : 1 | Local Epoch : 1 | [800/6417 (12%)]	Loss: 0.116210
| Global Round : 1 | Local Epoch : 1 | [900/6417 (14%)]	Loss: 0.529368
| Global Round : 1 | Local Epoch : 1 | [1000/6417 (16%)]	Loss: 0.400754
| Global Round : 1 | Local Epoch : 1 | [1100/6417 (17%)]	Loss: 0.511760
| Global Round : 1 | Local Epoch : 1 | [1200/6417 (19%)]	Loss: 0.259248
| Global Round : 1 | Local Epoch : 1 | [1300/6417 (20%)]	Loss: 0.561887
| Global Round : 1 | Local Epoch : 1 | [1400/6417 (22%)]	Loss: 0.474953
| Global Round : 1 | Local Epoch : 1 | [1500/6417 (23%)]	Loss: 0.399057
| Global Round : 1 | Local Epoch : 1 | [1600/6417 (25%)]	Loss: 0.274589
| Global Round : 1 | Local Epoch : 1 | [1700/6417 (26%)]	Loss: 0.440311
| Global Round : 1 | Local Epoch : 1 | [1800/6417 (28%)]	Loss: 0.363910
| Global Round : 1 | Local Epoch : 1 | [1900/6417 (30%)]	Loss: 0.423692
| Global Round : 1 | Local Epoch : 1 | [2000/6417 (31%)]	Loss: 0.499569
| Global Round : 1 | Local Epoch : 1 | [2100/6417 (33%)]	Loss: 0.189478
| Global Round : 1 | Local Epoch : 1 | [2200/6417 (34%)]	Loss: 0.370775
| Global Round : 1 | Local Epoch : 1 | [2300/6417 (36%)]	Loss: 0.589672
| Global Round : 1 | Local Epoch : 1 | [2400/6417 (37%)]	Loss: 0.413480
| Global Round : 1 | Local Epoch : 1 | [2500/6417 (39%)]	Loss: 0.273776
| Global Round : 1 | Local Epoch : 1 | [2600/6417 (40%)]	Loss: 0.367752
| Global Round : 1 | Local Epoch : 1 | [2700/6417 (42%)]	Loss: 0.456951
| Global Round : 1 | Local Epoch : 1 | [2800/6417 (44%)]	Loss: 0.305325
| Global Round : 1 | Local Epoch : 1 | [2900/6417 (45%)]	Loss: 0.428361
| Global Round : 1 | Local Epoch : 1 | [3000/6417 (47%)]	Loss: 0.493044
| Global Round : 1 | Local Epoch : 1 | [3100/6417 (48%)]	Loss: 0.408642
| Global Round : 1 | Local Epoch : 1 | [3200/6417 (50%)]	Loss: 0.522407
| Global Round : 1 | Local Epoch : 1 | [3300/6417 (51%)]	Loss: 0.238481
| Global Round : 1 | Local Epoch : 1 | [3400/6417 (53%)]	Loss: 0.253569
| Global Round : 1 | Local Epoch : 1 | [3500/6417 (55%)]	Loss: 0.412836
| Global Round : 1 | Local Epoch : 1 | [3600/6417 (56%)]	Loss: 0.423934
| Global Round : 1 | Local Epoch : 1 | [3700/6417 (58%)]	Loss: 0.316293
| Global Round : 1 | Local Epoch : 1 | [3800/6417 (59%)]	Loss: 0.504599
| Global Round : 1 | Local Epoch : 1 | [3900/6417 (61%)]	Loss: 0.332767
| Global Round : 1 | Local Epoch : 1 | [4000/6417 (62%)]	Loss: 0.240406
| Global Round : 1 | Local Epoch : 1 | [4100/6417 (64%)]	Loss: 0.334930
| Global Round : 1 | Local Epoch : 1 | [4200/6417 (65%)]	Loss: 0.485817
| Global Round : 1 | Local Epoch : 1 | [4300/6417 (67%)]	Loss: 0.276884
| Global Round : 1 | Local Epoch : 1 | [4400/6417 (69%)]	Loss: 0.159003
| Global Round : 1 | Local Epoch : 1 | [4500/6417 (70%)]	Loss: 0.362981
| Global Round : 1 | Local Epoch : 1 | [4600/6417 (72%)]	Loss: 0.550644
| Global Round : 1 | Local Epoch : 1 | [4700/6417 (73%)]	Loss: 0.226629
| Global Round : 1 | Local Epoch : 1 | [4800/6417 (75%)]	Loss: 0.284191
| Global Round : 1 | Local Epoch : 1 | [4900/6417 (76%)]	Loss: 0.431106
| Global Round : 1 | Local Epoch : 1 | [5000/6417 (78%)]	Loss: 0.400296
| Global Round : 1 | Local Epoch : 1 | [5100/6417 (79%)]	Loss: 0.381489
| Global Round : 1 | Local Epoch : 1 | [5200/6417 (81%)]	Loss: 0.360255
| Global Round : 1 | Local Epoch : 1 | [5300/6417 (83%)]	Loss: 0.339846
| Global Round : 1 | Local Epoch : 1 | [5400/6417 (84%)]	Loss: 0.214692
| Global Round : 1 | Local Epoch : 1 | [5500/6417 (86%)]	Loss: 0.091321
| Global Round : 1 | Local Epoch : 1 | [5600/6417 (87%)]	Loss: 0.459854
| Global Round : 1 | Local Epoch : 1 | [5700/6417 (89%)]	Loss: 0.207706
| Global Round : 1 | Local Epoch : 1 | [5800/6417 (90%)]	Loss: 0.463518
| Global Round : 1 | Local Epoch : 1 | [5900/6417 (92%)]	Loss: 0.404780
| Global Round : 1 | Local Epoch : 1 | [6000/6417 (93%)]	Loss: 0.246681
| Global Round : 1 | Local Epoch : 1 | [6100/6417 (95%)]	Loss: 0.345598
| Global Round : 1 | Local Epoch : 1 | [6200/6417 (97%)]	Loss: 0.618797
| Global Round : 1 | Local Epoch : 1 | [6300/6417 (98%)]	Loss: 0.900778
| Global Round : 1 | Local Epoch : 1 | [6400/6417 (100%)]	Loss: 0.534970
| Global Round : 1 | Local Epoch : 2 | [0/6417 (0%)]	Loss: 0.276976
| Global Round : 1 | Local Epoch : 2 | [100/6417 (2%)]	Loss: 0.110944
| Global Round : 1 | Local Epoch : 2 | [200/6417 (3%)]	Loss: 0.560653
| Global Round : 1 | Local Epoch : 2 | [300/6417 (5%)]	Loss: 0.461932
| Global Round : 1 | Local Epoch : 2 | [400/6417 (6%)]	Loss: 0.200030
| Global Round : 1 | Local Epoch : 2 | [500/6417 (8%)]	Loss: 0.360198
| Global Round : 1 | Local Epoch : 2 | [600/6417 (9%)]	Loss: 0.299055
| Global Round : 1 | Local Epoch : 2 | [700/6417 (11%)]	Loss: 0.356621
| Global Round : 1 | Local Epoch : 2 | [800/6417 (12%)]	Loss: 0.922976
| Global Round : 1 | Local Epoch : 2 | [900/6417 (14%)]	Loss: 0.273491
| Global Round : 1 | Local Epoch : 2 | [1000/6417 (16%)]	Loss: 0.166545
| Global Round : 1 | Local Epoch : 2 | [1100/6417 (17%)]	Loss: 0.120840
| Global Round : 1 | Local Epoch : 2 | [1200/6417 (19%)]	Loss: 0.287490
| Global Round : 1 | Local Epoch : 2 | [1300/6417 (20%)]	Loss: 0.184648
| Global Round : 1 | Local Epoch : 2 | [1400/6417 (22%)]	Loss: 0.482065
| Global Round : 1 | Local Epoch : 2 | [1500/6417 (23%)]	Loss: 0.368774
| Global Round : 1 | Local Epoch : 2 | [1600/6417 (25%)]	Loss: 0.369930
| Global Round : 1 | Local Epoch : 2 | [1700/6417 (26%)]	Loss: 0.291135
| Global Round : 1 | Local Epoch : 2 | [1800/6417 (28%)]	Loss: 0.232212
| Global Round : 1 | Local Epoch : 2 | [1900/6417 (30%)]	Loss: 0.544747
| Global Round : 1 | Local Epoch : 2 | [2000/6417 (31%)]	Loss: 0.151798
| Global Round : 1 | Local Epoch : 2 | [2100/6417 (33%)]	Loss: 0.174639
| Global Round : 1 | Local Epoch : 2 | [2200/6417 (34%)]	Loss: 0.438975
| Global Round : 1 | Local Epoch : 2 | [2300/6417 (36%)]	Loss: 0.554301
| Global Round : 1 | Local Epoch : 2 | [2400/6417 (37%)]	Loss: 0.325226
| Global Round : 1 | Local Epoch : 2 | [2500/6417 (39%)]	Loss: 0.298825
| Global Round : 1 | Local Epoch : 2 | [2600/6417 (40%)]	Loss: 0.457144
| Global Round : 1 | Local Epoch : 2 | [2700/6417 (42%)]	Loss: 0.584592
| Global Round : 1 | Local Epoch : 2 | [2800/6417 (44%)]	Loss: 0.267887
| Global Round : 1 | Local Epoch : 2 | [2900/6417 (45%)]	Loss: 0.261125
| Global Round : 1 | Local Epoch : 2 | [3000/6417 (47%)]	Loss: 0.187963
| Global Round : 1 | Local Epoch : 2 | [3100/6417 (48%)]	Loss: 0.181088
| Global Round : 1 | Local Epoch : 2 | [3200/6417 (50%)]	Loss: 0.278564
| Global Round : 1 | Local Epoch : 2 | [3300/6417 (51%)]	Loss: 0.241509
| Global Round : 1 | Local Epoch : 2 | [3400/6417 (53%)]	Loss: 0.226305
| Global Round : 1 | Local Epoch : 2 | [3500/6417 (55%)]	Loss: 0.356220
| Global Round : 1 | Local Epoch : 2 | [3600/6417 (56%)]	Loss: 0.219640
| Global Round : 1 | Local Epoch : 2 | [3700/6417 (58%)]	Loss: 0.230596
| Global Round : 1 | Local Epoch : 2 | [3800/6417 (59%)]	Loss: 0.456234
| Global Round : 1 | Local Epoch : 2 | [3900/6417 (61%)]	Loss: 0.741882
| Global Round : 1 | Local Epoch : 2 | [4000/6417 (62%)]	Loss: 0.309406
| Global Round : 1 | Local Epoch : 2 | [4100/6417 (64%)]	Loss: 0.223967
| Global Round : 1 | Local Epoch : 2 | [4200/6417 (65%)]	Loss: 0.220238
| Global Round : 1 | Local Epoch : 2 | [4300/6417 (67%)]	Loss: 0.480265
| Global Round : 1 | Local Epoch : 2 | [4400/6417 (69%)]	Loss: 0.274668
| Global Round : 1 | Local Epoch : 2 | [4500/6417 (70%)]	Loss: 0.512884
| Global Round : 1 | Local Epoch : 2 | [4600/6417 (72%)]	Loss: 0.402093
| Global Round : 1 | Local Epoch : 2 | [4700/6417 (73%)]	Loss: 0.293043
| Global Round : 1 | Local Epoch : 2 | [4800/6417 (75%)]	Loss: 0.140721
| Global Round : 1 | Local Epoch : 2 | [4900/6417 (76%)]	Loss: 0.771203
| Global Round : 1 | Local Epoch : 2 | [5000/6417 (78%)]	Loss: 0.233780
| Global Round : 1 | Local Epoch : 2 | [5100/6417 (79%)]	Loss: 0.611496
| Global Round : 1 | Local Epoch : 2 | [5200/6417 (81%)]	Loss: 0.317401
| Global Round : 1 | Local Epoch : 2 | [5300/6417 (83%)]	Loss: 0.171119
| Global Round : 1 | Local Epoch : 2 | [5400/6417 (84%)]	Loss: 0.343464
| Global Round : 1 | Local Epoch : 2 | [5500/6417 (86%)]	Loss: 0.307770
| Global Round : 1 | Local Epoch : 2 | [5600/6417 (87%)]	Loss: 0.365402
| Global Round : 1 | Local Epoch : 2 | [5700/6417 (89%)]	Loss: 0.233012
| Global Round : 1 | Local Epoch : 2 | [5800/6417 (90%)]	Loss: 0.298162
| Global Round : 1 | Local Epoch : 2 | [5900/6417 (92%)]	Loss: 0.215708
| Global Round : 1 | Local Epoch : 2 | [6000/6417 (93%)]	Loss: 0.310866
| Global Round : 1 | Local Epoch : 2 | [6100/6417 (95%)]	Loss: 0.182259
| Global Round : 1 | Local Epoch : 2 | [6200/6417 (97%)]	Loss: 0.188007
| Global Round : 1 | Local Epoch : 2 | [6300/6417 (98%)]	Loss: 0.120622
| Global Round : 1 | Local Epoch : 2 | [6400/6417 (100%)]	Loss: 0.172576
| Global Round : 1 | Local Epoch : 3 | [0/6417 (0%)]	Loss: 0.136322
| Global Round : 1 | Local Epoch : 3 | [100/6417 (2%)]	Loss: 0.442472
| Global Round : 1 | Local Epoch : 3 | [200/6417 (3%)]	Loss: 0.499108
| Global Round : 1 | Local Epoch : 3 | [300/6417 (5%)]	Loss: 0.405241
| Global Round : 1 | Local Epoch : 3 | [400/6417 (6%)]	Loss: 0.234486
| Global Round : 1 | Local Epoch : 3 | [500/6417 (8%)]	Loss: 0.104442
| Global Round : 1 | Local Epoch : 3 | [600/6417 (9%)]	Loss: 0.135887
| Global Round : 1 | Local Epoch : 3 | [700/6417 (11%)]	Loss: 0.170065
| Global Round : 1 | Local Epoch : 3 | [800/6417 (12%)]	Loss: 0.081509
| Global Round : 1 | Local Epoch : 3 | [900/6417 (14%)]	Loss: 0.538466
| Global Round : 1 | Local Epoch : 3 | [1000/6417 (16%)]	Loss: 0.453571
| Global Round : 1 | Local Epoch : 3 | [1100/6417 (17%)]	Loss: 0.220562
| Global Round : 1 | Local Epoch : 3 | [1200/6417 (19%)]	Loss: 0.184615
| Global Round : 1 | Local Epoch : 3 | [1300/6417 (20%)]	Loss: 0.809926
| Global Round : 1 | Local Epoch : 3 | [1400/6417 (22%)]	Loss: 0.278118
| Global Round : 1 | Local Epoch : 3 | [1500/6417 (23%)]	Loss: 0.592474
| Global Round : 1 | Local Epoch : 3 | [1600/6417 (25%)]	Loss: 0.393564
| Global Round : 1 | Local Epoch : 3 | [1700/6417 (26%)]	Loss: 0.228928
| Global Round : 1 | Local Epoch : 3 | [1800/6417 (28%)]	Loss: 0.224137
| Global Round : 1 | Local Epoch : 3 | [1900/6417 (30%)]	Loss: 0.394606
| Global Round : 1 | Local Epoch : 3 | [2000/6417 (31%)]	Loss: 0.339441
| Global Round : 1 | Local Epoch : 3 | [2100/6417 (33%)]	Loss: 0.302629
| Global Round : 1 | Local Epoch : 3 | [2200/6417 (34%)]	Loss: 0.259543
| Global Round : 1 | Local Epoch : 3 | [2300/6417 (36%)]	Loss: 0.300339
| Global Round : 1 | Local Epoch : 3 | [2400/6417 (37%)]	Loss: 0.338663
| Global Round : 1 | Local Epoch : 3 | [2500/6417 (39%)]	Loss: 0.306232
| Global Round : 1 | Local Epoch : 3 | [2600/6417 (40%)]	Loss: 0.598976
| Global Round : 1 | Local Epoch : 3 | [2700/6417 (42%)]	Loss: 0.362285
| Global Round : 1 | Local Epoch : 3 | [2800/6417 (44%)]	Loss: 0.424227
| Global Round : 1 | Local Epoch : 3 | [2900/6417 (45%)]	Loss: 0.295766
| Global Round : 1 | Local Epoch : 3 | [3000/6417 (47%)]	Loss: 0.204768
| Global Round : 1 | Local Epoch : 3 | [3100/6417 (48%)]	Loss: 0.402079
| Global Round : 1 | Local Epoch : 3 | [3200/6417 (50%)]	Loss: 0.352174
| Global Round : 1 | Local Epoch : 3 | [3300/6417 (51%)]	Loss: 0.083646
| Global Round : 1 | Local Epoch : 3 | [3400/6417 (53%)]	Loss: 0.261762
| Global Round : 1 | Local Epoch : 3 | [3500/6417 (55%)]	Loss: 0.431182
| Global Round : 1 | Local Epoch : 3 | [3600/6417 (56%)]	Loss: 0.179327
| Global Round : 1 | Local Epoch : 3 | [3700/6417 (58%)]	Loss: 0.296221
| Global Round : 1 | Local Epoch : 3 | [3800/6417 (59%)]	Loss: 0.162373
| Global Round : 1 | Local Epoch : 3 | [3900/6417 (61%)]	Loss: 0.220187
| Global Round : 1 | Local Epoch : 3 | [4000/6417 (62%)]	Loss: 0.333118
| Global Round : 1 | Local Epoch : 3 | [4100/6417 (64%)]	Loss: 0.250838
| Global Round : 1 | Local Epoch : 3 | [4200/6417 (65%)]	Loss: 0.060946
| Global Round : 1 | Local Epoch : 3 | [4300/6417 (67%)]	Loss: 0.295755
| Global Round : 1 | Local Epoch : 3 | [4400/6417 (69%)]	Loss: 0.176808
| Global Round : 1 | Local Epoch : 3 | [4500/6417 (70%)]	Loss: 0.100793
| Global Round : 1 | Local Epoch : 3 | [4600/6417 (72%)]	Loss: 0.607269
| Global Round : 1 | Local Epoch : 3 | [4700/6417 (73%)]	Loss: 0.344517
| Global Round : 1 | Local Epoch : 3 | [4800/6417 (75%)]	Loss: 0.129572
| Global Round : 1 | Local Epoch : 3 | [4900/6417 (76%)]	Loss: 0.499979
| Global Round : 1 | Local Epoch : 3 | [5000/6417 (78%)]	Loss: 0.417902
| Global Round : 1 | Local Epoch : 3 | [5100/6417 (79%)]	Loss: 0.277069
| Global Round : 1 | Local Epoch : 3 | [5200/6417 (81%)]	Loss: 0.143597
| Global Round : 1 | Local Epoch : 3 | [5300/6417 (83%)]	Loss: 0.120216
| Global Round : 1 | Local Epoch : 3 | [5400/6417 (84%)]	Loss: 0.310676
| Global Round : 1 | Local Epoch : 3 | [5500/6417 (86%)]	Loss: 0.077119
| Global Round : 1 | Local Epoch : 3 | [5600/6417 (87%)]	Loss: 0.283745
| Global Round : 1 | Local Epoch : 3 | [5700/6417 (89%)]	Loss: 0.434829
| Global Round : 1 | Local Epoch : 3 | [5800/6417 (90%)]	Loss: 0.341644
| Global Round : 1 | Local Epoch : 3 | [5900/6417 (92%)]	Loss: 0.310383
| Global Round : 1 | Local Epoch : 3 | [6000/6417 (93%)]	Loss: 0.274063
| Global Round : 1 | Local Epoch : 3 | [6100/6417 (95%)]	Loss: 0.215385
| Global Round : 1 | Local Epoch : 3 | [6200/6417 (97%)]	Loss: 0.301019
| Global Round : 1 | Local Epoch : 3 | [6300/6417 (98%)]	Loss: 0.176596
| Global Round : 1 | Local Epoch : 3 | [6400/6417 (100%)]	Loss: 0.326025
| Global Round : 1 | Local Epoch : 4 | [0/6417 (0%)]	Loss: 0.178868
| Global Round : 1 | Local Epoch : 4 | [100/6417 (2%)]	Loss: 0.158519
| Global Round : 1 | Local Epoch : 4 | [200/6417 (3%)]	Loss: 0.424464
| Global Round : 1 | Local Epoch : 4 | [300/6417 (5%)]	Loss: 0.286890
| Global Round : 1 | Local Epoch : 4 | [400/6417 (6%)]	Loss: 0.217832
| Global Round : 1 | Local Epoch : 4 | [500/6417 (8%)]	Loss: 0.183800
| Global Round : 1 | Local Epoch : 4 | [600/6417 (9%)]	Loss: 0.093709
| Global Round : 1 | Local Epoch : 4 | [700/6417 (11%)]	Loss: 0.667997
| Global Round : 1 | Local Epoch : 4 | [800/6417 (12%)]	Loss: 0.229529
| Global Round : 1 | Local Epoch : 4 | [900/6417 (14%)]	Loss: 0.090947
| Global Round : 1 | Local Epoch : 4 | [1000/6417 (16%)]	Loss: 0.055755
| Global Round : 1 | Local Epoch : 4 | [1100/6417 (17%)]	Loss: 0.076805
| Global Round : 1 | Local Epoch : 4 | [1200/6417 (19%)]	Loss: 0.376733
| Global Round : 1 | Local Epoch : 4 | [1300/6417 (20%)]	Loss: 0.056918
| Global Round : 1 | Local Epoch : 4 | [1400/6417 (22%)]	Loss: 0.318151
| Global Round : 1 | Local Epoch : 4 | [1500/6417 (23%)]	Loss: 0.122193
| Global Round : 1 | Local Epoch : 4 | [1600/6417 (25%)]	Loss: 0.247186
| Global Round : 1 | Local Epoch : 4 | [1700/6417 (26%)]	Loss: 0.348120
| Global Round : 1 | Local Epoch : 4 | [1800/6417 (28%)]	Loss: 0.610422
| Global Round : 1 | Local Epoch : 4 | [1900/6417 (30%)]	Loss: 0.233697
| Global Round : 1 | Local Epoch : 4 | [2000/6417 (31%)]	Loss: 0.462893
| Global Round : 1 | Local Epoch : 4 | [2100/6417 (33%)]	Loss: 0.242349
| Global Round : 1 | Local Epoch : 4 | [2200/6417 (34%)]	Loss: 0.956126
| Global Round : 1 | Local Epoch : 4 | [2300/6417 (36%)]	Loss: 0.189474
| Global Round : 1 | Local Epoch : 4 | [2400/6417 (37%)]	Loss: 0.363858
| Global Round : 1 | Local Epoch : 4 | [2500/6417 (39%)]	Loss: 0.189530
| Global Round : 1 | Local Epoch : 4 | [2600/6417 (40%)]	Loss: 0.284529
| Global Round : 1 | Local Epoch : 4 | [2700/6417 (42%)]	Loss: 0.163530
| Global Round : 1 | Local Epoch : 4 | [2800/6417 (44%)]	Loss: 0.388502
| Global Round : 1 | Local Epoch : 4 | [2900/6417 (45%)]	Loss: 0.251974
| Global Round : 1 | Local Epoch : 4 | [3000/6417 (47%)]	Loss: 0.299213
| Global Round : 1 | Local Epoch : 4 | [3100/6417 (48%)]	Loss: 0.229905
| Global Round : 1 | Local Epoch : 4 | [3200/6417 (50%)]	Loss: 0.273745
| Global Round : 1 | Local Epoch : 4 | [3300/6417 (51%)]	Loss: 0.727640
| Global Round : 1 | Local Epoch : 4 | [3400/6417 (53%)]	Loss: 0.273526
| Global Round : 1 | Local Epoch : 4 | [3500/6417 (55%)]	Loss: 0.638197
| Global Round : 1 | Local Epoch : 4 | [3600/6417 (56%)]	Loss: 0.046448
| Global Round : 1 | Local Epoch : 4 | [3700/6417 (58%)]	Loss: 0.204120
| Global Round : 1 | Local Epoch : 4 | [3800/6417 (59%)]	Loss: 0.344858
| Global Round : 1 | Local Epoch : 4 | [3900/6417 (61%)]	Loss: 0.114533
| Global Round : 1 | Local Epoch : 4 | [4000/6417 (62%)]	Loss: 0.301737
| Global Round : 1 | Local Epoch : 4 | [4100/6417 (64%)]	Loss: 0.561462
| Global Round : 1 | Local Epoch : 4 | [4200/6417 (65%)]	Loss: 0.086296
| Global Round : 1 | Local Epoch : 4 | [4300/6417 (67%)]	Loss: 0.125646
| Global Round : 1 | Local Epoch : 4 | [4400/6417 (69%)]	Loss: 0.403760
| Global Round : 1 | Local Epoch : 4 | [4500/6417 (70%)]	Loss: 0.070627
| Global Round : 1 | Local Epoch : 4 | [4600/6417 (72%)]	Loss: 0.306664
| Global Round : 1 | Local Epoch : 4 | [4700/6417 (73%)]	Loss: 0.259759
| Global Round : 1 | Local Epoch : 4 | [4800/6417 (75%)]	Loss: 0.247158
| Global Round : 1 | Local Epoch : 4 | [4900/6417 (76%)]	Loss: 0.202755
| Global Round : 1 | Local Epoch : 4 | [5000/6417 (78%)]	Loss: 0.319634
| Global Round : 1 | Local Epoch : 4 | [5100/6417 (79%)]	Loss: 0.142073
| Global Round : 1 | Local Epoch : 4 | [5200/6417 (81%)]	Loss: 0.200832
| Global Round : 1 | Local Epoch : 4 | [5300/6417 (83%)]	Loss: 0.161437
| Global Round : 1 | Local Epoch : 4 | [5400/6417 (84%)]	Loss: 0.126908
| Global Round : 1 | Local Epoch : 4 | [5500/6417 (86%)]	Loss: 0.252302
| Global Round : 1 | Local Epoch : 4 | [5600/6417 (87%)]	Loss: 0.255071
| Global Round : 1 | Local Epoch : 4 | [5700/6417 (89%)]	Loss: 0.091601
| Global Round : 1 | Local Epoch : 4 | [5800/6417 (90%)]	Loss: 0.336306
| Global Round : 1 | Local Epoch : 4 | [5900/6417 (92%)]	Loss: 0.042557
| Global Round : 1 | Local Epoch : 4 | [6000/6417 (93%)]	Loss: 0.226064
| Global Round : 1 | Local Epoch : 4 | [6100/6417 (95%)]	Loss: 0.147085
| Global Round : 1 | Local Epoch : 4 | [6200/6417 (97%)]	Loss: 0.286527
| Global Round : 1 | Local Epoch : 4 | [6300/6417 (98%)]	Loss: 0.334482
| Global Round : 1 | Local Epoch : 4 | [6400/6417 (100%)]	Loss: 0.317585
----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.98      0.91        42
         DME       0.97      0.82      0.89        38

    accuracy                           0.90        80
   macro avg       0.91      0.90      0.90        80
weighted avg       0.91      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.89      0.94        44
         DME       0.88      1.00      0.94        36

    accuracy                           0.94        80
   macro avg       0.94      0.94      0.94        80
weighted avg       0.95      0.94      0.94        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.97      0.93        39
         DME       0.97      0.88      0.92        41

    accuracy                           0.93        80
   macro avg       0.93      0.93      0.92        80
weighted avg       0.93      0.93      0.92        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.89      0.90        36
         DME       0.91      0.93      0.92        44

    accuracy                           0.91        80
   macro avg       0.91      0.91      0.91        80
weighted avg       0.91      0.91      0.91        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.86      0.87        44
         DME       0.84      0.86      0.85        36

    accuracy                           0.86        80
   macro avg       0.86      0.86      0.86        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.92      0.89        36
         DME       0.93      0.89      0.91        44

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.88      0.85        34
         DME       0.91      0.85      0.88        46

    accuracy                           0.86        80
   macro avg       0.86      0.87      0.86        80
weighted avg       0.87      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.93      0.90        40
         DME       0.92      0.88      0.90        40

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.80      0.86        46
         DME       0.78      0.91      0.84        34

    accuracy                           0.85        80
   macro avg       0.85      0.86      0.85        80
weighted avg       0.86      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.86      0.84        43
         DME       0.83      0.78      0.81        37

    accuracy                           0.82        80
   macro avg       0.83      0.82      0.82        80
weighted avg       0.83      0.82      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         2
         DME       1.00      1.00      1.00         1

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.98      0.91        42
      DRUSEN       0.97      0.82      0.89        38

    accuracy                           0.90        80
   macro avg       0.91      0.90      0.90        80
weighted avg       0.91      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.89      0.94        44
      DRUSEN       0.88      1.00      0.94        36

    accuracy                           0.94        80
   macro avg       0.94      0.94      0.94        80
weighted avg       0.95      0.94      0.94        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.97      0.93        39
      DRUSEN       0.97      0.88      0.92        41

    accuracy                           0.93        80
   macro avg       0.93      0.93      0.92        80
weighted avg       0.93      0.93      0.92        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.89      0.90        36
      DRUSEN       0.91      0.93      0.92        44

    accuracy                           0.91        80
   macro avg       0.91      0.91      0.91        80
weighted avg       0.91      0.91      0.91        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.86      0.87        44
      DRUSEN       0.84      0.86      0.85        36

    accuracy                           0.86        80
   macro avg       0.86      0.86      0.86        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.92      0.89        36
      DRUSEN       0.93      0.89      0.91        44

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.88      0.85        34
      DRUSEN       0.91      0.85      0.88        46

    accuracy                           0.86        80
   macro avg       0.86      0.87      0.86        80
weighted avg       0.87      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.93      0.90        40
      DRUSEN       0.92      0.88      0.90        40

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.80      0.86        46
      DRUSEN       0.78      0.91      0.84        34

    accuracy                           0.85        80
   macro avg       0.85      0.86      0.85        80
weighted avg       0.86      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.86      0.84        43
      DRUSEN       0.83      0.78      0.81        37

    accuracy                           0.82        80
   macro avg       0.83      0.82      0.82        80
weighted avg       0.83      0.82      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         2
      DRUSEN       1.00      1.00      1.00         1

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

----------------------

Training accuracy [0.8408521303258145, 0.887920298879203]
 
Avg Training Stats after 2 global rounds:
Training Loss : 0.467212481217243
Train Accuracy: 88.79% 


 | Global Training Round : 3 |

| Global Round : 2 | Local Epoch : 0 | [0/6417 (0%)]	Loss: 0.188598
| Global Round : 2 | Local Epoch : 0 | [100/6417 (2%)]	Loss: 0.019470
| Global Round : 2 | Local Epoch : 0 | [200/6417 (3%)]	Loss: 0.208637
| Global Round : 2 | Local Epoch : 0 | [300/6417 (5%)]	Loss: 0.183074
| Global Round : 2 | Local Epoch : 0 | [400/6417 (6%)]	Loss: 0.046203
| Global Round : 2 | Local Epoch : 0 | [500/6417 (8%)]	Loss: 0.134197
| Global Round : 2 | Local Epoch : 0 | [600/6417 (9%)]	Loss: 0.173227
| Global Round : 2 | Local Epoch : 0 | [700/6417 (11%)]	Loss: 0.440840
| Global Round : 2 | Local Epoch : 0 | [800/6417 (12%)]	Loss: 0.119891
| Global Round : 2 | Local Epoch : 0 | [900/6417 (14%)]	Loss: 0.143799
| Global Round : 2 | Local Epoch : 0 | [1000/6417 (16%)]	Loss: 0.462161
| Global Round : 2 | Local Epoch : 0 | [1100/6417 (17%)]	Loss: 0.486068
| Global Round : 2 | Local Epoch : 0 | [1200/6417 (19%)]	Loss: 0.340975
| Global Round : 2 | Local Epoch : 0 | [1300/6417 (20%)]	Loss: 0.179926
| Global Round : 2 | Local Epoch : 0 | [1400/6417 (22%)]	Loss: 0.256986
| Global Round : 2 | Local Epoch : 0 | [1500/6417 (23%)]	Loss: 0.188789
| Global Round : 2 | Local Epoch : 0 | [1600/6417 (25%)]	Loss: 0.153846
| Global Round : 2 | Local Epoch : 0 | [1700/6417 (26%)]	Loss: 0.218843
| Global Round : 2 | Local Epoch : 0 | [1800/6417 (28%)]	Loss: 0.194658
| Global Round : 2 | Local Epoch : 0 | [1900/6417 (30%)]	Loss: 0.072463
| Global Round : 2 | Local Epoch : 0 | [2000/6417 (31%)]	Loss: 0.168414
| Global Round : 2 | Local Epoch : 0 | [2100/6417 (33%)]	Loss: 0.355598
| Global Round : 2 | Local Epoch : 0 | [2200/6417 (34%)]	Loss: 0.197120
| Global Round : 2 | Local Epoch : 0 | [2300/6417 (36%)]	Loss: 0.360761
| Global Round : 2 | Local Epoch : 0 | [2400/6417 (37%)]	Loss: 0.181128
| Global Round : 2 | Local Epoch : 0 | [2500/6417 (39%)]	Loss: 0.151406
| Global Round : 2 | Local Epoch : 0 | [2600/6417 (40%)]	Loss: 0.294503
| Global Round : 2 | Local Epoch : 0 | [2700/6417 (42%)]	Loss: 0.657158
| Global Round : 2 | Local Epoch : 0 | [2800/6417 (44%)]	Loss: 0.272762
| Global Round : 2 | Local Epoch : 0 | [2900/6417 (45%)]	Loss: 0.068198
| Global Round : 2 | Local Epoch : 0 | [3000/6417 (47%)]	Loss: 0.138167
| Global Round : 2 | Local Epoch : 0 | [3100/6417 (48%)]	Loss: 0.144700
| Global Round : 2 | Local Epoch : 0 | [3200/6417 (50%)]	Loss: 0.230872
| Global Round : 2 | Local Epoch : 0 | [3300/6417 (51%)]	Loss: 0.064304
| Global Round : 2 | Local Epoch : 0 | [3400/6417 (53%)]	Loss: 0.294859
| Global Round : 2 | Local Epoch : 0 | [3500/6417 (55%)]	Loss: 0.058421
| Global Round : 2 | Local Epoch : 0 | [3600/6417 (56%)]	Loss: 0.417262
| Global Round : 2 | Local Epoch : 0 | [3700/6417 (58%)]	Loss: 0.111912
| Global Round : 2 | Local Epoch : 0 | [3800/6417 (59%)]	Loss: 0.250949
| Global Round : 2 | Local Epoch : 0 | [3900/6417 (61%)]	Loss: 0.197995
| Global Round : 2 | Local Epoch : 0 | [4000/6417 (62%)]	Loss: 0.338218
| Global Round : 2 | Local Epoch : 0 | [4100/6417 (64%)]	Loss: 0.127410
| Global Round : 2 | Local Epoch : 0 | [4200/6417 (65%)]	Loss: 0.131459
| Global Round : 2 | Local Epoch : 0 | [4300/6417 (67%)]	Loss: 0.042514
| Global Round : 2 | Local Epoch : 0 | [4400/6417 (69%)]	Loss: 0.079406
| Global Round : 2 | Local Epoch : 0 | [4500/6417 (70%)]	Loss: 0.456885
| Global Round : 2 | Local Epoch : 0 | [4600/6417 (72%)]	Loss: 0.095548
| Global Round : 2 | Local Epoch : 0 | [4700/6417 (73%)]	Loss: 0.341473
| Global Round : 2 | Local Epoch : 0 | [4800/6417 (75%)]	Loss: 0.227490
| Global Round : 2 | Local Epoch : 0 | [4900/6417 (76%)]	Loss: 0.353195
| Global Round : 2 | Local Epoch : 0 | [5000/6417 (78%)]	Loss: 0.088463
| Global Round : 2 | Local Epoch : 0 | [5100/6417 (79%)]	Loss: 0.139041
| Global Round : 2 | Local Epoch : 0 | [5200/6417 (81%)]	Loss: 0.088240
| Global Round : 2 | Local Epoch : 0 | [5300/6417 (83%)]	Loss: 0.114402
| Global Round : 2 | Local Epoch : 0 | [5400/6417 (84%)]	Loss: 0.102324
| Global Round : 2 | Local Epoch : 0 | [5500/6417 (86%)]	Loss: 0.551413
| Global Round : 2 | Local Epoch : 0 | [5600/6417 (87%)]	Loss: 0.412847
| Global Round : 2 | Local Epoch : 0 | [5700/6417 (89%)]	Loss: 0.369613
| Global Round : 2 | Local Epoch : 0 | [5800/6417 (90%)]	Loss: 0.238337
| Global Round : 2 | Local Epoch : 0 | [5900/6417 (92%)]	Loss: 0.162465
| Global Round : 2 | Local Epoch : 0 | [6000/6417 (93%)]	Loss: 0.104734
| Global Round : 2 | Local Epoch : 0 | [6100/6417 (95%)]	Loss: 0.245388
| Global Round : 2 | Local Epoch : 0 | [6200/6417 (97%)]	Loss: 0.702158
| Global Round : 2 | Local Epoch : 0 | [6300/6417 (98%)]	Loss: 0.177243
| Global Round : 2 | Local Epoch : 0 | [6400/6417 (100%)]	Loss: 0.221001
| Global Round : 2 | Local Epoch : 1 | [0/6417 (0%)]	Loss: 0.114335
| Global Round : 2 | Local Epoch : 1 | [100/6417 (2%)]	Loss: 0.047477
| Global Round : 2 | Local Epoch : 1 | [200/6417 (3%)]	Loss: 0.101701
| Global Round : 2 | Local Epoch : 1 | [300/6417 (5%)]	Loss: 0.308583
| Global Round : 2 | Local Epoch : 1 | [400/6417 (6%)]	Loss: 0.053570
| Global Round : 2 | Local Epoch : 1 | [500/6417 (8%)]	Loss: 0.075825
| Global Round : 2 | Local Epoch : 1 | [600/6417 (9%)]	Loss: 0.535913
| Global Round : 2 | Local Epoch : 1 | [700/6417 (11%)]	Loss: 0.033265
| Global Round : 2 | Local Epoch : 1 | [800/6417 (12%)]	Loss: 0.078581
| Global Round : 2 | Local Epoch : 1 | [900/6417 (14%)]	Loss: 0.218124
| Global Round : 2 | Local Epoch : 1 | [1000/6417 (16%)]	Loss: 0.058770
| Global Round : 2 | Local Epoch : 1 | [1100/6417 (17%)]	Loss: 0.084826
| Global Round : 2 | Local Epoch : 1 | [1200/6417 (19%)]	Loss: 0.124730
| Global Round : 2 | Local Epoch : 1 | [1300/6417 (20%)]	Loss: 0.206708
| Global Round : 2 | Local Epoch : 1 | [1400/6417 (22%)]	Loss: 0.094095
| Global Round : 2 | Local Epoch : 1 | [1500/6417 (23%)]	Loss: 0.189865
| Global Round : 2 | Local Epoch : 1 | [1600/6417 (25%)]	Loss: 0.171445
| Global Round : 2 | Local Epoch : 1 | [1700/6417 (26%)]	Loss: 0.072735
| Global Round : 2 | Local Epoch : 1 | [1800/6417 (28%)]	Loss: 0.181971
| Global Round : 2 | Local Epoch : 1 | [1900/6417 (30%)]	Loss: 0.113962
| Global Round : 2 | Local Epoch : 1 | [2000/6417 (31%)]	Loss: 0.094045
| Global Round : 2 | Local Epoch : 1 | [2100/6417 (33%)]	Loss: 0.096185
| Global Round : 2 | Local Epoch : 1 | [2200/6417 (34%)]	Loss: 0.178250
| Global Round : 2 | Local Epoch : 1 | [2300/6417 (36%)]	Loss: 0.107732
| Global Round : 2 | Local Epoch : 1 | [2400/6417 (37%)]	Loss: 0.297020
| Global Round : 2 | Local Epoch : 1 | [2500/6417 (39%)]	Loss: 0.137848
| Global Round : 2 | Local Epoch : 1 | [2600/6417 (40%)]	Loss: 0.226755
| Global Round : 2 | Local Epoch : 1 | [2700/6417 (42%)]	Loss: 0.060277
| Global Round : 2 | Local Epoch : 1 | [2800/6417 (44%)]	Loss: 0.412458
| Global Round : 2 | Local Epoch : 1 | [2900/6417 (45%)]	Loss: 0.224010
| Global Round : 2 | Local Epoch : 1 | [3000/6417 (47%)]	Loss: 0.804342
| Global Round : 2 | Local Epoch : 1 | [3100/6417 (48%)]	Loss: 0.032438
| Global Round : 2 | Local Epoch : 1 | [3200/6417 (50%)]	Loss: 0.179483
| Global Round : 2 | Local Epoch : 1 | [3300/6417 (51%)]	Loss: 0.164066
| Global Round : 2 | Local Epoch : 1 | [3400/6417 (53%)]	Loss: 0.420061
| Global Round : 2 | Local Epoch : 1 | [3500/6417 (55%)]	Loss: 0.343808
| Global Round : 2 | Local Epoch : 1 | [3600/6417 (56%)]	Loss: 0.293085
| Global Round : 2 | Local Epoch : 1 | [3700/6417 (58%)]	Loss: 0.153104
| Global Round : 2 | Local Epoch : 1 | [3800/6417 (59%)]	Loss: 0.100686
| Global Round : 2 | Local Epoch : 1 | [3900/6417 (61%)]	Loss: 0.183595
| Global Round : 2 | Local Epoch : 1 | [4000/6417 (62%)]	Loss: 0.175838
| Global Round : 2 | Local Epoch : 1 | [4100/6417 (64%)]	Loss: 0.134249
| Global Round : 2 | Local Epoch : 1 | [4200/6417 (65%)]	Loss: 0.129150
| Global Round : 2 | Local Epoch : 1 | [4300/6417 (67%)]	Loss: 1.021779
| Global Round : 2 | Local Epoch : 1 | [4400/6417 (69%)]	Loss: 0.156430
| Global Round : 2 | Local Epoch : 1 | [4500/6417 (70%)]	Loss: 0.260361
| Global Round : 2 | Local Epoch : 1 | [4600/6417 (72%)]	Loss: 0.060465
| Global Round : 2 | Local Epoch : 1 | [4700/6417 (73%)]	Loss: 0.300581
| Global Round : 2 | Local Epoch : 1 | [4800/6417 (75%)]	Loss: 0.019467
| Global Round : 2 | Local Epoch : 1 | [4900/6417 (76%)]	Loss: 0.067430
| Global Round : 2 | Local Epoch : 1 | [5000/6417 (78%)]	Loss: 0.028866
| Global Round : 2 | Local Epoch : 1 | [5100/6417 (79%)]	Loss: 0.160625
| Global Round : 2 | Local Epoch : 1 | [5200/6417 (81%)]	Loss: 0.066553
| Global Round : 2 | Local Epoch : 1 | [5300/6417 (83%)]	Loss: 0.030881
| Global Round : 2 | Local Epoch : 1 | [5400/6417 (84%)]	Loss: 0.590636
| Global Round : 2 | Local Epoch : 1 | [5500/6417 (86%)]	Loss: 0.221506
| Global Round : 2 | Local Epoch : 1 | [5600/6417 (87%)]	Loss: 0.169035
| Global Round : 2 | Local Epoch : 1 | [5700/6417 (89%)]	Loss: 1.234146
| Global Round : 2 | Local Epoch : 1 | [5800/6417 (90%)]	Loss: 0.371328
| Global Round : 2 | Local Epoch : 1 | [5900/6417 (92%)]	Loss: 0.086656
| Global Round : 2 | Local Epoch : 1 | [6000/6417 (93%)]	Loss: 0.147212
| Global Round : 2 | Local Epoch : 1 | [6100/6417 (95%)]	Loss: 0.018389
| Global Round : 2 | Local Epoch : 1 | [6200/6417 (97%)]	Loss: 0.083276
| Global Round : 2 | Local Epoch : 1 | [6300/6417 (98%)]	Loss: 0.082192
| Global Round : 2 | Local Epoch : 1 | [6400/6417 (100%)]	Loss: 0.155562
| Global Round : 2 | Local Epoch : 2 | [0/6417 (0%)]	Loss: 0.201555
| Global Round : 2 | Local Epoch : 2 | [100/6417 (2%)]	Loss: 0.047657
| Global Round : 2 | Local Epoch : 2 | [200/6417 (3%)]	Loss: 0.083628
| Global Round : 2 | Local Epoch : 2 | [300/6417 (5%)]	Loss: 0.245620
| Global Round : 2 | Local Epoch : 2 | [400/6417 (6%)]	Loss: 0.007306
| Global Round : 2 | Local Epoch : 2 | [500/6417 (8%)]	Loss: 0.031913
| Global Round : 2 | Local Epoch : 2 | [600/6417 (9%)]	Loss: 0.248665
| Global Round : 2 | Local Epoch : 2 | [700/6417 (11%)]	Loss: 0.108657
| Global Round : 2 | Local Epoch : 2 | [800/6417 (12%)]	Loss: 0.061790
| Global Round : 2 | Local Epoch : 2 | [900/6417 (14%)]	Loss: 0.098026
| Global Round : 2 | Local Epoch : 2 | [1000/6417 (16%)]	Loss: 0.333409
| Global Round : 2 | Local Epoch : 2 | [1100/6417 (17%)]	Loss: 0.410869
| Global Round : 2 | Local Epoch : 2 | [1200/6417 (19%)]	Loss: 0.307305
| Global Round : 2 | Local Epoch : 2 | [1300/6417 (20%)]	Loss: 0.169511
| Global Round : 2 | Local Epoch : 2 | [1400/6417 (22%)]	Loss: 0.045583
| Global Round : 2 | Local Epoch : 2 | [1500/6417 (23%)]	Loss: 0.112259
| Global Round : 2 | Local Epoch : 2 | [1600/6417 (25%)]	Loss: 0.095902
| Global Round : 2 | Local Epoch : 2 | [1700/6417 (26%)]	Loss: 0.071933
| Global Round : 2 | Local Epoch : 2 | [1800/6417 (28%)]	Loss: 0.368945
| Global Round : 2 | Local Epoch : 2 | [1900/6417 (30%)]	Loss: 0.646452
| Global Round : 2 | Local Epoch : 2 | [2000/6417 (31%)]	Loss: 0.396300
| Global Round : 2 | Local Epoch : 2 | [2100/6417 (33%)]	Loss: 0.269787
| Global Round : 2 | Local Epoch : 2 | [2200/6417 (34%)]	Loss: 0.226504
| Global Round : 2 | Local Epoch : 2 | [2300/6417 (36%)]	Loss: 0.329276
| Global Round : 2 | Local Epoch : 2 | [2400/6417 (37%)]	Loss: 0.173692
| Global Round : 2 | Local Epoch : 2 | [2500/6417 (39%)]	Loss: 0.095828
| Global Round : 2 | Local Epoch : 2 | [2600/6417 (40%)]	Loss: 0.028475
| Global Round : 2 | Local Epoch : 2 | [2700/6417 (42%)]	Loss: 0.378416
| Global Round : 2 | Local Epoch : 2 | [2800/6417 (44%)]	Loss: 0.093025
| Global Round : 2 | Local Epoch : 2 | [2900/6417 (45%)]	Loss: 0.352380
| Global Round : 2 | Local Epoch : 2 | [3000/6417 (47%)]	Loss: 0.458154
| Global Round : 2 | Local Epoch : 2 | [3100/6417 (48%)]	Loss: 0.048676
| Global Round : 2 | Local Epoch : 2 | [3200/6417 (50%)]	Loss: 0.100842
| Global Round : 2 | Local Epoch : 2 | [3300/6417 (51%)]	Loss: 0.044050
| Global Round : 2 | Local Epoch : 2 | [3400/6417 (53%)]	Loss: 0.134753
| Global Round : 2 | Local Epoch : 2 | [3500/6417 (55%)]	Loss: 0.005618
| Global Round : 2 | Local Epoch : 2 | [3600/6417 (56%)]	Loss: 0.142612
| Global Round : 2 | Local Epoch : 2 | [3700/6417 (58%)]	Loss: 0.598851
| Global Round : 2 | Local Epoch : 2 | [3800/6417 (59%)]	Loss: 0.086629
| Global Round : 2 | Local Epoch : 2 | [3900/6417 (61%)]	Loss: 0.195334
| Global Round : 2 | Local Epoch : 2 | [4000/6417 (62%)]	Loss: 0.149494
| Global Round : 2 | Local Epoch : 2 | [4100/6417 (64%)]	Loss: 0.156219
| Global Round : 2 | Local Epoch : 2 | [4200/6417 (65%)]	Loss: 0.081706
| Global Round : 2 | Local Epoch : 2 | [4300/6417 (67%)]	Loss: 0.160291
| Global Round : 2 | Local Epoch : 2 | [4400/6417 (69%)]	Loss: 0.058340
| Global Round : 2 | Local Epoch : 2 | [4500/6417 (70%)]	Loss: 0.057998
| Global Round : 2 | Local Epoch : 2 | [4600/6417 (72%)]	Loss: 0.077279
| Global Round : 2 | Local Epoch : 2 | [4700/6417 (73%)]	Loss: 0.091069
| Global Round : 2 | Local Epoch : 2 | [4800/6417 (75%)]	Loss: 0.033530
| Global Round : 2 | Local Epoch : 2 | [4900/6417 (76%)]	Loss: 0.070791
| Global Round : 2 | Local Epoch : 2 | [5000/6417 (78%)]	Loss: 0.345329
| Global Round : 2 | Local Epoch : 2 | [5100/6417 (79%)]	Loss: 0.227937
| Global Round : 2 | Local Epoch : 2 | [5200/6417 (81%)]	Loss: 0.530782
| Global Round : 2 | Local Epoch : 2 | [5300/6417 (83%)]	Loss: 0.078323
| Global Round : 2 | Local Epoch : 2 | [5400/6417 (84%)]	Loss: 0.236898
| Global Round : 2 | Local Epoch : 2 | [5500/6417 (86%)]	Loss: 0.101608
| Global Round : 2 | Local Epoch : 2 | [5600/6417 (87%)]	Loss: 0.309626
| Global Round : 2 | Local Epoch : 2 | [5700/6417 (89%)]	Loss: 0.284696
| Global Round : 2 | Local Epoch : 2 | [5800/6417 (90%)]	Loss: 0.217563
| Global Round : 2 | Local Epoch : 2 | [5900/6417 (92%)]	Loss: 0.145366
| Global Round : 2 | Local Epoch : 2 | [6000/6417 (93%)]	Loss: 0.064268
| Global Round : 2 | Local Epoch : 2 | [6100/6417 (95%)]	Loss: 0.027533
| Global Round : 2 | Local Epoch : 2 | [6200/6417 (97%)]	Loss: 0.106526
| Global Round : 2 | Local Epoch : 2 | [6300/6417 (98%)]	Loss: 0.072019
| Global Round : 2 | Local Epoch : 2 | [6400/6417 (100%)]	Loss: 0.112933
| Global Round : 2 | Local Epoch : 3 | [0/6417 (0%)]	Loss: 0.420979
| Global Round : 2 | Local Epoch : 3 | [100/6417 (2%)]	Loss: 0.061058
| Global Round : 2 | Local Epoch : 3 | [200/6417 (3%)]	Loss: 0.067250
| Global Round : 2 | Local Epoch : 3 | [300/6417 (5%)]	Loss: 0.126631
| Global Round : 2 | Local Epoch : 3 | [400/6417 (6%)]	Loss: 0.208551
| Global Round : 2 | Local Epoch : 3 | [500/6417 (8%)]	Loss: 0.298263
| Global Round : 2 | Local Epoch : 3 | [600/6417 (9%)]	Loss: 0.039186
| Global Round : 2 | Local Epoch : 3 | [700/6417 (11%)]	Loss: 0.032298
| Global Round : 2 | Local Epoch : 3 | [800/6417 (12%)]	Loss: 0.027861
| Global Round : 2 | Local Epoch : 3 | [900/6417 (14%)]	Loss: 0.174054
| Global Round : 2 | Local Epoch : 3 | [1000/6417 (16%)]	Loss: 0.083354
| Global Round : 2 | Local Epoch : 3 | [1100/6417 (17%)]	Loss: 0.093259
| Global Round : 2 | Local Epoch : 3 | [1200/6417 (19%)]	Loss: 0.151881
| Global Round : 2 | Local Epoch : 3 | [1300/6417 (20%)]	Loss: 0.269116
| Global Round : 2 | Local Epoch : 3 | [1400/6417 (22%)]	Loss: 0.112284
| Global Round : 2 | Local Epoch : 3 | [1500/6417 (23%)]	Loss: 0.244011
| Global Round : 2 | Local Epoch : 3 | [1600/6417 (25%)]	Loss: 0.076639
| Global Round : 2 | Local Epoch : 3 | [1700/6417 (26%)]	Loss: 0.082657
| Global Round : 2 | Local Epoch : 3 | [1800/6417 (28%)]	Loss: 0.157268
| Global Round : 2 | Local Epoch : 3 | [1900/6417 (30%)]	Loss: 0.171030
| Global Round : 2 | Local Epoch : 3 | [2000/6417 (31%)]	Loss: 0.184549
| Global Round : 2 | Local Epoch : 3 | [2100/6417 (33%)]	Loss: 0.032554
| Global Round : 2 | Local Epoch : 3 | [2200/6417 (34%)]	Loss: 0.067135
| Global Round : 2 | Local Epoch : 3 | [2300/6417 (36%)]	Loss: 0.471840
| Global Round : 2 | Local Epoch : 3 | [2400/6417 (37%)]	Loss: 0.143193
| Global Round : 2 | Local Epoch : 3 | [2500/6417 (39%)]	Loss: 0.619332
| Global Round : 2 | Local Epoch : 3 | [2600/6417 (40%)]	Loss: 0.356829
| Global Round : 2 | Local Epoch : 3 | [2700/6417 (42%)]	Loss: 0.041624
| Global Round : 2 | Local Epoch : 3 | [2800/6417 (44%)]	Loss: 0.419566
| Global Round : 2 | Local Epoch : 3 | [2900/6417 (45%)]	Loss: 0.205755
| Global Round : 2 | Local Epoch : 3 | [3000/6417 (47%)]	Loss: 0.063816
| Global Round : 2 | Local Epoch : 3 | [3100/6417 (48%)]	Loss: 0.063173
| Global Round : 2 | Local Epoch : 3 | [3200/6417 (50%)]	Loss: 0.075894
| Global Round : 2 | Local Epoch : 3 | [3300/6417 (51%)]	Loss: 0.098270
| Global Round : 2 | Local Epoch : 3 | [3400/6417 (53%)]	Loss: 0.085070
| Global Round : 2 | Local Epoch : 3 | [3500/6417 (55%)]	Loss: 0.213803
| Global Round : 2 | Local Epoch : 3 | [3600/6417 (56%)]	Loss: 0.039648
| Global Round : 2 | Local Epoch : 3 | [3700/6417 (58%)]	Loss: 0.005207
| Global Round : 2 | Local Epoch : 3 | [3800/6417 (59%)]	Loss: 3.413877
| Global Round : 2 | Local Epoch : 3 | [3900/6417 (61%)]	Loss: 0.114736
| Global Round : 2 | Local Epoch : 3 | [4000/6417 (62%)]	Loss: 0.208143
| Global Round : 2 | Local Epoch : 3 | [4100/6417 (64%)]	Loss: 0.074633
| Global Round : 2 | Local Epoch : 3 | [4200/6417 (65%)]	Loss: 0.267636
| Global Round : 2 | Local Epoch : 3 | [4300/6417 (67%)]	Loss: 0.061017
| Global Round : 2 | Local Epoch : 3 | [4400/6417 (69%)]	Loss: 0.137564
| Global Round : 2 | Local Epoch : 3 | [4500/6417 (70%)]	Loss: 0.197349
| Global Round : 2 | Local Epoch : 3 | [4600/6417 (72%)]	Loss: 0.283945
| Global Round : 2 | Local Epoch : 3 | [4700/6417 (73%)]	Loss: 0.153632
| Global Round : 2 | Local Epoch : 3 | [4800/6417 (75%)]	Loss: 0.024330
| Global Round : 2 | Local Epoch : 3 | [4900/6417 (76%)]	Loss: 0.958016
| Global Round : 2 | Local Epoch : 3 | [5000/6417 (78%)]	Loss: 0.062382
| Global Round : 2 | Local Epoch : 3 | [5100/6417 (79%)]	Loss: 0.093297
| Global Round : 2 | Local Epoch : 3 | [5200/6417 (81%)]	Loss: 0.242337
| Global Round : 2 | Local Epoch : 3 | [5300/6417 (83%)]	Loss: 0.159256
| Global Round : 2 | Local Epoch : 3 | [5400/6417 (84%)]	Loss: 0.022090
| Global Round : 2 | Local Epoch : 3 | [5500/6417 (86%)]	Loss: 0.105007
| Global Round : 2 | Local Epoch : 3 | [5600/6417 (87%)]	Loss: 0.001698
| Global Round : 2 | Local Epoch : 3 | [5700/6417 (89%)]	Loss: 0.222455
| Global Round : 2 | Local Epoch : 3 | [5800/6417 (90%)]	Loss: 0.137855
| Global Round : 2 | Local Epoch : 3 | [5900/6417 (92%)]	Loss: 0.132480
| Global Round : 2 | Local Epoch : 3 | [6000/6417 (93%)]	Loss: 0.018863
| Global Round : 2 | Local Epoch : 3 | [6100/6417 (95%)]	Loss: 0.032707
| Global Round : 2 | Local Epoch : 3 | [6200/6417 (97%)]	Loss: 0.532984
| Global Round : 2 | Local Epoch : 3 | [6300/6417 (98%)]	Loss: 0.009809
| Global Round : 2 | Local Epoch : 3 | [6400/6417 (100%)]	Loss: 0.227748
| Global Round : 2 | Local Epoch : 4 | [0/6417 (0%)]	Loss: 0.232664
| Global Round : 2 | Local Epoch : 4 | [100/6417 (2%)]	Loss: 0.051673
| Global Round : 2 | Local Epoch : 4 | [200/6417 (3%)]	Loss: 0.146498
| Global Round : 2 | Local Epoch : 4 | [300/6417 (5%)]	Loss: 0.142698
| Global Round : 2 | Local Epoch : 4 | [400/6417 (6%)]	Loss: 0.083823
| Global Round : 2 | Local Epoch : 4 | [500/6417 (8%)]	Loss: 0.068795
| Global Round : 2 | Local Epoch : 4 | [600/6417 (9%)]	Loss: 0.024397
| Global Round : 2 | Local Epoch : 4 | [700/6417 (11%)]	Loss: 0.197744
| Global Round : 2 | Local Epoch : 4 | [800/6417 (12%)]	Loss: 0.397034
| Global Round : 2 | Local Epoch : 4 | [900/6417 (14%)]	Loss: 0.016531
| Global Round : 2 | Local Epoch : 4 | [1000/6417 (16%)]	Loss: 0.191613
| Global Round : 2 | Local Epoch : 4 | [1100/6417 (17%)]	Loss: 0.024815
| Global Round : 2 | Local Epoch : 4 | [1200/6417 (19%)]	Loss: 0.108843
| Global Round : 2 | Local Epoch : 4 | [1300/6417 (20%)]	Loss: 0.069081
| Global Round : 2 | Local Epoch : 4 | [1400/6417 (22%)]	Loss: 0.366967
| Global Round : 2 | Local Epoch : 4 | [1500/6417 (23%)]	Loss: 0.182042
| Global Round : 2 | Local Epoch : 4 | [1600/6417 (25%)]	Loss: 0.397749
| Global Round : 2 | Local Epoch : 4 | [1700/6417 (26%)]	Loss: 0.280465
| Global Round : 2 | Local Epoch : 4 | [1800/6417 (28%)]	Loss: 0.143875
| Global Round : 2 | Local Epoch : 4 | [1900/6417 (30%)]	Loss: 0.540814
| Global Round : 2 | Local Epoch : 4 | [2000/6417 (31%)]	Loss: 0.453917
| Global Round : 2 | Local Epoch : 4 | [2100/6417 (33%)]	Loss: 0.108030
| Global Round : 2 | Local Epoch : 4 | [2200/6417 (34%)]	Loss: 0.341937
| Global Round : 2 | Local Epoch : 4 | [2300/6417 (36%)]	Loss: 0.367956
| Global Round : 2 | Local Epoch : 4 | [2400/6417 (37%)]	Loss: 0.243755
| Global Round : 2 | Local Epoch : 4 | [2500/6417 (39%)]	Loss: 0.054122
| Global Round : 2 | Local Epoch : 4 | [2600/6417 (40%)]	Loss: 0.179355
| Global Round : 2 | Local Epoch : 4 | [2700/6417 (42%)]	Loss: 0.491568
| Global Round : 2 | Local Epoch : 4 | [2800/6417 (44%)]	Loss: 0.180810
| Global Round : 2 | Local Epoch : 4 | [2900/6417 (45%)]	Loss: 0.092053
| Global Round : 2 | Local Epoch : 4 | [3000/6417 (47%)]	Loss: 0.145735
| Global Round : 2 | Local Epoch : 4 | [3100/6417 (48%)]	Loss: 0.081098
| Global Round : 2 | Local Epoch : 4 | [3200/6417 (50%)]	Loss: 0.215333
| Global Round : 2 | Local Epoch : 4 | [3300/6417 (51%)]	Loss: 0.113509
| Global Round : 2 | Local Epoch : 4 | [3400/6417 (53%)]	Loss: 0.070030
| Global Round : 2 | Local Epoch : 4 | [3500/6417 (55%)]	Loss: 0.220799
| Global Round : 2 | Local Epoch : 4 | [3600/6417 (56%)]	Loss: 0.040264
| Global Round : 2 | Local Epoch : 4 | [3700/6417 (58%)]	Loss: 0.037584
| Global Round : 2 | Local Epoch : 4 | [3800/6417 (59%)]	Loss: 0.169855
| Global Round : 2 | Local Epoch : 4 | [3900/6417 (61%)]	Loss: 0.066521
| Global Round : 2 | Local Epoch : 4 | [4000/6417 (62%)]	Loss: 0.228060
| Global Round : 2 | Local Epoch : 4 | [4100/6417 (64%)]	Loss: 0.024505
| Global Round : 2 | Local Epoch : 4 | [4200/6417 (65%)]	Loss: 0.069544
| Global Round : 2 | Local Epoch : 4 | [4300/6417 (67%)]	Loss: 0.095083
| Global Round : 2 | Local Epoch : 4 | [4400/6417 (69%)]	Loss: 0.012309
| Global Round : 2 | Local Epoch : 4 | [4500/6417 (70%)]	Loss: 0.002100
| Global Round : 2 | Local Epoch : 4 | [4600/6417 (72%)]	Loss: 0.060195
| Global Round : 2 | Local Epoch : 4 | [4700/6417 (73%)]	Loss: 0.060358
| Global Round : 2 | Local Epoch : 4 | [4800/6417 (75%)]	Loss: 0.094551
| Global Round : 2 | Local Epoch : 4 | [4900/6417 (76%)]	Loss: 0.283452
| Global Round : 2 | Local Epoch : 4 | [5000/6417 (78%)]	Loss: 0.031988
| Global Round : 2 | Local Epoch : 4 | [5100/6417 (79%)]	Loss: 0.062944
| Global Round : 2 | Local Epoch : 4 | [5200/6417 (81%)]	Loss: 0.187310
| Global Round : 2 | Local Epoch : 4 | [5300/6417 (83%)]	Loss: 0.216248
| Global Round : 2 | Local Epoch : 4 | [5400/6417 (84%)]	Loss: 0.027521
| Global Round : 2 | Local Epoch : 4 | [5500/6417 (86%)]	Loss: 0.707654
| Global Round : 2 | Local Epoch : 4 | [5600/6417 (87%)]	Loss: 0.085882
| Global Round : 2 | Local Epoch : 4 | [5700/6417 (89%)]	Loss: 0.076045
| Global Round : 2 | Local Epoch : 4 | [5800/6417 (90%)]	Loss: 0.068461
| Global Round : 2 | Local Epoch : 4 | [5900/6417 (92%)]	Loss: 0.194844
| Global Round : 2 | Local Epoch : 4 | [6000/6417 (93%)]	Loss: 0.444814
| Global Round : 2 | Local Epoch : 4 | [6100/6417 (95%)]	Loss: 0.002859
| Global Round : 2 | Local Epoch : 4 | [6200/6417 (97%)]	Loss: 0.021468
| Global Round : 2 | Local Epoch : 4 | [6300/6417 (98%)]	Loss: 1.035336
| Global Round : 2 | Local Epoch : 4 | [6400/6417 (100%)]	Loss: 0.035730
----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.98      0.90        41
         DME       0.97      0.79      0.87        39

    accuracy                           0.89        80
   macro avg       0.90      0.89      0.89        80
weighted avg       0.90      0.89      0.89        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.91      0.95        43
         DME       0.90      1.00      0.95        37

    accuracy                           0.95        80
   macro avg       0.95      0.95      0.95        80
weighted avg       0.95      0.95      0.95        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.97      0.93        39
         DME       0.97      0.88      0.92        41

    accuracy                           0.93        80
   macro avg       0.93      0.93      0.92        80
weighted avg       0.93      0.93      0.92        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.89      0.89        35
         DME       0.91      0.91      0.91        45

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.89      0.93        47
         DME       0.86      0.97      0.91        33

    accuracy                           0.93        80
   macro avg       0.92      0.93      0.92        80
weighted avg       0.93      0.93      0.93        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.89      0.89        38
         DME       0.90      0.90      0.90        42

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.70      0.84      0.76        31
         DME       0.88      0.78      0.83        49

    accuracy                           0.80        80
   macro avg       0.79      0.81      0.80        80
weighted avg       0.81      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.92      0.89        39
         DME       0.92      0.85      0.89        41

    accuracy                           0.89        80
   macro avg       0.89      0.89      0.89        80
weighted avg       0.89      0.89      0.89        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.85      0.91        46
         DME       0.82      0.97      0.89        34

    accuracy                           0.90        80
   macro avg       0.90      0.91      0.90        80
weighted avg       0.91      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.85      0.86        46
         DME       0.80      0.82      0.81        34

    accuracy                           0.84        80
   macro avg       0.83      0.84      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         2
         DME       1.00      1.00      1.00         1

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.98      0.90        41
      DRUSEN       0.97      0.79      0.87        39

    accuracy                           0.89        80
   macro avg       0.90      0.89      0.89        80
weighted avg       0.90      0.89      0.89        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.91      0.95        43
      DRUSEN       0.90      1.00      0.95        37

    accuracy                           0.95        80
   macro avg       0.95      0.95      0.95        80
weighted avg       0.95      0.95      0.95        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.97      0.93        39
      DRUSEN       0.97      0.88      0.92        41

    accuracy                           0.93        80
   macro avg       0.93      0.93      0.92        80
weighted avg       0.93      0.93      0.92        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.89      0.89        35
      DRUSEN       0.91      0.91      0.91        45

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.89      0.93        47
      DRUSEN       0.86      0.97      0.91        33

    accuracy                           0.93        80
   macro avg       0.92      0.93      0.92        80
weighted avg       0.93      0.93      0.93        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.89      0.89        38
      DRUSEN       0.90      0.90      0.90        42

    accuracy                           0.90        80
   macro avg       0.90      0.90      0.90        80
weighted avg       0.90      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.70      0.84      0.76        31
      DRUSEN       0.88      0.78      0.83        49

    accuracy                           0.80        80
   macro avg       0.79      0.81      0.80        80
weighted avg       0.81      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.92      0.89        39
      DRUSEN       0.92      0.85      0.89        41

    accuracy                           0.89        80
   macro avg       0.89      0.89      0.89        80
weighted avg       0.89      0.89      0.89        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.85      0.91        46
      DRUSEN       0.82      0.97      0.89        34

    accuracy                           0.90        80
   macro avg       0.90      0.91      0.90        80
weighted avg       0.91      0.90      0.90        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.85      0.86        46
      DRUSEN       0.80      0.82      0.81        34

    accuracy                           0.84        80
   macro avg       0.83      0.84      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         2
      DRUSEN       1.00      1.00      1.00         1

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

----------------------

Training accuracy [0.8408521303258145, 0.887920298879203, 0.8916562889165629]
########################

Client 1 Test Statistics

==========================

For client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.74      0.84        78
         DME       0.71      0.96      0.81        50

    accuracy                           0.83       128
   macro avg       0.84      0.85      0.83       128
weighted avg       0.86      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.77      0.84        75
         DME       0.74      0.91      0.81        53

    accuracy                           0.83       128
   macro avg       0.83      0.84      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.82      0.88        90
         DME       0.68      0.89      0.77        38

    accuracy                           0.84       128
   macro avg       0.81      0.86      0.83       128
weighted avg       0.87      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.71      0.81        86
         DME       0.60      0.90      0.72        42

    accuracy                           0.77       128
   macro avg       0.77      0.81      0.77       128
weighted avg       0.83      0.77      0.78       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.80      0.88        82
         DME       0.73      0.96      0.83        46

    accuracy                           0.86       128
   macro avg       0.85      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.78      0.86        77
         DME       0.74      0.94      0.83        51

    accuracy                           0.84       128
   macro avg       0.85      0.86      0.84       128
weighted avg       0.87      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.80      0.86        80
         DME       0.73      0.92      0.81        48

    accuracy                           0.84       128
   macro avg       0.84      0.86      0.84       128
weighted avg       0.86      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.78      0.87        77
         DME       0.75      0.98      0.85        51

    accuracy                           0.86       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        73
         DME       0.75      0.95      0.84        55

    accuracy                           0.84       128
   macro avg       0.85      0.86      0.84       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.75      0.84        73
         DME       0.74      0.95      0.83        55

    accuracy                           0.84       128
   macro avg       0.85      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.67      0.79        88
         DME       0.56      0.93      0.70        40

    accuracy                           0.75       128
   macro avg       0.76      0.80      0.74       128
weighted avg       0.83      0.75      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.71      0.81        68
         DME       0.74      0.95      0.83        60

    accuracy                           0.82       128
   macro avg       0.84      0.83      0.82       128
weighted avg       0.85      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        82
         DME       0.69      0.93      0.80        46

    accuracy                           0.83       128
   macro avg       0.82      0.85      0.82       128
weighted avg       0.86      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.73      0.84        79
         DME       0.70      0.98      0.81        49

    accuracy                           0.83       128
   macro avg       0.84      0.86      0.83       128
weighted avg       0.87      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.73      0.83        71
         DME       0.74      0.95      0.83        57

    accuracy                           0.83       128
   macro avg       0.84      0.84      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.82      0.88        68
         DME       0.72      0.91      0.81        34

    accuracy                           0.85       102
   macro avg       0.84      0.87      0.84       102
weighted avg       0.87      0.85      0.86       102

----------------------

==========================

Testing client 1 on client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.84      0.87        63
      DRUSEN       0.86      0.91      0.88        65

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.96      0.90        69
      DRUSEN       0.94      0.81      0.87        59

    accuracy                           0.89       128
   macro avg       0.90      0.89      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.83      0.86        64
      DRUSEN       0.84      0.91      0.87        64

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.90      0.88        62
      DRUSEN       0.90      0.86      0.88        66

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.86      0.90        58
      DRUSEN       0.89      0.96      0.92        70

    accuracy                           0.91       128
   macro avg       0.92      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.89      0.88        63
      DRUSEN       0.89      0.88      0.88        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.94      0.94        62
      DRUSEN       0.94      0.95      0.95        66

    accuracy                           0.95       128
   macro avg       0.95      0.95      0.95       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.86      0.87        69
      DRUSEN       0.84      0.88      0.86        59

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.93      0.92        81
      DRUSEN       0.87      0.85      0.86        47

    accuracy                           0.90       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.80      0.82        65
      DRUSEN       0.80      0.84      0.82        63

    accuracy                           0.82       128
   macro avg       0.82      0.82      0.82       128
weighted avg       0.82      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.90      0.88        67
      DRUSEN       0.88      0.84      0.86        61

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.78      0.82        69
      DRUSEN       0.77      0.86      0.82        59

    accuracy                           0.82       128
   macro avg       0.82      0.82      0.82       128
weighted avg       0.83      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.84      0.89        63
      DRUSEN       0.86      0.95      0.91        65

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.92      0.92        65
      DRUSEN       0.92      0.90      0.91        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.91      0.90        57
      DRUSEN       0.93      0.90      0.91        71

    accuracy                           0.91       128
   macro avg       0.90      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.91      0.86        23
      DRUSEN       0.94      0.86      0.90        35

    accuracy                           0.88        58
   macro avg       0.87      0.89      0.88        58
weighted avg       0.89      0.88      0.88        58

----------------------

########################

Client 2 Test Statistics

==========================

For client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.84      0.87        63
      DRUSEN       0.86      0.91      0.88        65

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.96      0.90        69
      DRUSEN       0.94      0.81      0.87        59

    accuracy                           0.89       128
   macro avg       0.90      0.89      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.83      0.86        64
      DRUSEN       0.84      0.91      0.87        64

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.90      0.88        62
      DRUSEN       0.90      0.86      0.88        66

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.86      0.90        58
      DRUSEN       0.89      0.96      0.92        70

    accuracy                           0.91       128
   macro avg       0.92      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.89      0.88        63
      DRUSEN       0.89      0.88      0.88        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.94      0.94        62
      DRUSEN       0.94      0.95      0.95        66

    accuracy                           0.95       128
   macro avg       0.95      0.95      0.95       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.86      0.87        69
      DRUSEN       0.84      0.88      0.86        59

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.93      0.92        81
      DRUSEN       0.87      0.85      0.86        47

    accuracy                           0.90       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.80      0.82        65
      DRUSEN       0.80      0.84      0.82        63

    accuracy                           0.82       128
   macro avg       0.82      0.82      0.82       128
weighted avg       0.82      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.90      0.88        67
      DRUSEN       0.88      0.84      0.86        61

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.78      0.82        69
      DRUSEN       0.77      0.86      0.82        59

    accuracy                           0.82       128
   macro avg       0.82      0.82      0.82       128
weighted avg       0.83      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.84      0.89        63
      DRUSEN       0.86      0.95      0.91        65

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.92      0.92        65
      DRUSEN       0.92      0.90      0.91        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.91      0.90        57
      DRUSEN       0.93      0.90      0.91        71

    accuracy                           0.91       128
   macro avg       0.90      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.91      0.86        23
      DRUSEN       0.94      0.86      0.90        35

    accuracy                           0.88        58
   macro avg       0.87      0.89      0.88        58
weighted avg       0.89      0.88      0.88        58

----------------------

==========================

Testing client 2 on client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.74      0.84        78
         DME       0.71      0.96      0.81        50

    accuracy                           0.83       128
   macro avg       0.84      0.85      0.83       128
weighted avg       0.86      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.77      0.84        75
         DME       0.74      0.91      0.81        53

    accuracy                           0.83       128
   macro avg       0.83      0.84      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.82      0.88        90
         DME       0.68      0.89      0.77        38

    accuracy                           0.84       128
   macro avg       0.81      0.86      0.83       128
weighted avg       0.87      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.71      0.81        86
         DME       0.60      0.90      0.72        42

    accuracy                           0.77       128
   macro avg       0.77      0.81      0.77       128
weighted avg       0.83      0.77      0.78       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.80      0.88        82
         DME       0.73      0.96      0.83        46

    accuracy                           0.86       128
   macro avg       0.85      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.78      0.86        77
         DME       0.74      0.94      0.83        51

    accuracy                           0.84       128
   macro avg       0.85      0.86      0.84       128
weighted avg       0.87      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.80      0.86        80
         DME       0.73      0.92      0.81        48

    accuracy                           0.84       128
   macro avg       0.84      0.86      0.84       128
weighted avg       0.86      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.78      0.87        77
         DME       0.75      0.98      0.85        51

    accuracy                           0.86       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        73
         DME       0.75      0.95      0.84        55

    accuracy                           0.84       128
   macro avg       0.85      0.86      0.84       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.75      0.84        73
         DME       0.74      0.95      0.83        55

    accuracy                           0.84       128
   macro avg       0.85      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.67      0.79        88
         DME       0.56      0.93      0.70        40

    accuracy                           0.75       128
   macro avg       0.76      0.80      0.74       128
weighted avg       0.83      0.75      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.71      0.81        68
         DME       0.74      0.95      0.83        60

    accuracy                           0.82       128
   macro avg       0.84      0.83      0.82       128
weighted avg       0.85      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        82
         DME       0.69      0.93      0.80        46

    accuracy                           0.83       128
   macro avg       0.82      0.85      0.82       128
weighted avg       0.86      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.73      0.84        79
         DME       0.70      0.98      0.81        49

    accuracy                           0.83       128
   macro avg       0.84      0.86      0.83       128
weighted avg       0.87      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.73      0.83        71
         DME       0.74      0.95      0.83        57

    accuracy                           0.83       128
   macro avg       0.84      0.84      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.82      0.88        68
         DME       0.72      0.91      0.81        34

    accuracy                           0.85       102
   macro avg       0.84      0.87      0.84       102
weighted avg       0.87      0.85      0.86       102

----------------------

Test accuracy on client 1 0.8288822947576657
Test accuracy on client 2 0.8832153690596563
========================================

========================================

Test on original client distribution for client 1 : 82.89%
Test on client 2 distribution for client 1 : 88.32%
Test on original client distribution for client 2 : 88.32%
Test on client 1 distribution for client 2 : 82.89%
