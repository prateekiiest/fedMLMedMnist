
Experimental details:
    Model     : cnn
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 3

    Federated parameters:
   IID
    Number of users  : 2
    Local Batch size   : 10
    Local Epochs       : 5

CNNOCTMnist(
  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): Dropout2d(p=0.5, inplace=False)
  (fc1): Linear(in_features=100820, out_features=50, bias=True)
  (fc2): Linear(in_features=50, out_features=2, bias=True)
)

 | Global Training Round : 1 |

| Global Round : 0 | Local Epoch : 0 | [0/6396 (0%)]	Loss: 0.664547
| Global Round : 0 | Local Epoch : 0 | [100/6396 (2%)]	Loss: 0.827669
| Global Round : 0 | Local Epoch : 0 | [200/6396 (3%)]	Loss: 0.702626
| Global Round : 0 | Local Epoch : 0 | [300/6396 (5%)]	Loss: 0.639991
| Global Round : 0 | Local Epoch : 0 | [400/6396 (6%)]	Loss: 0.685229
| Global Round : 0 | Local Epoch : 0 | [500/6396 (8%)]	Loss: 0.707156
| Global Round : 0 | Local Epoch : 0 | [600/6396 (9%)]	Loss: 0.719398
| Global Round : 0 | Local Epoch : 0 | [700/6396 (11%)]	Loss: 0.684590
| Global Round : 0 | Local Epoch : 0 | [800/6396 (12%)]	Loss: 0.689632
| Global Round : 0 | Local Epoch : 0 | [900/6396 (14%)]	Loss: 0.669835
| Global Round : 0 | Local Epoch : 0 | [1000/6396 (16%)]	Loss: 0.698352
| Global Round : 0 | Local Epoch : 0 | [1100/6396 (17%)]	Loss: 0.666568
| Global Round : 0 | Local Epoch : 0 | [1200/6396 (19%)]	Loss: 0.685601
| Global Round : 0 | Local Epoch : 0 | [1300/6396 (20%)]	Loss: 0.696179
| Global Round : 0 | Local Epoch : 0 | [1400/6396 (22%)]	Loss: 0.693022
| Global Round : 0 | Local Epoch : 0 | [1500/6396 (23%)]	Loss: 0.678847
| Global Round : 0 | Local Epoch : 0 | [1600/6396 (25%)]	Loss: 0.695307
| Global Round : 0 | Local Epoch : 0 | [1700/6396 (27%)]	Loss: 0.694353
| Global Round : 0 | Local Epoch : 0 | [1800/6396 (28%)]	Loss: 0.698625
| Global Round : 0 | Local Epoch : 0 | [1900/6396 (30%)]	Loss: 0.703267
| Global Round : 0 | Local Epoch : 0 | [2000/6396 (31%)]	Loss: 0.689739
| Global Round : 0 | Local Epoch : 0 | [2100/6396 (33%)]	Loss: 0.703160
| Global Round : 0 | Local Epoch : 0 | [2200/6396 (34%)]	Loss: 0.681896
| Global Round : 0 | Local Epoch : 0 | [2300/6396 (36%)]	Loss: 0.764335
| Global Round : 0 | Local Epoch : 0 | [2400/6396 (38%)]	Loss: 0.726486
| Global Round : 0 | Local Epoch : 0 | [2500/6396 (39%)]	Loss: 0.699148
| Global Round : 0 | Local Epoch : 0 | [2600/6396 (41%)]	Loss: 0.691903
| Global Round : 0 | Local Epoch : 0 | [2700/6396 (42%)]	Loss: 0.678677
| Global Round : 0 | Local Epoch : 0 | [2800/6396 (44%)]	Loss: 0.685544
| Global Round : 0 | Local Epoch : 0 | [2900/6396 (45%)]	Loss: 0.680859
| Global Round : 0 | Local Epoch : 0 | [3000/6396 (47%)]	Loss: 0.688914
| Global Round : 0 | Local Epoch : 0 | [3100/6396 (48%)]	Loss: 0.698041
| Global Round : 0 | Local Epoch : 0 | [3200/6396 (50%)]	Loss: 0.681990
| Global Round : 0 | Local Epoch : 0 | [3300/6396 (52%)]	Loss: 0.682172
| Global Round : 0 | Local Epoch : 0 | [3400/6396 (53%)]	Loss: 0.714964
| Global Round : 0 | Local Epoch : 0 | [3500/6396 (55%)]	Loss: 0.725247
| Global Round : 0 | Local Epoch : 0 | [3600/6396 (56%)]	Loss: 0.705850
| Global Round : 0 | Local Epoch : 0 | [3700/6396 (58%)]	Loss: 0.706418
| Global Round : 0 | Local Epoch : 0 | [3800/6396 (59%)]	Loss: 0.703932
| Global Round : 0 | Local Epoch : 0 | [3900/6396 (61%)]	Loss: 0.683331
| Global Round : 0 | Local Epoch : 0 | [4000/6396 (62%)]	Loss: 0.691159
| Global Round : 0 | Local Epoch : 0 | [4100/6396 (64%)]	Loss: 0.675861
| Global Round : 0 | Local Epoch : 0 | [4200/6396 (66%)]	Loss: 0.679732
| Global Round : 0 | Local Epoch : 0 | [4300/6396 (67%)]	Loss: 0.676017
| Global Round : 0 | Local Epoch : 0 | [4400/6396 (69%)]	Loss: 0.719411
| Global Round : 0 | Local Epoch : 0 | [4500/6396 (70%)]	Loss: 0.655807
| Global Round : 0 | Local Epoch : 0 | [4600/6396 (72%)]	Loss: 0.697979
| Global Round : 0 | Local Epoch : 0 | [4700/6396 (73%)]	Loss: 0.684822
| Global Round : 0 | Local Epoch : 0 | [4800/6396 (75%)]	Loss: 0.686728
| Global Round : 0 | Local Epoch : 0 | [4900/6396 (77%)]	Loss: 0.809993
| Global Round : 0 | Local Epoch : 0 | [5000/6396 (78%)]	Loss: 0.674599
| Global Round : 0 | Local Epoch : 0 | [5100/6396 (80%)]	Loss: 0.671560
| Global Round : 0 | Local Epoch : 0 | [5200/6396 (81%)]	Loss: 0.694532
| Global Round : 0 | Local Epoch : 0 | [5300/6396 (83%)]	Loss: 0.653473
| Global Round : 0 | Local Epoch : 0 | [5400/6396 (84%)]	Loss: 0.693122
| Global Round : 0 | Local Epoch : 0 | [5500/6396 (86%)]	Loss: 0.697017
| Global Round : 0 | Local Epoch : 0 | [5600/6396 (88%)]	Loss: 0.678620
| Global Round : 0 | Local Epoch : 0 | [5700/6396 (89%)]	Loss: 0.622470
| Global Round : 0 | Local Epoch : 0 | [5800/6396 (91%)]	Loss: 0.702035
| Global Round : 0 | Local Epoch : 0 | [5900/6396 (92%)]	Loss: 0.664386
| Global Round : 0 | Local Epoch : 0 | [6000/6396 (94%)]	Loss: 0.674292
| Global Round : 0 | Local Epoch : 0 | [6100/6396 (95%)]	Loss: 0.676083
| Global Round : 0 | Local Epoch : 0 | [6200/6396 (97%)]	Loss: 0.675864
| Global Round : 0 | Local Epoch : 0 | [6300/6396 (98%)]	Loss: 0.698390
| Global Round : 0 | Local Epoch : 1 | [0/6396 (0%)]	Loss: 0.708861
| Global Round : 0 | Local Epoch : 1 | [100/6396 (2%)]	Loss: 0.700500
| Global Round : 0 | Local Epoch : 1 | [200/6396 (3%)]	Loss: 0.690122
| Global Round : 0 | Local Epoch : 1 | [300/6396 (5%)]	Loss: 0.681672
| Global Round : 0 | Local Epoch : 1 | [400/6396 (6%)]	Loss: 0.714270
| Global Round : 0 | Local Epoch : 1 | [500/6396 (8%)]	Loss: 0.770027
| Global Round : 0 | Local Epoch : 1 | [600/6396 (9%)]	Loss: 0.679286
| Global Round : 0 | Local Epoch : 1 | [700/6396 (11%)]	Loss: 0.676546
| Global Round : 0 | Local Epoch : 1 | [800/6396 (12%)]	Loss: 0.684405
| Global Round : 0 | Local Epoch : 1 | [900/6396 (14%)]	Loss: 0.664034
| Global Round : 0 | Local Epoch : 1 | [1000/6396 (16%)]	Loss: 0.627996
| Global Round : 0 | Local Epoch : 1 | [1100/6396 (17%)]	Loss: 0.690678
| Global Round : 0 | Local Epoch : 1 | [1200/6396 (19%)]	Loss: 0.665779
| Global Round : 0 | Local Epoch : 1 | [1300/6396 (20%)]	Loss: 0.691218
| Global Round : 0 | Local Epoch : 1 | [1400/6396 (22%)]	Loss: 0.677879
| Global Round : 0 | Local Epoch : 1 | [1500/6396 (23%)]	Loss: 0.657850
| Global Round : 0 | Local Epoch : 1 | [1600/6396 (25%)]	Loss: 0.709527
| Global Round : 0 | Local Epoch : 1 | [1700/6396 (27%)]	Loss: 0.665290
| Global Round : 0 | Local Epoch : 1 | [1800/6396 (28%)]	Loss: 0.723554
| Global Round : 0 | Local Epoch : 1 | [1900/6396 (30%)]	Loss: 0.672631
| Global Round : 0 | Local Epoch : 1 | [2000/6396 (31%)]	Loss: 0.632021
| Global Round : 0 | Local Epoch : 1 | [2100/6396 (33%)]	Loss: 0.643972
| Global Round : 0 | Local Epoch : 1 | [2200/6396 (34%)]	Loss: 0.886873
| Global Round : 0 | Local Epoch : 1 | [2300/6396 (36%)]	Loss: 0.706716
| Global Round : 0 | Local Epoch : 1 | [2400/6396 (38%)]	Loss: 0.727325
| Global Round : 0 | Local Epoch : 1 | [2500/6396 (39%)]	Loss: 0.675443
| Global Round : 0 | Local Epoch : 1 | [2600/6396 (41%)]	Loss: 0.725286
| Global Round : 0 | Local Epoch : 1 | [2700/6396 (42%)]	Loss: 0.689635
| Global Round : 0 | Local Epoch : 1 | [2800/6396 (44%)]	Loss: 0.662660
| Global Round : 0 | Local Epoch : 1 | [2900/6396 (45%)]	Loss: 0.678716
| Global Round : 0 | Local Epoch : 1 | [3000/6396 (47%)]	Loss: 0.763770
| Global Round : 0 | Local Epoch : 1 | [3100/6396 (48%)]	Loss: 0.682379
| Global Round : 0 | Local Epoch : 1 | [3200/6396 (50%)]	Loss: 0.721262
| Global Round : 0 | Local Epoch : 1 | [3300/6396 (52%)]	Loss: 0.597681
| Global Round : 0 | Local Epoch : 1 | [3400/6396 (53%)]	Loss: 0.670940
| Global Round : 0 | Local Epoch : 1 | [3500/6396 (55%)]	Loss: 0.706761
| Global Round : 0 | Local Epoch : 1 | [3600/6396 (56%)]	Loss: 0.632529
| Global Round : 0 | Local Epoch : 1 | [3700/6396 (58%)]	Loss: 0.757897
| Global Round : 0 | Local Epoch : 1 | [3800/6396 (59%)]	Loss: 0.623665
| Global Round : 0 | Local Epoch : 1 | [3900/6396 (61%)]	Loss: 0.632277
| Global Round : 0 | Local Epoch : 1 | [4000/6396 (62%)]	Loss: 0.658467
| Global Round : 0 | Local Epoch : 1 | [4100/6396 (64%)]	Loss: 0.678343
| Global Round : 0 | Local Epoch : 1 | [4200/6396 (66%)]	Loss: 0.710547
| Global Round : 0 | Local Epoch : 1 | [4300/6396 (67%)]	Loss: 0.658256
| Global Round : 0 | Local Epoch : 1 | [4400/6396 (69%)]	Loss: 0.707696
| Global Round : 0 | Local Epoch : 1 | [4500/6396 (70%)]	Loss: 0.722370
| Global Round : 0 | Local Epoch : 1 | [4600/6396 (72%)]	Loss: 0.739221
| Global Round : 0 | Local Epoch : 1 | [4700/6396 (73%)]	Loss: 0.590767
| Global Round : 0 | Local Epoch : 1 | [4800/6396 (75%)]	Loss: 0.647061
| Global Round : 0 | Local Epoch : 1 | [4900/6396 (77%)]	Loss: 0.671496
| Global Round : 0 | Local Epoch : 1 | [5000/6396 (78%)]	Loss: 0.558162
| Global Round : 0 | Local Epoch : 1 | [5100/6396 (80%)]	Loss: 0.652701
| Global Round : 0 | Local Epoch : 1 | [5200/6396 (81%)]	Loss: 0.661260
| Global Round : 0 | Local Epoch : 1 | [5300/6396 (83%)]	Loss: 0.737464
| Global Round : 0 | Local Epoch : 1 | [5400/6396 (84%)]	Loss: 0.813267
| Global Round : 0 | Local Epoch : 1 | [5500/6396 (86%)]	Loss: 0.697420
| Global Round : 0 | Local Epoch : 1 | [5600/6396 (88%)]	Loss: 0.626895
| Global Round : 0 | Local Epoch : 1 | [5700/6396 (89%)]	Loss: 0.662861
| Global Round : 0 | Local Epoch : 1 | [5800/6396 (91%)]	Loss: 0.706084
| Global Round : 0 | Local Epoch : 1 | [5900/6396 (92%)]	Loss: 0.506841
| Global Round : 0 | Local Epoch : 1 | [6000/6396 (94%)]	Loss: 0.711813
| Global Round : 0 | Local Epoch : 1 | [6100/6396 (95%)]	Loss: 0.635079
| Global Round : 0 | Local Epoch : 1 | [6200/6396 (97%)]	Loss: 0.648600
| Global Round : 0 | Local Epoch : 1 | [6300/6396 (98%)]	Loss: 0.557304
| Global Round : 0 | Local Epoch : 2 | [0/6396 (0%)]	Loss: 0.617590
| Global Round : 0 | Local Epoch : 2 | [100/6396 (2%)]	Loss: 0.549193
| Global Round : 0 | Local Epoch : 2 | [200/6396 (3%)]	Loss: 0.637420
| Global Round : 0 | Local Epoch : 2 | [300/6396 (5%)]	Loss: 0.685238
| Global Round : 0 | Local Epoch : 2 | [400/6396 (6%)]	Loss: 0.612226
| Global Round : 0 | Local Epoch : 2 | [500/6396 (8%)]	Loss: 0.527560
| Global Round : 0 | Local Epoch : 2 | [600/6396 (9%)]	Loss: 0.713963
| Global Round : 0 | Local Epoch : 2 | [700/6396 (11%)]	Loss: 0.544946
| Global Round : 0 | Local Epoch : 2 | [800/6396 (12%)]	Loss: 0.696265
| Global Round : 0 | Local Epoch : 2 | [900/6396 (14%)]	Loss: 0.725679
| Global Round : 0 | Local Epoch : 2 | [1000/6396 (16%)]	Loss: 0.683535
| Global Round : 0 | Local Epoch : 2 | [1100/6396 (17%)]	Loss: 0.630913
| Global Round : 0 | Local Epoch : 2 | [1200/6396 (19%)]	Loss: 0.617493
| Global Round : 0 | Local Epoch : 2 | [1300/6396 (20%)]	Loss: 0.384786
| Global Round : 0 | Local Epoch : 2 | [1400/6396 (22%)]	Loss: 0.620389
| Global Round : 0 | Local Epoch : 2 | [1500/6396 (23%)]	Loss: 0.491299
| Global Round : 0 | Local Epoch : 2 | [1600/6396 (25%)]	Loss: 0.709300
| Global Round : 0 | Local Epoch : 2 | [1700/6396 (27%)]	Loss: 0.454540
| Global Round : 0 | Local Epoch : 2 | [1800/6396 (28%)]	Loss: 0.698818
| Global Round : 0 | Local Epoch : 2 | [1900/6396 (30%)]	Loss: 0.608877
| Global Round : 0 | Local Epoch : 2 | [2000/6396 (31%)]	Loss: 0.965595
| Global Round : 0 | Local Epoch : 2 | [2100/6396 (33%)]	Loss: 0.496902
| Global Round : 0 | Local Epoch : 2 | [2200/6396 (34%)]	Loss: 0.619240
| Global Round : 0 | Local Epoch : 2 | [2300/6396 (36%)]	Loss: 0.654289
| Global Round : 0 | Local Epoch : 2 | [2400/6396 (38%)]	Loss: 0.542336
| Global Round : 0 | Local Epoch : 2 | [2500/6396 (39%)]	Loss: 0.570946
| Global Round : 0 | Local Epoch : 2 | [2600/6396 (41%)]	Loss: 0.549734
| Global Round : 0 | Local Epoch : 2 | [2700/6396 (42%)]	Loss: 0.692901
| Global Round : 0 | Local Epoch : 2 | [2800/6396 (44%)]	Loss: 0.638045
| Global Round : 0 | Local Epoch : 2 | [2900/6396 (45%)]	Loss: 0.634283
| Global Round : 0 | Local Epoch : 2 | [3000/6396 (47%)]	Loss: 0.596232
| Global Round : 0 | Local Epoch : 2 | [3100/6396 (48%)]	Loss: 0.514680
| Global Round : 0 | Local Epoch : 2 | [3200/6396 (50%)]	Loss: 0.551663
| Global Round : 0 | Local Epoch : 2 | [3300/6396 (52%)]	Loss: 0.459576
| Global Round : 0 | Local Epoch : 2 | [3400/6396 (53%)]	Loss: 0.540287
| Global Round : 0 | Local Epoch : 2 | [3500/6396 (55%)]	Loss: 0.812333
| Global Round : 0 | Local Epoch : 2 | [3600/6396 (56%)]	Loss: 0.555152
| Global Round : 0 | Local Epoch : 2 | [3700/6396 (58%)]	Loss: 0.655383
| Global Round : 0 | Local Epoch : 2 | [3800/6396 (59%)]	Loss: 0.463155
| Global Round : 0 | Local Epoch : 2 | [3900/6396 (61%)]	Loss: 0.553581
| Global Round : 0 | Local Epoch : 2 | [4000/6396 (62%)]	Loss: 0.292518
| Global Round : 0 | Local Epoch : 2 | [4100/6396 (64%)]	Loss: 0.853607
| Global Round : 0 | Local Epoch : 2 | [4200/6396 (66%)]	Loss: 0.644612
| Global Round : 0 | Local Epoch : 2 | [4300/6396 (67%)]	Loss: 0.356249
| Global Round : 0 | Local Epoch : 2 | [4400/6396 (69%)]	Loss: 0.531464
| Global Round : 0 | Local Epoch : 2 | [4500/6396 (70%)]	Loss: 0.590585
| Global Round : 0 | Local Epoch : 2 | [4600/6396 (72%)]	Loss: 0.458084
| Global Round : 0 | Local Epoch : 2 | [4700/6396 (73%)]	Loss: 0.306568
| Global Round : 0 | Local Epoch : 2 | [4800/6396 (75%)]	Loss: 0.536571
| Global Round : 0 | Local Epoch : 2 | [4900/6396 (77%)]	Loss: 0.525126
| Global Round : 0 | Local Epoch : 2 | [5000/6396 (78%)]	Loss: 0.421159
| Global Round : 0 | Local Epoch : 2 | [5100/6396 (80%)]	Loss: 0.613883
| Global Round : 0 | Local Epoch : 2 | [5200/6396 (81%)]	Loss: 0.542287
| Global Round : 0 | Local Epoch : 2 | [5300/6396 (83%)]	Loss: 0.729104
| Global Round : 0 | Local Epoch : 2 | [5400/6396 (84%)]	Loss: 0.435677
| Global Round : 0 | Local Epoch : 2 | [5500/6396 (86%)]	Loss: 0.671958
| Global Round : 0 | Local Epoch : 2 | [5600/6396 (88%)]	Loss: 0.387608
| Global Round : 0 | Local Epoch : 2 | [5700/6396 (89%)]	Loss: 0.708926
| Global Round : 0 | Local Epoch : 2 | [5800/6396 (91%)]	Loss: 0.581330
| Global Round : 0 | Local Epoch : 2 | [5900/6396 (92%)]	Loss: 0.300707
| Global Round : 0 | Local Epoch : 2 | [6000/6396 (94%)]	Loss: 0.384493
| Global Round : 0 | Local Epoch : 2 | [6100/6396 (95%)]	Loss: 0.502346
| Global Round : 0 | Local Epoch : 2 | [6200/6396 (97%)]	Loss: 0.264435
| Global Round : 0 | Local Epoch : 2 | [6300/6396 (98%)]	Loss: 0.388941
| Global Round : 0 | Local Epoch : 3 | [0/6396 (0%)]	Loss: 0.542589
| Global Round : 0 | Local Epoch : 3 | [100/6396 (2%)]	Loss: 0.492470
| Global Round : 0 | Local Epoch : 3 | [200/6396 (3%)]	Loss: 0.719308
| Global Round : 0 | Local Epoch : 3 | [300/6396 (5%)]	Loss: 0.620463
| Global Round : 0 | Local Epoch : 3 | [400/6396 (6%)]	Loss: 0.364524
| Global Round : 0 | Local Epoch : 3 | [500/6396 (8%)]	Loss: 0.437222
| Global Round : 0 | Local Epoch : 3 | [600/6396 (9%)]	Loss: 0.505876
| Global Round : 0 | Local Epoch : 3 | [700/6396 (11%)]	Loss: 0.393600
| Global Round : 0 | Local Epoch : 3 | [800/6396 (12%)]	Loss: 0.584131
| Global Round : 0 | Local Epoch : 3 | [900/6396 (14%)]	Loss: 0.405713
| Global Round : 0 | Local Epoch : 3 | [1000/6396 (16%)]	Loss: 0.633307
| Global Round : 0 | Local Epoch : 3 | [1100/6396 (17%)]	Loss: 0.442886
| Global Round : 0 | Local Epoch : 3 | [1200/6396 (19%)]	Loss: 0.304767
| Global Round : 0 | Local Epoch : 3 | [1300/6396 (20%)]	Loss: 0.244855
| Global Round : 0 | Local Epoch : 3 | [1400/6396 (22%)]	Loss: 0.328688
| Global Round : 0 | Local Epoch : 3 | [1500/6396 (23%)]	Loss: 0.222522
| Global Round : 0 | Local Epoch : 3 | [1600/6396 (25%)]	Loss: 0.397287
| Global Round : 0 | Local Epoch : 3 | [1700/6396 (27%)]	Loss: 0.682277
| Global Round : 0 | Local Epoch : 3 | [1800/6396 (28%)]	Loss: 0.366776
| Global Round : 0 | Local Epoch : 3 | [1900/6396 (30%)]	Loss: 0.294686
| Global Round : 0 | Local Epoch : 3 | [2000/6396 (31%)]	Loss: 0.690995
| Global Round : 0 | Local Epoch : 3 | [2100/6396 (33%)]	Loss: 0.260692
| Global Round : 0 | Local Epoch : 3 | [2200/6396 (34%)]	Loss: 0.481411
| Global Round : 0 | Local Epoch : 3 | [2300/6396 (36%)]	Loss: 0.805185
| Global Round : 0 | Local Epoch : 3 | [2400/6396 (38%)]	Loss: 0.542077
| Global Round : 0 | Local Epoch : 3 | [2500/6396 (39%)]	Loss: 0.431615
| Global Round : 0 | Local Epoch : 3 | [2600/6396 (41%)]	Loss: 0.323024
| Global Round : 0 | Local Epoch : 3 | [2700/6396 (42%)]	Loss: 0.340396
| Global Round : 0 | Local Epoch : 3 | [2800/6396 (44%)]	Loss: 0.261524
| Global Round : 0 | Local Epoch : 3 | [2900/6396 (45%)]	Loss: 0.486420
| Global Round : 0 | Local Epoch : 3 | [3000/6396 (47%)]	Loss: 0.695608
| Global Round : 0 | Local Epoch : 3 | [3100/6396 (48%)]	Loss: 0.860088
| Global Round : 0 | Local Epoch : 3 | [3200/6396 (50%)]	Loss: 0.370499
| Global Round : 0 | Local Epoch : 3 | [3300/6396 (52%)]	Loss: 0.352203
| Global Round : 0 | Local Epoch : 3 | [3400/6396 (53%)]	Loss: 0.279210
| Global Round : 0 | Local Epoch : 3 | [3500/6396 (55%)]	Loss: 0.559064
| Global Round : 0 | Local Epoch : 3 | [3600/6396 (56%)]	Loss: 0.344099
| Global Round : 0 | Local Epoch : 3 | [3700/6396 (58%)]	Loss: 0.224551
| Global Round : 0 | Local Epoch : 3 | [3800/6396 (59%)]	Loss: 0.772311
| Global Round : 0 | Local Epoch : 3 | [3900/6396 (61%)]	Loss: 0.612193
| Global Round : 0 | Local Epoch : 3 | [4000/6396 (62%)]	Loss: 0.453742
| Global Round : 0 | Local Epoch : 3 | [4100/6396 (64%)]	Loss: 0.874876
| Global Round : 0 | Local Epoch : 3 | [4200/6396 (66%)]	Loss: 0.477301
| Global Round : 0 | Local Epoch : 3 | [4300/6396 (67%)]	Loss: 0.687961
| Global Round : 0 | Local Epoch : 3 | [4400/6396 (69%)]	Loss: 0.354459
| Global Round : 0 | Local Epoch : 3 | [4500/6396 (70%)]	Loss: 0.501559
| Global Round : 0 | Local Epoch : 3 | [4600/6396 (72%)]	Loss: 0.504207
| Global Round : 0 | Local Epoch : 3 | [4700/6396 (73%)]	Loss: 0.494952
| Global Round : 0 | Local Epoch : 3 | [4800/6396 (75%)]	Loss: 0.414027
| Global Round : 0 | Local Epoch : 3 | [4900/6396 (77%)]	Loss: 0.264772
| Global Round : 0 | Local Epoch : 3 | [5000/6396 (78%)]	Loss: 0.272681
| Global Round : 0 | Local Epoch : 3 | [5100/6396 (80%)]	Loss: 0.178740
| Global Round : 0 | Local Epoch : 3 | [5200/6396 (81%)]	Loss: 1.114759
| Global Round : 0 | Local Epoch : 3 | [5300/6396 (83%)]	Loss: 0.417806
| Global Round : 0 | Local Epoch : 3 | [5400/6396 (84%)]	Loss: 0.938002
| Global Round : 0 | Local Epoch : 3 | [5500/6396 (86%)]	Loss: 0.575996
| Global Round : 0 | Local Epoch : 3 | [5600/6396 (88%)]	Loss: 0.388094
| Global Round : 0 | Local Epoch : 3 | [5700/6396 (89%)]	Loss: 0.341529
| Global Round : 0 | Local Epoch : 3 | [5800/6396 (91%)]	Loss: 0.705025
| Global Round : 0 | Local Epoch : 3 | [5900/6396 (92%)]	Loss: 0.879384
| Global Round : 0 | Local Epoch : 3 | [6000/6396 (94%)]	Loss: 0.277417
| Global Round : 0 | Local Epoch : 3 | [6100/6396 (95%)]	Loss: 0.417108
| Global Round : 0 | Local Epoch : 3 | [6200/6396 (97%)]	Loss: 1.235971
| Global Round : 0 | Local Epoch : 3 | [6300/6396 (98%)]	Loss: 0.361568
| Global Round : 0 | Local Epoch : 4 | [0/6396 (0%)]	Loss: 0.695306
| Global Round : 0 | Local Epoch : 4 | [100/6396 (2%)]	Loss: 0.494881
| Global Round : 0 | Local Epoch : 4 | [200/6396 (3%)]	Loss: 0.188032
| Global Round : 0 | Local Epoch : 4 | [300/6396 (5%)]	Loss: 0.324785
| Global Round : 0 | Local Epoch : 4 | [400/6396 (6%)]	Loss: 0.559536
| Global Round : 0 | Local Epoch : 4 | [500/6396 (8%)]	Loss: 0.417275
| Global Round : 0 | Local Epoch : 4 | [600/6396 (9%)]	Loss: 0.441991
| Global Round : 0 | Local Epoch : 4 | [700/6396 (11%)]	Loss: 0.276213
| Global Round : 0 | Local Epoch : 4 | [800/6396 (12%)]	Loss: 0.612669
| Global Round : 0 | Local Epoch : 4 | [900/6396 (14%)]	Loss: 0.245833
| Global Round : 0 | Local Epoch : 4 | [1000/6396 (16%)]	Loss: 0.837753
| Global Round : 0 | Local Epoch : 4 | [1100/6396 (17%)]	Loss: 0.520124
| Global Round : 0 | Local Epoch : 4 | [1200/6396 (19%)]	Loss: 0.570928
| Global Round : 0 | Local Epoch : 4 | [1300/6396 (20%)]	Loss: 0.482309
| Global Round : 0 | Local Epoch : 4 | [1400/6396 (22%)]	Loss: 0.493471
| Global Round : 0 | Local Epoch : 4 | [1500/6396 (23%)]	Loss: 0.258369
| Global Round : 0 | Local Epoch : 4 | [1600/6396 (25%)]	Loss: 0.601742
| Global Round : 0 | Local Epoch : 4 | [1700/6396 (27%)]	Loss: 0.414350
| Global Round : 0 | Local Epoch : 4 | [1800/6396 (28%)]	Loss: 0.496319
| Global Round : 0 | Local Epoch : 4 | [1900/6396 (30%)]	Loss: 0.234068
| Global Round : 0 | Local Epoch : 4 | [2000/6396 (31%)]	Loss: 0.351456
| Global Round : 0 | Local Epoch : 4 | [2100/6396 (33%)]	Loss: 0.506849
| Global Round : 0 | Local Epoch : 4 | [2200/6396 (34%)]	Loss: 0.522906
| Global Round : 0 | Local Epoch : 4 | [2300/6396 (36%)]	Loss: 0.396727
| Global Round : 0 | Local Epoch : 4 | [2400/6396 (38%)]	Loss: 0.709192
| Global Round : 0 | Local Epoch : 4 | [2500/6396 (39%)]	Loss: 0.758041
| Global Round : 0 | Local Epoch : 4 | [2600/6396 (41%)]	Loss: 0.307205
| Global Round : 0 | Local Epoch : 4 | [2700/6396 (42%)]	Loss: 0.589312
| Global Round : 0 | Local Epoch : 4 | [2800/6396 (44%)]	Loss: 0.535036
| Global Round : 0 | Local Epoch : 4 | [2900/6396 (45%)]	Loss: 0.277121
| Global Round : 0 | Local Epoch : 4 | [3000/6396 (47%)]	Loss: 0.421640
| Global Round : 0 | Local Epoch : 4 | [3100/6396 (48%)]	Loss: 0.232019
| Global Round : 0 | Local Epoch : 4 | [3200/6396 (50%)]	Loss: 0.497850
| Global Round : 0 | Local Epoch : 4 | [3300/6396 (52%)]	Loss: 0.802910
| Global Round : 0 | Local Epoch : 4 | [3400/6396 (53%)]	Loss: 0.742671
| Global Round : 0 | Local Epoch : 4 | [3500/6396 (55%)]	Loss: 0.625875
| Global Round : 0 | Local Epoch : 4 | [3600/6396 (56%)]	Loss: 0.260233
| Global Round : 0 | Local Epoch : 4 | [3700/6396 (58%)]	Loss: 0.506922
| Global Round : 0 | Local Epoch : 4 | [3800/6396 (59%)]	Loss: 0.282150
| Global Round : 0 | Local Epoch : 4 | [3900/6396 (61%)]	Loss: 0.465449
| Global Round : 0 | Local Epoch : 4 | [4000/6396 (62%)]	Loss: 0.235166
| Global Round : 0 | Local Epoch : 4 | [4100/6396 (64%)]	Loss: 0.650445
| Global Round : 0 | Local Epoch : 4 | [4200/6396 (66%)]	Loss: 0.392456
| Global Round : 0 | Local Epoch : 4 | [4300/6396 (67%)]	Loss: 0.545907
| Global Round : 0 | Local Epoch : 4 | [4400/6396 (69%)]	Loss: 0.870497
| Global Round : 0 | Local Epoch : 4 | [4500/6396 (70%)]	Loss: 0.369301
| Global Round : 0 | Local Epoch : 4 | [4600/6396 (72%)]	Loss: 0.382220
| Global Round : 0 | Local Epoch : 4 | [4700/6396 (73%)]	Loss: 0.495566
| Global Round : 0 | Local Epoch : 4 | [4800/6396 (75%)]	Loss: 0.506572
| Global Round : 0 | Local Epoch : 4 | [4900/6396 (77%)]	Loss: 0.128128
| Global Round : 0 | Local Epoch : 4 | [5000/6396 (78%)]	Loss: 0.345330
| Global Round : 0 | Local Epoch : 4 | [5100/6396 (80%)]	Loss: 0.471873
| Global Round : 0 | Local Epoch : 4 | [5200/6396 (81%)]	Loss: 0.588263
| Global Round : 0 | Local Epoch : 4 | [5300/6396 (83%)]	Loss: 0.617259
| Global Round : 0 | Local Epoch : 4 | [5400/6396 (84%)]	Loss: 0.267552
| Global Round : 0 | Local Epoch : 4 | [5500/6396 (86%)]	Loss: 0.288396
| Global Round : 0 | Local Epoch : 4 | [5600/6396 (88%)]	Loss: 0.297044
| Global Round : 0 | Local Epoch : 4 | [5700/6396 (89%)]	Loss: 0.265175
| Global Round : 0 | Local Epoch : 4 | [5800/6396 (91%)]	Loss: 0.587932
| Global Round : 0 | Local Epoch : 4 | [5900/6396 (92%)]	Loss: 0.265238
| Global Round : 0 | Local Epoch : 4 | [6000/6396 (94%)]	Loss: 0.314995
| Global Round : 0 | Local Epoch : 4 | [6100/6396 (95%)]	Loss: 0.732330
| Global Round : 0 | Local Epoch : 4 | [6200/6396 (97%)]	Loss: 1.506375
| Global Round : 0 | Local Epoch : 4 | [6300/6396 (98%)]	Loss: 0.379566
----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.90      0.84        29
         DME       0.94      0.86      0.90        51

    accuracy                           0.88        80
   macro avg       0.86      0.88      0.87        80
weighted avg       0.88      0.88      0.88        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.89      0.85        36
         DME       0.90      0.84      0.87        44

    accuracy                           0.86        80
   macro avg       0.86      0.86      0.86        80
weighted avg       0.87      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.85      0.85        39
         DME       0.85      0.85      0.85        41

    accuracy                           0.85        80
   macro avg       0.85      0.85      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.67      0.79      0.72        38
         DME       0.77      0.64      0.70        42

    accuracy                           0.71        80
   macro avg       0.72      0.72      0.71        80
weighted avg       0.72      0.71      0.71        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.68      0.81      0.74        26
         DME       0.90      0.81      0.85        54

    accuracy                           0.81        80
   macro avg       0.79      0.81      0.80        80
weighted avg       0.83      0.81      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.63      0.86      0.73        28
         DME       0.90      0.73      0.81        52

    accuracy                           0.78        80
   macro avg       0.77      0.79      0.77        80
weighted avg       0.81      0.78      0.78        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.76      0.86      0.81        36
         DME       0.87      0.77      0.82        44

    accuracy                           0.81        80
   macro avg       0.81      0.82      0.81        80
weighted avg       0.82      0.81      0.81        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.61      0.86      0.71        29
         DME       0.90      0.69      0.78        51

    accuracy                           0.75        80
   macro avg       0.75      0.77      0.75        80
weighted avg       0.79      0.75      0.75        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.69      0.85      0.76        26
         DME       0.92      0.81      0.86        54

    accuracy                           0.82        80
   macro avg       0.80      0.83      0.81        80
weighted avg       0.84      0.82      0.83        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.70      0.93      0.80        28
         DME       0.95      0.79      0.86        52

    accuracy                           0.84        80
   macro avg       0.83      0.86      0.83        80
weighted avg       0.87      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.90      0.84        29
      DRUSEN       0.94      0.86      0.90        51

    accuracy                           0.88        80
   macro avg       0.86      0.88      0.87        80
weighted avg       0.88      0.88      0.88        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.89      0.85        36
      DRUSEN       0.90      0.84      0.87        44

    accuracy                           0.86        80
   macro avg       0.86      0.86      0.86        80
weighted avg       0.87      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.85      0.85        39
      DRUSEN       0.85      0.85      0.85        41

    accuracy                           0.85        80
   macro avg       0.85      0.85      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.67      0.79      0.72        38
      DRUSEN       0.77      0.64      0.70        42

    accuracy                           0.71        80
   macro avg       0.72      0.72      0.71        80
weighted avg       0.72      0.71      0.71        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.68      0.81      0.74        26
      DRUSEN       0.90      0.81      0.85        54

    accuracy                           0.81        80
   macro avg       0.79      0.81      0.80        80
weighted avg       0.83      0.81      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.63      0.86      0.73        28
      DRUSEN       0.90      0.73      0.81        52

    accuracy                           0.78        80
   macro avg       0.77      0.79      0.77        80
weighted avg       0.81      0.78      0.78        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.76      0.86      0.81        36
      DRUSEN       0.87      0.77      0.82        44

    accuracy                           0.81        80
   macro avg       0.81      0.82      0.81        80
weighted avg       0.82      0.81      0.81        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.61      0.86      0.71        29
      DRUSEN       0.90      0.69      0.78        51

    accuracy                           0.75        80
   macro avg       0.75      0.77      0.75        80
weighted avg       0.79      0.75      0.75        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.69      0.85      0.76        26
      DRUSEN       0.92      0.81      0.86        54

    accuracy                           0.82        80
   macro avg       0.80      0.83      0.81        80
weighted avg       0.84      0.82      0.83        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.70      0.93      0.80        28
      DRUSEN       0.95      0.79      0.86        52

    accuracy                           0.84        80
   macro avg       0.83      0.86      0.83        80
weighted avg       0.87      0.84      0.84        80

----------------------

Training accuracy [0.81125]

 | Global Training Round : 2 |

| Global Round : 1 | Local Epoch : 0 | [0/6396 (0%)]	Loss: 0.421039
| Global Round : 1 | Local Epoch : 0 | [100/6396 (2%)]	Loss: 0.385279
| Global Round : 1 | Local Epoch : 0 | [200/6396 (3%)]	Loss: 0.232472
| Global Round : 1 | Local Epoch : 0 | [300/6396 (5%)]	Loss: 0.509088
| Global Round : 1 | Local Epoch : 0 | [400/6396 (6%)]	Loss: 0.290817
| Global Round : 1 | Local Epoch : 0 | [500/6396 (8%)]	Loss: 0.753436
| Global Round : 1 | Local Epoch : 0 | [600/6396 (9%)]	Loss: 0.375796
| Global Round : 1 | Local Epoch : 0 | [700/6396 (11%)]	Loss: 0.508294
| Global Round : 1 | Local Epoch : 0 | [800/6396 (12%)]	Loss: 0.280540
| Global Round : 1 | Local Epoch : 0 | [900/6396 (14%)]	Loss: 0.526691
| Global Round : 1 | Local Epoch : 0 | [1000/6396 (16%)]	Loss: 0.444922
| Global Round : 1 | Local Epoch : 0 | [1100/6396 (17%)]	Loss: 0.795961
| Global Round : 1 | Local Epoch : 0 | [1200/6396 (19%)]	Loss: 0.387280
| Global Round : 1 | Local Epoch : 0 | [1300/6396 (20%)]	Loss: 0.459468
| Global Round : 1 | Local Epoch : 0 | [1400/6396 (22%)]	Loss: 0.558918
| Global Round : 1 | Local Epoch : 0 | [1500/6396 (23%)]	Loss: 0.543801
| Global Round : 1 | Local Epoch : 0 | [1600/6396 (25%)]	Loss: 0.458371
| Global Round : 1 | Local Epoch : 0 | [1700/6396 (27%)]	Loss: 0.883943
| Global Round : 1 | Local Epoch : 0 | [1800/6396 (28%)]	Loss: 0.566821
| Global Round : 1 | Local Epoch : 0 | [1900/6396 (30%)]	Loss: 0.355285
| Global Round : 1 | Local Epoch : 0 | [2000/6396 (31%)]	Loss: 0.398784
| Global Round : 1 | Local Epoch : 0 | [2100/6396 (33%)]	Loss: 0.336008
| Global Round : 1 | Local Epoch : 0 | [2200/6396 (34%)]	Loss: 0.165703
| Global Round : 1 | Local Epoch : 0 | [2300/6396 (36%)]	Loss: 0.202288
| Global Round : 1 | Local Epoch : 0 | [2400/6396 (38%)]	Loss: 0.368210
| Global Round : 1 | Local Epoch : 0 | [2500/6396 (39%)]	Loss: 0.412871
| Global Round : 1 | Local Epoch : 0 | [2600/6396 (41%)]	Loss: 0.562647
| Global Round : 1 | Local Epoch : 0 | [2700/6396 (42%)]	Loss: 0.790582
| Global Round : 1 | Local Epoch : 0 | [2800/6396 (44%)]	Loss: 0.472733
| Global Round : 1 | Local Epoch : 0 | [2900/6396 (45%)]	Loss: 0.211800
| Global Round : 1 | Local Epoch : 0 | [3000/6396 (47%)]	Loss: 0.215170
| Global Round : 1 | Local Epoch : 0 | [3100/6396 (48%)]	Loss: 0.377417
| Global Round : 1 | Local Epoch : 0 | [3200/6396 (50%)]	Loss: 0.477074
| Global Round : 1 | Local Epoch : 0 | [3300/6396 (52%)]	Loss: 0.399443
| Global Round : 1 | Local Epoch : 0 | [3400/6396 (53%)]	Loss: 0.496692
| Global Round : 1 | Local Epoch : 0 | [3500/6396 (55%)]	Loss: 0.544558
| Global Round : 1 | Local Epoch : 0 | [3600/6396 (56%)]	Loss: 0.457478
| Global Round : 1 | Local Epoch : 0 | [3700/6396 (58%)]	Loss: 0.348807
| Global Round : 1 | Local Epoch : 0 | [3800/6396 (59%)]	Loss: 0.424860
| Global Round : 1 | Local Epoch : 0 | [3900/6396 (61%)]	Loss: 0.664660
| Global Round : 1 | Local Epoch : 0 | [4000/6396 (62%)]	Loss: 0.150034
| Global Round : 1 | Local Epoch : 0 | [4100/6396 (64%)]	Loss: 0.562355
| Global Round : 1 | Local Epoch : 0 | [4200/6396 (66%)]	Loss: 0.583964
| Global Round : 1 | Local Epoch : 0 | [4300/6396 (67%)]	Loss: 0.307935
| Global Round : 1 | Local Epoch : 0 | [4400/6396 (69%)]	Loss: 0.119470
| Global Round : 1 | Local Epoch : 0 | [4500/6396 (70%)]	Loss: 0.481704
| Global Round : 1 | Local Epoch : 0 | [4600/6396 (72%)]	Loss: 0.217544
| Global Round : 1 | Local Epoch : 0 | [4700/6396 (73%)]	Loss: 0.519684
| Global Round : 1 | Local Epoch : 0 | [4800/6396 (75%)]	Loss: 0.495025
| Global Round : 1 | Local Epoch : 0 | [4900/6396 (77%)]	Loss: 0.199415
| Global Round : 1 | Local Epoch : 0 | [5000/6396 (78%)]	Loss: 0.592455
| Global Round : 1 | Local Epoch : 0 | [5100/6396 (80%)]	Loss: 0.627946
| Global Round : 1 | Local Epoch : 0 | [5200/6396 (81%)]	Loss: 0.364836
| Global Round : 1 | Local Epoch : 0 | [5300/6396 (83%)]	Loss: 0.316994
| Global Round : 1 | Local Epoch : 0 | [5400/6396 (84%)]	Loss: 0.491380
| Global Round : 1 | Local Epoch : 0 | [5500/6396 (86%)]	Loss: 0.266753
| Global Round : 1 | Local Epoch : 0 | [5600/6396 (88%)]	Loss: 0.325459
| Global Round : 1 | Local Epoch : 0 | [5700/6396 (89%)]	Loss: 0.822586
| Global Round : 1 | Local Epoch : 0 | [5800/6396 (91%)]	Loss: 0.146420
| Global Round : 1 | Local Epoch : 0 | [5900/6396 (92%)]	Loss: 0.379914
| Global Round : 1 | Local Epoch : 0 | [6000/6396 (94%)]	Loss: 0.713544
| Global Round : 1 | Local Epoch : 0 | [6100/6396 (95%)]	Loss: 0.498539
| Global Round : 1 | Local Epoch : 0 | [6200/6396 (97%)]	Loss: 0.141190
| Global Round : 1 | Local Epoch : 0 | [6300/6396 (98%)]	Loss: 0.523171
| Global Round : 1 | Local Epoch : 1 | [0/6396 (0%)]	Loss: 0.372899
| Global Round : 1 | Local Epoch : 1 | [100/6396 (2%)]	Loss: 0.532249
| Global Round : 1 | Local Epoch : 1 | [200/6396 (3%)]	Loss: 0.265311
| Global Round : 1 | Local Epoch : 1 | [300/6396 (5%)]	Loss: 0.191929
| Global Round : 1 | Local Epoch : 1 | [400/6396 (6%)]	Loss: 0.660754
| Global Round : 1 | Local Epoch : 1 | [500/6396 (8%)]	Loss: 1.275525
| Global Round : 1 | Local Epoch : 1 | [600/6396 (9%)]	Loss: 0.431186
| Global Round : 1 | Local Epoch : 1 | [700/6396 (11%)]	Loss: 0.213904
| Global Round : 1 | Local Epoch : 1 | [800/6396 (12%)]	Loss: 0.881754
| Global Round : 1 | Local Epoch : 1 | [900/6396 (14%)]	Loss: 0.346005
| Global Round : 1 | Local Epoch : 1 | [1000/6396 (16%)]	Loss: 0.368185
| Global Round : 1 | Local Epoch : 1 | [1100/6396 (17%)]	Loss: 0.401353
| Global Round : 1 | Local Epoch : 1 | [1200/6396 (19%)]	Loss: 0.482107
| Global Round : 1 | Local Epoch : 1 | [1300/6396 (20%)]	Loss: 0.740267
| Global Round : 1 | Local Epoch : 1 | [1400/6396 (22%)]	Loss: 0.442572
| Global Round : 1 | Local Epoch : 1 | [1500/6396 (23%)]	Loss: 0.138034
| Global Round : 1 | Local Epoch : 1 | [1600/6396 (25%)]	Loss: 0.383019
| Global Round : 1 | Local Epoch : 1 | [1700/6396 (27%)]	Loss: 0.302841
| Global Round : 1 | Local Epoch : 1 | [1800/6396 (28%)]	Loss: 0.489394
| Global Round : 1 | Local Epoch : 1 | [1900/6396 (30%)]	Loss: 0.404959
| Global Round : 1 | Local Epoch : 1 | [2000/6396 (31%)]	Loss: 0.695768
| Global Round : 1 | Local Epoch : 1 | [2100/6396 (33%)]	Loss: 0.357327
| Global Round : 1 | Local Epoch : 1 | [2200/6396 (34%)]	Loss: 0.414366
| Global Round : 1 | Local Epoch : 1 | [2300/6396 (36%)]	Loss: 0.298857
| Global Round : 1 | Local Epoch : 1 | [2400/6396 (38%)]	Loss: 0.259655
| Global Round : 1 | Local Epoch : 1 | [2500/6396 (39%)]	Loss: 0.102064
| Global Round : 1 | Local Epoch : 1 | [2600/6396 (41%)]	Loss: 0.224990
| Global Round : 1 | Local Epoch : 1 | [2700/6396 (42%)]	Loss: 0.143195
| Global Round : 1 | Local Epoch : 1 | [2800/6396 (44%)]	Loss: 0.273541
| Global Round : 1 | Local Epoch : 1 | [2900/6396 (45%)]	Loss: 0.231573
| Global Round : 1 | Local Epoch : 1 | [3000/6396 (47%)]	Loss: 0.370478
| Global Round : 1 | Local Epoch : 1 | [3100/6396 (48%)]	Loss: 0.384090
| Global Round : 1 | Local Epoch : 1 | [3200/6396 (50%)]	Loss: 0.466709
| Global Round : 1 | Local Epoch : 1 | [3300/6396 (52%)]	Loss: 0.413488
| Global Round : 1 | Local Epoch : 1 | [3400/6396 (53%)]	Loss: 0.306113
| Global Round : 1 | Local Epoch : 1 | [3500/6396 (55%)]	Loss: 0.945858
| Global Round : 1 | Local Epoch : 1 | [3600/6396 (56%)]	Loss: 0.437049
| Global Round : 1 | Local Epoch : 1 | [3700/6396 (58%)]	Loss: 0.180960
| Global Round : 1 | Local Epoch : 1 | [3800/6396 (59%)]	Loss: 0.171575
| Global Round : 1 | Local Epoch : 1 | [3900/6396 (61%)]	Loss: 0.232527
| Global Round : 1 | Local Epoch : 1 | [4000/6396 (62%)]	Loss: 0.249582
| Global Round : 1 | Local Epoch : 1 | [4100/6396 (64%)]	Loss: 0.312342
| Global Round : 1 | Local Epoch : 1 | [4200/6396 (66%)]	Loss: 0.143452
| Global Round : 1 | Local Epoch : 1 | [4300/6396 (67%)]	Loss: 0.480721
| Global Round : 1 | Local Epoch : 1 | [4400/6396 (69%)]	Loss: 0.518723
| Global Round : 1 | Local Epoch : 1 | [4500/6396 (70%)]	Loss: 0.248474
| Global Round : 1 | Local Epoch : 1 | [4600/6396 (72%)]	Loss: 0.344552
| Global Round : 1 | Local Epoch : 1 | [4700/6396 (73%)]	Loss: 0.320261
| Global Round : 1 | Local Epoch : 1 | [4800/6396 (75%)]	Loss: 0.463094
| Global Round : 1 | Local Epoch : 1 | [4900/6396 (77%)]	Loss: 0.638334
| Global Round : 1 | Local Epoch : 1 | [5000/6396 (78%)]	Loss: 0.311628
| Global Round : 1 | Local Epoch : 1 | [5100/6396 (80%)]	Loss: 0.334307
| Global Round : 1 | Local Epoch : 1 | [5200/6396 (81%)]	Loss: 0.503838
| Global Round : 1 | Local Epoch : 1 | [5300/6396 (83%)]	Loss: 0.390936
| Global Round : 1 | Local Epoch : 1 | [5400/6396 (84%)]	Loss: 0.243137
| Global Round : 1 | Local Epoch : 1 | [5500/6396 (86%)]	Loss: 0.302027
| Global Round : 1 | Local Epoch : 1 | [5600/6396 (88%)]	Loss: 0.402488
| Global Round : 1 | Local Epoch : 1 | [5700/6396 (89%)]	Loss: 0.235616
| Global Round : 1 | Local Epoch : 1 | [5800/6396 (91%)]	Loss: 0.390457
| Global Round : 1 | Local Epoch : 1 | [5900/6396 (92%)]	Loss: 0.324813
| Global Round : 1 | Local Epoch : 1 | [6000/6396 (94%)]	Loss: 0.229042
| Global Round : 1 | Local Epoch : 1 | [6100/6396 (95%)]	Loss: 0.575542
| Global Round : 1 | Local Epoch : 1 | [6200/6396 (97%)]	Loss: 0.189290
| Global Round : 1 | Local Epoch : 1 | [6300/6396 (98%)]	Loss: 1.124984
| Global Round : 1 | Local Epoch : 2 | [0/6396 (0%)]	Loss: 0.434267
| Global Round : 1 | Local Epoch : 2 | [100/6396 (2%)]	Loss: 0.224095
| Global Round : 1 | Local Epoch : 2 | [200/6396 (3%)]	Loss: 0.458872
| Global Round : 1 | Local Epoch : 2 | [300/6396 (5%)]	Loss: 0.398305
| Global Round : 1 | Local Epoch : 2 | [400/6396 (6%)]	Loss: 0.645565
| Global Round : 1 | Local Epoch : 2 | [500/6396 (8%)]	Loss: 0.404192
| Global Round : 1 | Local Epoch : 2 | [600/6396 (9%)]	Loss: 0.637550
| Global Round : 1 | Local Epoch : 2 | [700/6396 (11%)]	Loss: 0.528158
| Global Round : 1 | Local Epoch : 2 | [800/6396 (12%)]	Loss: 0.196282
| Global Round : 1 | Local Epoch : 2 | [900/6396 (14%)]	Loss: 0.430259
| Global Round : 1 | Local Epoch : 2 | [1000/6396 (16%)]	Loss: 0.286352
| Global Round : 1 | Local Epoch : 2 | [1100/6396 (17%)]	Loss: 0.196130
| Global Round : 1 | Local Epoch : 2 | [1200/6396 (19%)]	Loss: 0.486714
| Global Round : 1 | Local Epoch : 2 | [1300/6396 (20%)]	Loss: 0.263841
| Global Round : 1 | Local Epoch : 2 | [1400/6396 (22%)]	Loss: 0.279101
| Global Round : 1 | Local Epoch : 2 | [1500/6396 (23%)]	Loss: 0.386027
| Global Round : 1 | Local Epoch : 2 | [1600/6396 (25%)]	Loss: 0.224672
| Global Round : 1 | Local Epoch : 2 | [1700/6396 (27%)]	Loss: 0.331819
| Global Round : 1 | Local Epoch : 2 | [1800/6396 (28%)]	Loss: 0.223356
| Global Round : 1 | Local Epoch : 2 | [1900/6396 (30%)]	Loss: 0.221550
| Global Round : 1 | Local Epoch : 2 | [2000/6396 (31%)]	Loss: 0.219753
| Global Round : 1 | Local Epoch : 2 | [2100/6396 (33%)]	Loss: 0.313676
| Global Round : 1 | Local Epoch : 2 | [2200/6396 (34%)]	Loss: 0.411425
| Global Round : 1 | Local Epoch : 2 | [2300/6396 (36%)]	Loss: 0.234324
| Global Round : 1 | Local Epoch : 2 | [2400/6396 (38%)]	Loss: 0.383707
| Global Round : 1 | Local Epoch : 2 | [2500/6396 (39%)]	Loss: 0.404231
| Global Round : 1 | Local Epoch : 2 | [2600/6396 (41%)]	Loss: 0.154234
| Global Round : 1 | Local Epoch : 2 | [2700/6396 (42%)]	Loss: 0.577270
| Global Round : 1 | Local Epoch : 2 | [2800/6396 (44%)]	Loss: 0.278838
| Global Round : 1 | Local Epoch : 2 | [2900/6396 (45%)]	Loss: 0.350420
| Global Round : 1 | Local Epoch : 2 | [3000/6396 (47%)]	Loss: 0.464689
| Global Round : 1 | Local Epoch : 2 | [3100/6396 (48%)]	Loss: 0.358010
| Global Round : 1 | Local Epoch : 2 | [3200/6396 (50%)]	Loss: 0.235931
| Global Round : 1 | Local Epoch : 2 | [3300/6396 (52%)]	Loss: 0.229894
| Global Round : 1 | Local Epoch : 2 | [3400/6396 (53%)]	Loss: 0.569624
| Global Round : 1 | Local Epoch : 2 | [3500/6396 (55%)]	Loss: 0.153508
| Global Round : 1 | Local Epoch : 2 | [3600/6396 (56%)]	Loss: 0.221670
| Global Round : 1 | Local Epoch : 2 | [3700/6396 (58%)]	Loss: 0.413279
| Global Round : 1 | Local Epoch : 2 | [3800/6396 (59%)]	Loss: 0.220795
| Global Round : 1 | Local Epoch : 2 | [3900/6396 (61%)]	Loss: 0.255090
| Global Round : 1 | Local Epoch : 2 | [4000/6396 (62%)]	Loss: 0.523197
| Global Round : 1 | Local Epoch : 2 | [4100/6396 (64%)]	Loss: 0.567630
| Global Round : 1 | Local Epoch : 2 | [4200/6396 (66%)]	Loss: 0.382316
| Global Round : 1 | Local Epoch : 2 | [4300/6396 (67%)]	Loss: 0.304282
| Global Round : 1 | Local Epoch : 2 | [4400/6396 (69%)]	Loss: 0.183459
| Global Round : 1 | Local Epoch : 2 | [4500/6396 (70%)]	Loss: 0.485025
| Global Round : 1 | Local Epoch : 2 | [4600/6396 (72%)]	Loss: 0.179428
| Global Round : 1 | Local Epoch : 2 | [4700/6396 (73%)]	Loss: 0.399831
| Global Round : 1 | Local Epoch : 2 | [4800/6396 (75%)]	Loss: 0.481195
| Global Round : 1 | Local Epoch : 2 | [4900/6396 (77%)]	Loss: 0.622495
| Global Round : 1 | Local Epoch : 2 | [5000/6396 (78%)]	Loss: 0.391207
| Global Round : 1 | Local Epoch : 2 | [5100/6396 (80%)]	Loss: 0.133048
| Global Round : 1 | Local Epoch : 2 | [5200/6396 (81%)]	Loss: 0.412014
| Global Round : 1 | Local Epoch : 2 | [5300/6396 (83%)]	Loss: 0.298248
| Global Round : 1 | Local Epoch : 2 | [5400/6396 (84%)]	Loss: 0.602820
| Global Round : 1 | Local Epoch : 2 | [5500/6396 (86%)]	Loss: 0.281447
| Global Round : 1 | Local Epoch : 2 | [5600/6396 (88%)]	Loss: 0.547026
| Global Round : 1 | Local Epoch : 2 | [5700/6396 (89%)]	Loss: 0.446094
| Global Round : 1 | Local Epoch : 2 | [5800/6396 (91%)]	Loss: 0.192996
| Global Round : 1 | Local Epoch : 2 | [5900/6396 (92%)]	Loss: 0.280775
| Global Round : 1 | Local Epoch : 2 | [6000/6396 (94%)]	Loss: 0.230576
| Global Round : 1 | Local Epoch : 2 | [6100/6396 (95%)]	Loss: 1.119886
| Global Round : 1 | Local Epoch : 2 | [6200/6396 (97%)]	Loss: 0.559855
| Global Round : 1 | Local Epoch : 2 | [6300/6396 (98%)]	Loss: 0.554243
| Global Round : 1 | Local Epoch : 3 | [0/6396 (0%)]	Loss: 0.219244
| Global Round : 1 | Local Epoch : 3 | [100/6396 (2%)]	Loss: 0.282778
| Global Round : 1 | Local Epoch : 3 | [200/6396 (3%)]	Loss: 0.309038
| Global Round : 1 | Local Epoch : 3 | [300/6396 (5%)]	Loss: 0.426093
| Global Round : 1 | Local Epoch : 3 | [400/6396 (6%)]	Loss: 0.388075
| Global Round : 1 | Local Epoch : 3 | [500/6396 (8%)]	Loss: 0.218985
| Global Round : 1 | Local Epoch : 3 | [600/6396 (9%)]	Loss: 0.679437
| Global Round : 1 | Local Epoch : 3 | [700/6396 (11%)]	Loss: 0.211696
| Global Round : 1 | Local Epoch : 3 | [800/6396 (12%)]	Loss: 0.225720
| Global Round : 1 | Local Epoch : 3 | [900/6396 (14%)]	Loss: 0.100128
| Global Round : 1 | Local Epoch : 3 | [1000/6396 (16%)]	Loss: 0.427379
| Global Round : 1 | Local Epoch : 3 | [1100/6396 (17%)]	Loss: 0.124565
| Global Round : 1 | Local Epoch : 3 | [1200/6396 (19%)]	Loss: 0.195825
| Global Round : 1 | Local Epoch : 3 | [1300/6396 (20%)]	Loss: 0.193225
| Global Round : 1 | Local Epoch : 3 | [1400/6396 (22%)]	Loss: 0.058417
| Global Round : 1 | Local Epoch : 3 | [1500/6396 (23%)]	Loss: 0.494548
| Global Round : 1 | Local Epoch : 3 | [1600/6396 (25%)]	Loss: 0.137779
| Global Round : 1 | Local Epoch : 3 | [1700/6396 (27%)]	Loss: 0.136307
| Global Round : 1 | Local Epoch : 3 | [1800/6396 (28%)]	Loss: 0.541794
| Global Round : 1 | Local Epoch : 3 | [1900/6396 (30%)]	Loss: 0.256217
| Global Round : 1 | Local Epoch : 3 | [2000/6396 (31%)]	Loss: 0.364171
| Global Round : 1 | Local Epoch : 3 | [2100/6396 (33%)]	Loss: 0.475344
| Global Round : 1 | Local Epoch : 3 | [2200/6396 (34%)]	Loss: 0.157722
| Global Round : 1 | Local Epoch : 3 | [2300/6396 (36%)]	Loss: 0.431884
| Global Round : 1 | Local Epoch : 3 | [2400/6396 (38%)]	Loss: 0.921388
| Global Round : 1 | Local Epoch : 3 | [2500/6396 (39%)]	Loss: 0.291094
| Global Round : 1 | Local Epoch : 3 | [2600/6396 (41%)]	Loss: 0.276415
| Global Round : 1 | Local Epoch : 3 | [2700/6396 (42%)]	Loss: 0.270822
| Global Round : 1 | Local Epoch : 3 | [2800/6396 (44%)]	Loss: 0.277208
| Global Round : 1 | Local Epoch : 3 | [2900/6396 (45%)]	Loss: 0.335371
| Global Round : 1 | Local Epoch : 3 | [3000/6396 (47%)]	Loss: 0.258225
| Global Round : 1 | Local Epoch : 3 | [3100/6396 (48%)]	Loss: 0.513746
| Global Round : 1 | Local Epoch : 3 | [3200/6396 (50%)]	Loss: 0.116684
| Global Round : 1 | Local Epoch : 3 | [3300/6396 (52%)]	Loss: 0.128684
| Global Round : 1 | Local Epoch : 3 | [3400/6396 (53%)]	Loss: 0.299254
| Global Round : 1 | Local Epoch : 3 | [3500/6396 (55%)]	Loss: 0.392342
| Global Round : 1 | Local Epoch : 3 | [3600/6396 (56%)]	Loss: 0.154842
| Global Round : 1 | Local Epoch : 3 | [3700/6396 (58%)]	Loss: 0.504687
| Global Round : 1 | Local Epoch : 3 | [3800/6396 (59%)]	Loss: 0.997101
| Global Round : 1 | Local Epoch : 3 | [3900/6396 (61%)]	Loss: 0.373035
| Global Round : 1 | Local Epoch : 3 | [4000/6396 (62%)]	Loss: 0.255082
| Global Round : 1 | Local Epoch : 3 | [4100/6396 (64%)]	Loss: 0.304001
| Global Round : 1 | Local Epoch : 3 | [4200/6396 (66%)]	Loss: 0.209588
| Global Round : 1 | Local Epoch : 3 | [4300/6396 (67%)]	Loss: 0.715234
| Global Round : 1 | Local Epoch : 3 | [4400/6396 (69%)]	Loss: 0.135496
| Global Round : 1 | Local Epoch : 3 | [4500/6396 (70%)]	Loss: 0.349820
| Global Round : 1 | Local Epoch : 3 | [4600/6396 (72%)]	Loss: 0.193497
| Global Round : 1 | Local Epoch : 3 | [4700/6396 (73%)]	Loss: 0.241326
| Global Round : 1 | Local Epoch : 3 | [4800/6396 (75%)]	Loss: 0.159308
| Global Round : 1 | Local Epoch : 3 | [4900/6396 (77%)]	Loss: 0.358211
| Global Round : 1 | Local Epoch : 3 | [5000/6396 (78%)]	Loss: 0.363347
| Global Round : 1 | Local Epoch : 3 | [5100/6396 (80%)]	Loss: 0.418704
| Global Round : 1 | Local Epoch : 3 | [5200/6396 (81%)]	Loss: 0.184138
| Global Round : 1 | Local Epoch : 3 | [5300/6396 (83%)]	Loss: 0.612763
| Global Round : 1 | Local Epoch : 3 | [5400/6396 (84%)]	Loss: 0.395107
| Global Round : 1 | Local Epoch : 3 | [5500/6396 (86%)]	Loss: 0.199141
| Global Round : 1 | Local Epoch : 3 | [5600/6396 (88%)]	Loss: 0.095636
| Global Round : 1 | Local Epoch : 3 | [5700/6396 (89%)]	Loss: 0.317433
| Global Round : 1 | Local Epoch : 3 | [5800/6396 (91%)]	Loss: 0.221480
| Global Round : 1 | Local Epoch : 3 | [5900/6396 (92%)]	Loss: 0.531673
| Global Round : 1 | Local Epoch : 3 | [6000/6396 (94%)]	Loss: 0.331540
| Global Round : 1 | Local Epoch : 3 | [6100/6396 (95%)]	Loss: 0.273767
| Global Round : 1 | Local Epoch : 3 | [6200/6396 (97%)]	Loss: 0.386160
| Global Round : 1 | Local Epoch : 3 | [6300/6396 (98%)]	Loss: 0.212354
| Global Round : 1 | Local Epoch : 4 | [0/6396 (0%)]	Loss: 0.117198
| Global Round : 1 | Local Epoch : 4 | [100/6396 (2%)]	Loss: 0.150931
| Global Round : 1 | Local Epoch : 4 | [200/6396 (3%)]	Loss: 0.071894
| Global Round : 1 | Local Epoch : 4 | [300/6396 (5%)]	Loss: 0.147487
| Global Round : 1 | Local Epoch : 4 | [400/6396 (6%)]	Loss: 0.430483
| Global Round : 1 | Local Epoch : 4 | [500/6396 (8%)]	Loss: 0.136914
| Global Round : 1 | Local Epoch : 4 | [600/6396 (9%)]	Loss: 0.160906
| Global Round : 1 | Local Epoch : 4 | [700/6396 (11%)]	Loss: 0.092586
| Global Round : 1 | Local Epoch : 4 | [800/6396 (12%)]	Loss: 0.178364
| Global Round : 1 | Local Epoch : 4 | [900/6396 (14%)]	Loss: 0.084994
| Global Round : 1 | Local Epoch : 4 | [1000/6396 (16%)]	Loss: 0.093761
| Global Round : 1 | Local Epoch : 4 | [1100/6396 (17%)]	Loss: 0.153188
| Global Round : 1 | Local Epoch : 4 | [1200/6396 (19%)]	Loss: 0.253140
| Global Round : 1 | Local Epoch : 4 | [1300/6396 (20%)]	Loss: 0.235579
| Global Round : 1 | Local Epoch : 4 | [1400/6396 (22%)]	Loss: 0.136645
| Global Round : 1 | Local Epoch : 4 | [1500/6396 (23%)]	Loss: 0.427316
| Global Round : 1 | Local Epoch : 4 | [1600/6396 (25%)]	Loss: 0.607730
| Global Round : 1 | Local Epoch : 4 | [1700/6396 (27%)]	Loss: 0.489784
| Global Round : 1 | Local Epoch : 4 | [1800/6396 (28%)]	Loss: 0.103265
| Global Round : 1 | Local Epoch : 4 | [1900/6396 (30%)]	Loss: 0.552643
| Global Round : 1 | Local Epoch : 4 | [2000/6396 (31%)]	Loss: 0.075133
| Global Round : 1 | Local Epoch : 4 | [2100/6396 (33%)]	Loss: 0.139052
| Global Round : 1 | Local Epoch : 4 | [2200/6396 (34%)]	Loss: 0.313759
| Global Round : 1 | Local Epoch : 4 | [2300/6396 (36%)]	Loss: 0.109790
| Global Round : 1 | Local Epoch : 4 | [2400/6396 (38%)]	Loss: 0.375715
| Global Round : 1 | Local Epoch : 4 | [2500/6396 (39%)]	Loss: 0.421908
| Global Round : 1 | Local Epoch : 4 | [2600/6396 (41%)]	Loss: 0.227380
| Global Round : 1 | Local Epoch : 4 | [2700/6396 (42%)]	Loss: 0.304125
| Global Round : 1 | Local Epoch : 4 | [2800/6396 (44%)]	Loss: 0.696934
| Global Round : 1 | Local Epoch : 4 | [2900/6396 (45%)]	Loss: 0.068213
| Global Round : 1 | Local Epoch : 4 | [3000/6396 (47%)]	Loss: 0.262235
| Global Round : 1 | Local Epoch : 4 | [3100/6396 (48%)]	Loss: 0.603119
| Global Round : 1 | Local Epoch : 4 | [3200/6396 (50%)]	Loss: 0.252838
| Global Round : 1 | Local Epoch : 4 | [3300/6396 (52%)]	Loss: 0.104912
| Global Round : 1 | Local Epoch : 4 | [3400/6396 (53%)]	Loss: 0.300332
| Global Round : 1 | Local Epoch : 4 | [3500/6396 (55%)]	Loss: 0.248568
| Global Round : 1 | Local Epoch : 4 | [3600/6396 (56%)]	Loss: 1.083112
| Global Round : 1 | Local Epoch : 4 | [3700/6396 (58%)]	Loss: 0.306614
| Global Round : 1 | Local Epoch : 4 | [3800/6396 (59%)]	Loss: 0.109547
| Global Round : 1 | Local Epoch : 4 | [3900/6396 (61%)]	Loss: 0.061883
| Global Round : 1 | Local Epoch : 4 | [4000/6396 (62%)]	Loss: 0.365111
| Global Round : 1 | Local Epoch : 4 | [4100/6396 (64%)]	Loss: 0.407256
| Global Round : 1 | Local Epoch : 4 | [4200/6396 (66%)]	Loss: 0.405024
| Global Round : 1 | Local Epoch : 4 | [4300/6396 (67%)]	Loss: 0.245952
| Global Round : 1 | Local Epoch : 4 | [4400/6396 (69%)]	Loss: 0.204485
| Global Round : 1 | Local Epoch : 4 | [4500/6396 (70%)]	Loss: 0.336687
| Global Round : 1 | Local Epoch : 4 | [4600/6396 (72%)]	Loss: 0.337111
| Global Round : 1 | Local Epoch : 4 | [4700/6396 (73%)]	Loss: 0.213142
| Global Round : 1 | Local Epoch : 4 | [4800/6396 (75%)]	Loss: 0.336792
| Global Round : 1 | Local Epoch : 4 | [4900/6396 (77%)]	Loss: 0.207001
| Global Round : 1 | Local Epoch : 4 | [5000/6396 (78%)]	Loss: 0.343331
| Global Round : 1 | Local Epoch : 4 | [5100/6396 (80%)]	Loss: 0.399754
| Global Round : 1 | Local Epoch : 4 | [5200/6396 (81%)]	Loss: 0.350495
| Global Round : 1 | Local Epoch : 4 | [5300/6396 (83%)]	Loss: 0.376809
| Global Round : 1 | Local Epoch : 4 | [5400/6396 (84%)]	Loss: 0.063343
| Global Round : 1 | Local Epoch : 4 | [5500/6396 (86%)]	Loss: 0.437048
| Global Round : 1 | Local Epoch : 4 | [5600/6396 (88%)]	Loss: 0.057249
| Global Round : 1 | Local Epoch : 4 | [5700/6396 (89%)]	Loss: 0.149463
| Global Round : 1 | Local Epoch : 4 | [5800/6396 (91%)]	Loss: 0.619323
| Global Round : 1 | Local Epoch : 4 | [5900/6396 (92%)]	Loss: 0.252158
| Global Round : 1 | Local Epoch : 4 | [6000/6396 (94%)]	Loss: 0.147898
| Global Round : 1 | Local Epoch : 4 | [6100/6396 (95%)]	Loss: 0.558369
| Global Round : 1 | Local Epoch : 4 | [6200/6396 (97%)]	Loss: 0.090587
| Global Round : 1 | Local Epoch : 4 | [6300/6396 (98%)]	Loss: 0.495554
----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.79      0.81        34
         DME       0.85      0.87      0.86        46

    accuracy                           0.84        80
   macro avg       0.83      0.83      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.86      0.84        37
         DME       0.88      0.84      0.86        43

    accuracy                           0.85        80
   macro avg       0.85      0.85      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.83      0.85        41
         DME       0.83      0.87      0.85        39

    accuracy                           0.85        80
   macro avg       0.85      0.85      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.86      0.83        42
         DME       0.83      0.76      0.79        38

    accuracy                           0.81        80
   macro avg       0.81      0.81      0.81        80
weighted avg       0.81      0.81      0.81        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.83      0.82        30
         DME       0.90      0.88      0.89        50

    accuracy                           0.86        80
   macro avg       0.85      0.86      0.85        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.68      0.84      0.75        31
         DME       0.88      0.76      0.81        49

    accuracy                           0.79        80
   macro avg       0.78      0.80      0.78        80
weighted avg       0.80      0.79      0.79        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.83      0.83        41
         DME       0.82      0.82      0.82        39

    accuracy                           0.82        80
   macro avg       0.82      0.82      0.82        80
weighted avg       0.82      0.82      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.71      0.88      0.78        33
         DME       0.90      0.74      0.81        47

    accuracy                           0.80        80
   macro avg       0.80      0.81      0.80        80
weighted avg       0.82      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.75      0.86      0.80        28
         DME       0.92      0.85      0.88        52

    accuracy                           0.85        80
   macro avg       0.83      0.85      0.84        80
weighted avg       0.86      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.78      0.78      0.78        37
         DME       0.81      0.81      0.81        43

    accuracy                           0.80        80
   macro avg       0.80      0.80      0.80        80
weighted avg       0.80      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.79      0.81        34
      DRUSEN       0.85      0.87      0.86        46

    accuracy                           0.84        80
   macro avg       0.83      0.83      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.86      0.84        37
      DRUSEN       0.88      0.84      0.86        43

    accuracy                           0.85        80
   macro avg       0.85      0.85      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.83      0.85        41
      DRUSEN       0.83      0.87      0.85        39

    accuracy                           0.85        80
   macro avg       0.85      0.85      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.86      0.83        42
      DRUSEN       0.83      0.76      0.79        38

    accuracy                           0.81        80
   macro avg       0.81      0.81      0.81        80
weighted avg       0.81      0.81      0.81        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.83      0.82        30
      DRUSEN       0.90      0.88      0.89        50

    accuracy                           0.86        80
   macro avg       0.85      0.86      0.85        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.68      0.84      0.75        31
      DRUSEN       0.88      0.76      0.81        49

    accuracy                           0.79        80
   macro avg       0.78      0.80      0.78        80
weighted avg       0.80      0.79      0.79        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.83      0.83        41
      DRUSEN       0.82      0.82      0.82        39

    accuracy                           0.82        80
   macro avg       0.82      0.82      0.82        80
weighted avg       0.82      0.82      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.71      0.88      0.78        33
      DRUSEN       0.90      0.74      0.81        47

    accuracy                           0.80        80
   macro avg       0.80      0.81      0.80        80
weighted avg       0.82      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.75      0.86      0.80        28
      DRUSEN       0.92      0.85      0.88        52

    accuracy                           0.85        80
   macro avg       0.83      0.85      0.84        80
weighted avg       0.86      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.78      0.78      0.78        37
      DRUSEN       0.81      0.81      0.81        43

    accuracy                           0.80        80
   macro avg       0.80      0.80      0.80        80
weighted avg       0.80      0.80      0.80        80

----------------------

Training accuracy [0.81125, 0.8275]
 
Avg Training Stats after 2 global rounds:
Training Loss : 0.46898397582175677
Train Accuracy: 82.75% 


 | Global Training Round : 3 |

| Global Round : 2 | Local Epoch : 0 | [0/6396 (0%)]	Loss: 0.163265
| Global Round : 2 | Local Epoch : 0 | [100/6396 (2%)]	Loss: 0.336043
| Global Round : 2 | Local Epoch : 0 | [200/6396 (3%)]	Loss: 0.489075
| Global Round : 2 | Local Epoch : 0 | [300/6396 (5%)]	Loss: 0.234547
| Global Round : 2 | Local Epoch : 0 | [400/6396 (6%)]	Loss: 0.175579
| Global Round : 2 | Local Epoch : 0 | [500/6396 (8%)]	Loss: 0.166073
| Global Round : 2 | Local Epoch : 0 | [600/6396 (9%)]	Loss: 0.572860
| Global Round : 2 | Local Epoch : 0 | [700/6396 (11%)]	Loss: 0.448281
| Global Round : 2 | Local Epoch : 0 | [800/6396 (12%)]	Loss: 0.394799
| Global Round : 2 | Local Epoch : 0 | [900/6396 (14%)]	Loss: 0.462381
| Global Round : 2 | Local Epoch : 0 | [1000/6396 (16%)]	Loss: 0.148757
| Global Round : 2 | Local Epoch : 0 | [1100/6396 (17%)]	Loss: 0.191038
| Global Round : 2 | Local Epoch : 0 | [1200/6396 (19%)]	Loss: 0.133175
| Global Round : 2 | Local Epoch : 0 | [1300/6396 (20%)]	Loss: 0.251725
| Global Round : 2 | Local Epoch : 0 | [1400/6396 (22%)]	Loss: 0.208462
| Global Round : 2 | Local Epoch : 0 | [1500/6396 (23%)]	Loss: 0.230754
| Global Round : 2 | Local Epoch : 0 | [1600/6396 (25%)]	Loss: 0.108687
| Global Round : 2 | Local Epoch : 0 | [1700/6396 (27%)]	Loss: 0.075242
| Global Round : 2 | Local Epoch : 0 | [1800/6396 (28%)]	Loss: 0.195995
| Global Round : 2 | Local Epoch : 0 | [1900/6396 (30%)]	Loss: 0.436237
| Global Round : 2 | Local Epoch : 0 | [2000/6396 (31%)]	Loss: 0.238372
| Global Round : 2 | Local Epoch : 0 | [2100/6396 (33%)]	Loss: 0.171806
| Global Round : 2 | Local Epoch : 0 | [2200/6396 (34%)]	Loss: 0.184237
| Global Round : 2 | Local Epoch : 0 | [2300/6396 (36%)]	Loss: 0.546130
| Global Round : 2 | Local Epoch : 0 | [2400/6396 (38%)]	Loss: 0.408312
| Global Round : 2 | Local Epoch : 0 | [2500/6396 (39%)]	Loss: 0.260170
| Global Round : 2 | Local Epoch : 0 | [2600/6396 (41%)]	Loss: 0.194173
| Global Round : 2 | Local Epoch : 0 | [2700/6396 (42%)]	Loss: 0.123052
| Global Round : 2 | Local Epoch : 0 | [2800/6396 (44%)]	Loss: 0.599949
| Global Round : 2 | Local Epoch : 0 | [2900/6396 (45%)]	Loss: 0.196531
| Global Round : 2 | Local Epoch : 0 | [3000/6396 (47%)]	Loss: 0.218420
| Global Round : 2 | Local Epoch : 0 | [3100/6396 (48%)]	Loss: 0.521120
| Global Round : 2 | Local Epoch : 0 | [3200/6396 (50%)]	Loss: 0.240446
| Global Round : 2 | Local Epoch : 0 | [3300/6396 (52%)]	Loss: 0.104583
| Global Round : 2 | Local Epoch : 0 | [3400/6396 (53%)]	Loss: 0.270128
| Global Round : 2 | Local Epoch : 0 | [3500/6396 (55%)]	Loss: 0.253254
| Global Round : 2 | Local Epoch : 0 | [3600/6396 (56%)]	Loss: 0.241310
| Global Round : 2 | Local Epoch : 0 | [3700/6396 (58%)]	Loss: 0.127388
| Global Round : 2 | Local Epoch : 0 | [3800/6396 (59%)]	Loss: 0.174353
| Global Round : 2 | Local Epoch : 0 | [3900/6396 (61%)]	Loss: 0.366271
| Global Round : 2 | Local Epoch : 0 | [4000/6396 (62%)]	Loss: 0.129094
| Global Round : 2 | Local Epoch : 0 | [4100/6396 (64%)]	Loss: 0.353796
| Global Round : 2 | Local Epoch : 0 | [4200/6396 (66%)]	Loss: 0.211587
| Global Round : 2 | Local Epoch : 0 | [4300/6396 (67%)]	Loss: 0.614585
| Global Round : 2 | Local Epoch : 0 | [4400/6396 (69%)]	Loss: 0.482085
| Global Round : 2 | Local Epoch : 0 | [4500/6396 (70%)]	Loss: 0.100873
| Global Round : 2 | Local Epoch : 0 | [4600/6396 (72%)]	Loss: 0.241529
| Global Round : 2 | Local Epoch : 0 | [4700/6396 (73%)]	Loss: 0.218793
| Global Round : 2 | Local Epoch : 0 | [4800/6396 (75%)]	Loss: 0.771768
| Global Round : 2 | Local Epoch : 0 | [4900/6396 (77%)]	Loss: 0.107463
| Global Round : 2 | Local Epoch : 0 | [5000/6396 (78%)]	Loss: 0.398518
| Global Round : 2 | Local Epoch : 0 | [5100/6396 (80%)]	Loss: 0.195013
| Global Round : 2 | Local Epoch : 0 | [5200/6396 (81%)]	Loss: 0.241401
| Global Round : 2 | Local Epoch : 0 | [5300/6396 (83%)]	Loss: 0.347791
| Global Round : 2 | Local Epoch : 0 | [5400/6396 (84%)]	Loss: 0.239119
| Global Round : 2 | Local Epoch : 0 | [5500/6396 (86%)]	Loss: 0.580656
| Global Round : 2 | Local Epoch : 0 | [5600/6396 (88%)]	Loss: 0.177418
| Global Round : 2 | Local Epoch : 0 | [5700/6396 (89%)]	Loss: 0.185222
| Global Round : 2 | Local Epoch : 0 | [5800/6396 (91%)]	Loss: 0.383862
| Global Round : 2 | Local Epoch : 0 | [5900/6396 (92%)]	Loss: 0.848791
| Global Round : 2 | Local Epoch : 0 | [6000/6396 (94%)]	Loss: 0.058703
| Global Round : 2 | Local Epoch : 0 | [6100/6396 (95%)]	Loss: 0.343590
| Global Round : 2 | Local Epoch : 0 | [6200/6396 (97%)]	Loss: 0.048008
| Global Round : 2 | Local Epoch : 0 | [6300/6396 (98%)]	Loss: 0.525707
| Global Round : 2 | Local Epoch : 1 | [0/6396 (0%)]	Loss: 0.089774
| Global Round : 2 | Local Epoch : 1 | [100/6396 (2%)]	Loss: 0.298412
| Global Round : 2 | Local Epoch : 1 | [200/6396 (3%)]	Loss: 0.151800
| Global Round : 2 | Local Epoch : 1 | [300/6396 (5%)]	Loss: 0.252697
| Global Round : 2 | Local Epoch : 1 | [400/6396 (6%)]	Loss: 0.297786
| Global Round : 2 | Local Epoch : 1 | [500/6396 (8%)]	Loss: 0.363719
| Global Round : 2 | Local Epoch : 1 | [600/6396 (9%)]	Loss: 0.335243
| Global Round : 2 | Local Epoch : 1 | [700/6396 (11%)]	Loss: 0.081318
| Global Round : 2 | Local Epoch : 1 | [800/6396 (12%)]	Loss: 0.207391
| Global Round : 2 | Local Epoch : 1 | [900/6396 (14%)]	Loss: 0.170350
| Global Round : 2 | Local Epoch : 1 | [1000/6396 (16%)]	Loss: 0.216731
| Global Round : 2 | Local Epoch : 1 | [1100/6396 (17%)]	Loss: 0.268579
| Global Round : 2 | Local Epoch : 1 | [1200/6396 (19%)]	Loss: 0.623337
| Global Round : 2 | Local Epoch : 1 | [1300/6396 (20%)]	Loss: 0.381374
| Global Round : 2 | Local Epoch : 1 | [1400/6396 (22%)]	Loss: 0.461382
| Global Round : 2 | Local Epoch : 1 | [1500/6396 (23%)]	Loss: 0.062138
| Global Round : 2 | Local Epoch : 1 | [1600/6396 (25%)]	Loss: 0.368379
| Global Round : 2 | Local Epoch : 1 | [1700/6396 (27%)]	Loss: 0.105674
| Global Round : 2 | Local Epoch : 1 | [1800/6396 (28%)]	Loss: 0.128341
| Global Round : 2 | Local Epoch : 1 | [1900/6396 (30%)]	Loss: 0.447651
| Global Round : 2 | Local Epoch : 1 | [2000/6396 (31%)]	Loss: 0.168703
| Global Round : 2 | Local Epoch : 1 | [2100/6396 (33%)]	Loss: 0.289896
| Global Round : 2 | Local Epoch : 1 | [2200/6396 (34%)]	Loss: 0.152524
| Global Round : 2 | Local Epoch : 1 | [2300/6396 (36%)]	Loss: 0.466672
| Global Round : 2 | Local Epoch : 1 | [2400/6396 (38%)]	Loss: 0.168784
| Global Round : 2 | Local Epoch : 1 | [2500/6396 (39%)]	Loss: 0.179842
| Global Round : 2 | Local Epoch : 1 | [2600/6396 (41%)]	Loss: 0.295800
| Global Round : 2 | Local Epoch : 1 | [2700/6396 (42%)]	Loss: 0.235816
| Global Round : 2 | Local Epoch : 1 | [2800/6396 (44%)]	Loss: 0.296978
| Global Round : 2 | Local Epoch : 1 | [2900/6396 (45%)]	Loss: 0.516421
| Global Round : 2 | Local Epoch : 1 | [3000/6396 (47%)]	Loss: 0.046757
| Global Round : 2 | Local Epoch : 1 | [3100/6396 (48%)]	Loss: 0.463986
| Global Round : 2 | Local Epoch : 1 | [3200/6396 (50%)]	Loss: 0.640249
| Global Round : 2 | Local Epoch : 1 | [3300/6396 (52%)]	Loss: 0.104814
| Global Round : 2 | Local Epoch : 1 | [3400/6396 (53%)]	Loss: 0.125540
| Global Round : 2 | Local Epoch : 1 | [3500/6396 (55%)]	Loss: 0.180901
| Global Round : 2 | Local Epoch : 1 | [3600/6396 (56%)]	Loss: 0.137098
| Global Round : 2 | Local Epoch : 1 | [3700/6396 (58%)]	Loss: 0.553836
| Global Round : 2 | Local Epoch : 1 | [3800/6396 (59%)]	Loss: 0.297929
| Global Round : 2 | Local Epoch : 1 | [3900/6396 (61%)]	Loss: 0.277305
| Global Round : 2 | Local Epoch : 1 | [4000/6396 (62%)]	Loss: 0.238905
| Global Round : 2 | Local Epoch : 1 | [4100/6396 (64%)]	Loss: 0.178523
| Global Round : 2 | Local Epoch : 1 | [4200/6396 (66%)]	Loss: 0.110704
| Global Round : 2 | Local Epoch : 1 | [4300/6396 (67%)]	Loss: 0.148332
| Global Round : 2 | Local Epoch : 1 | [4400/6396 (69%)]	Loss: 0.190628
| Global Round : 2 | Local Epoch : 1 | [4500/6396 (70%)]	Loss: 0.114695
| Global Round : 2 | Local Epoch : 1 | [4600/6396 (72%)]	Loss: 0.431747
| Global Round : 2 | Local Epoch : 1 | [4700/6396 (73%)]	Loss: 0.163469
| Global Round : 2 | Local Epoch : 1 | [4800/6396 (75%)]	Loss: 0.099160
| Global Round : 2 | Local Epoch : 1 | [4900/6396 (77%)]	Loss: 0.170732
| Global Round : 2 | Local Epoch : 1 | [5000/6396 (78%)]	Loss: 0.170072
| Global Round : 2 | Local Epoch : 1 | [5100/6396 (80%)]	Loss: 0.691978
| Global Round : 2 | Local Epoch : 1 | [5200/6396 (81%)]	Loss: 0.171061
| Global Round : 2 | Local Epoch : 1 | [5300/6396 (83%)]	Loss: 0.164068
| Global Round : 2 | Local Epoch : 1 | [5400/6396 (84%)]	Loss: 0.380018
| Global Round : 2 | Local Epoch : 1 | [5500/6396 (86%)]	Loss: 0.252459
| Global Round : 2 | Local Epoch : 1 | [5600/6396 (88%)]	Loss: 0.320550
| Global Round : 2 | Local Epoch : 1 | [5700/6396 (89%)]	Loss: 0.391964
| Global Round : 2 | Local Epoch : 1 | [5800/6396 (91%)]	Loss: 0.232702
| Global Round : 2 | Local Epoch : 1 | [5900/6396 (92%)]	Loss: 0.296757
| Global Round : 2 | Local Epoch : 1 | [6000/6396 (94%)]	Loss: 0.512540
| Global Round : 2 | Local Epoch : 1 | [6100/6396 (95%)]	Loss: 0.510472
| Global Round : 2 | Local Epoch : 1 | [6200/6396 (97%)]	Loss: 0.282713
| Global Round : 2 | Local Epoch : 1 | [6300/6396 (98%)]	Loss: 0.278557
| Global Round : 2 | Local Epoch : 2 | [0/6396 (0%)]	Loss: 0.179394
| Global Round : 2 | Local Epoch : 2 | [100/6396 (2%)]	Loss: 0.271247
| Global Round : 2 | Local Epoch : 2 | [200/6396 (3%)]	Loss: 0.218254
| Global Round : 2 | Local Epoch : 2 | [300/6396 (5%)]	Loss: 0.188234
| Global Round : 2 | Local Epoch : 2 | [400/6396 (6%)]	Loss: 0.044688
| Global Round : 2 | Local Epoch : 2 | [500/6396 (8%)]	Loss: 0.237074
| Global Round : 2 | Local Epoch : 2 | [600/6396 (9%)]	Loss: 0.122335
| Global Round : 2 | Local Epoch : 2 | [700/6396 (11%)]	Loss: 0.444290
| Global Round : 2 | Local Epoch : 2 | [800/6396 (12%)]	Loss: 0.054153
| Global Round : 2 | Local Epoch : 2 | [900/6396 (14%)]	Loss: 0.138999
| Global Round : 2 | Local Epoch : 2 | [1000/6396 (16%)]	Loss: 0.408388
| Global Round : 2 | Local Epoch : 2 | [1100/6396 (17%)]	Loss: 0.180280
| Global Round : 2 | Local Epoch : 2 | [1200/6396 (19%)]	Loss: 0.134717
| Global Round : 2 | Local Epoch : 2 | [1300/6396 (20%)]	Loss: 0.370442
| Global Round : 2 | Local Epoch : 2 | [1400/6396 (22%)]	Loss: 0.204209
| Global Round : 2 | Local Epoch : 2 | [1500/6396 (23%)]	Loss: 0.371917
| Global Round : 2 | Local Epoch : 2 | [1600/6396 (25%)]	Loss: 0.180011
| Global Round : 2 | Local Epoch : 2 | [1700/6396 (27%)]	Loss: 0.154152
| Global Round : 2 | Local Epoch : 2 | [1800/6396 (28%)]	Loss: 0.251850
| Global Round : 2 | Local Epoch : 2 | [1900/6396 (30%)]	Loss: 0.246439
| Global Round : 2 | Local Epoch : 2 | [2000/6396 (31%)]	Loss: 0.088895
| Global Round : 2 | Local Epoch : 2 | [2100/6396 (33%)]	Loss: 0.125749
| Global Round : 2 | Local Epoch : 2 | [2200/6396 (34%)]	Loss: 0.250466
| Global Round : 2 | Local Epoch : 2 | [2300/6396 (36%)]	Loss: 0.178050
| Global Round : 2 | Local Epoch : 2 | [2400/6396 (38%)]	Loss: 0.356943
| Global Round : 2 | Local Epoch : 2 | [2500/6396 (39%)]	Loss: 0.107418
| Global Round : 2 | Local Epoch : 2 | [2600/6396 (41%)]	Loss: 0.354120
| Global Round : 2 | Local Epoch : 2 | [2700/6396 (42%)]	Loss: 0.153907
| Global Round : 2 | Local Epoch : 2 | [2800/6396 (44%)]	Loss: 0.287941
| Global Round : 2 | Local Epoch : 2 | [2900/6396 (45%)]	Loss: 0.418634
| Global Round : 2 | Local Epoch : 2 | [3000/6396 (47%)]	Loss: 0.079973
| Global Round : 2 | Local Epoch : 2 | [3100/6396 (48%)]	Loss: 0.112519
| Global Round : 2 | Local Epoch : 2 | [3200/6396 (50%)]	Loss: 0.244794
| Global Round : 2 | Local Epoch : 2 | [3300/6396 (52%)]	Loss: 0.170480
| Global Round : 2 | Local Epoch : 2 | [3400/6396 (53%)]	Loss: 0.265886
| Global Round : 2 | Local Epoch : 2 | [3500/6396 (55%)]	Loss: 0.125457
| Global Round : 2 | Local Epoch : 2 | [3600/6396 (56%)]	Loss: 0.747678
| Global Round : 2 | Local Epoch : 2 | [3700/6396 (58%)]	Loss: 0.289354
| Global Round : 2 | Local Epoch : 2 | [3800/6396 (59%)]	Loss: 0.142349
| Global Round : 2 | Local Epoch : 2 | [3900/6396 (61%)]	Loss: 0.123531
| Global Round : 2 | Local Epoch : 2 | [4000/6396 (62%)]	Loss: 0.110014
| Global Round : 2 | Local Epoch : 2 | [4100/6396 (64%)]	Loss: 0.357388
| Global Round : 2 | Local Epoch : 2 | [4200/6396 (66%)]	Loss: 0.460484
| Global Round : 2 | Local Epoch : 2 | [4300/6396 (67%)]	Loss: 0.408256
| Global Round : 2 | Local Epoch : 2 | [4400/6396 (69%)]	Loss: 0.046624
| Global Round : 2 | Local Epoch : 2 | [4500/6396 (70%)]	Loss: 0.309938
| Global Round : 2 | Local Epoch : 2 | [4600/6396 (72%)]	Loss: 0.125120
| Global Round : 2 | Local Epoch : 2 | [4700/6396 (73%)]	Loss: 0.227963
| Global Round : 2 | Local Epoch : 2 | [4800/6396 (75%)]	Loss: 0.510866
| Global Round : 2 | Local Epoch : 2 | [4900/6396 (77%)]	Loss: 0.237729
| Global Round : 2 | Local Epoch : 2 | [5000/6396 (78%)]	Loss: 0.191213
| Global Round : 2 | Local Epoch : 2 | [5100/6396 (80%)]	Loss: 0.092389
| Global Round : 2 | Local Epoch : 2 | [5200/6396 (81%)]	Loss: 0.229287
| Global Round : 2 | Local Epoch : 2 | [5300/6396 (83%)]	Loss: 0.269224
| Global Round : 2 | Local Epoch : 2 | [5400/6396 (84%)]	Loss: 0.526046
| Global Round : 2 | Local Epoch : 2 | [5500/6396 (86%)]	Loss: 0.111411
| Global Round : 2 | Local Epoch : 2 | [5600/6396 (88%)]	Loss: 0.276432
| Global Round : 2 | Local Epoch : 2 | [5700/6396 (89%)]	Loss: 0.363287
| Global Round : 2 | Local Epoch : 2 | [5800/6396 (91%)]	Loss: 0.258457
| Global Round : 2 | Local Epoch : 2 | [5900/6396 (92%)]	Loss: 0.199243
| Global Round : 2 | Local Epoch : 2 | [6000/6396 (94%)]	Loss: 0.311679
| Global Round : 2 | Local Epoch : 2 | [6100/6396 (95%)]	Loss: 0.205054
| Global Round : 2 | Local Epoch : 2 | [6200/6396 (97%)]	Loss: 0.329110
| Global Round : 2 | Local Epoch : 2 | [6300/6396 (98%)]	Loss: 0.182541
| Global Round : 2 | Local Epoch : 3 | [0/6396 (0%)]	Loss: 0.203249
| Global Round : 2 | Local Epoch : 3 | [100/6396 (2%)]	Loss: 0.158647
| Global Round : 2 | Local Epoch : 3 | [200/6396 (3%)]	Loss: 0.179514
| Global Round : 2 | Local Epoch : 3 | [300/6396 (5%)]	Loss: 0.318339
| Global Round : 2 | Local Epoch : 3 | [400/6396 (6%)]	Loss: 0.330016
| Global Round : 2 | Local Epoch : 3 | [500/6396 (8%)]	Loss: 0.367263
| Global Round : 2 | Local Epoch : 3 | [600/6396 (9%)]	Loss: 0.326061
| Global Round : 2 | Local Epoch : 3 | [700/6396 (11%)]	Loss: 0.150547
| Global Round : 2 | Local Epoch : 3 | [800/6396 (12%)]	Loss: 0.267302
| Global Round : 2 | Local Epoch : 3 | [900/6396 (14%)]	Loss: 0.138755
| Global Round : 2 | Local Epoch : 3 | [1000/6396 (16%)]	Loss: 0.062520
| Global Round : 2 | Local Epoch : 3 | [1100/6396 (17%)]	Loss: 0.167191
| Global Round : 2 | Local Epoch : 3 | [1200/6396 (19%)]	Loss: 0.401424
| Global Round : 2 | Local Epoch : 3 | [1300/6396 (20%)]	Loss: 1.200029
| Global Round : 2 | Local Epoch : 3 | [1400/6396 (22%)]	Loss: 0.193863
| Global Round : 2 | Local Epoch : 3 | [1500/6396 (23%)]	Loss: 0.361129
| Global Round : 2 | Local Epoch : 3 | [1600/6396 (25%)]	Loss: 0.629147
| Global Round : 2 | Local Epoch : 3 | [1700/6396 (27%)]	Loss: 0.135919
| Global Round : 2 | Local Epoch : 3 | [1800/6396 (28%)]	Loss: 0.072037
| Global Round : 2 | Local Epoch : 3 | [1900/6396 (30%)]	Loss: 0.421014
| Global Round : 2 | Local Epoch : 3 | [2000/6396 (31%)]	Loss: 0.121091
| Global Round : 2 | Local Epoch : 3 | [2100/6396 (33%)]	Loss: 0.502124
| Global Round : 2 | Local Epoch : 3 | [2200/6396 (34%)]	Loss: 0.062819
| Global Round : 2 | Local Epoch : 3 | [2300/6396 (36%)]	Loss: 0.036866
| Global Round : 2 | Local Epoch : 3 | [2400/6396 (38%)]	Loss: 0.078587
| Global Round : 2 | Local Epoch : 3 | [2500/6396 (39%)]	Loss: 0.229356
| Global Round : 2 | Local Epoch : 3 | [2600/6396 (41%)]	Loss: 0.387071
| Global Round : 2 | Local Epoch : 3 | [2700/6396 (42%)]	Loss: 0.314035
| Global Round : 2 | Local Epoch : 3 | [2800/6396 (44%)]	Loss: 0.478678
| Global Round : 2 | Local Epoch : 3 | [2900/6396 (45%)]	Loss: 0.243041
| Global Round : 2 | Local Epoch : 3 | [3000/6396 (47%)]	Loss: 0.150255
| Global Round : 2 | Local Epoch : 3 | [3100/6396 (48%)]	Loss: 0.132500
| Global Round : 2 | Local Epoch : 3 | [3200/6396 (50%)]	Loss: 0.141832
| Global Round : 2 | Local Epoch : 3 | [3300/6396 (52%)]	Loss: 0.205112
| Global Round : 2 | Local Epoch : 3 | [3400/6396 (53%)]	Loss: 0.060979
| Global Round : 2 | Local Epoch : 3 | [3500/6396 (55%)]	Loss: 0.442789
| Global Round : 2 | Local Epoch : 3 | [3600/6396 (56%)]	Loss: 0.137992
| Global Round : 2 | Local Epoch : 3 | [3700/6396 (58%)]	Loss: 0.413330
| Global Round : 2 | Local Epoch : 3 | [3800/6396 (59%)]	Loss: 0.172000
| Global Round : 2 | Local Epoch : 3 | [3900/6396 (61%)]	Loss: 0.642711
| Global Round : 2 | Local Epoch : 3 | [4000/6396 (62%)]	Loss: 0.294505
| Global Round : 2 | Local Epoch : 3 | [4100/6396 (64%)]	Loss: 0.105326
| Global Round : 2 | Local Epoch : 3 | [4200/6396 (66%)]	Loss: 0.166555
| Global Round : 2 | Local Epoch : 3 | [4300/6396 (67%)]	Loss: 0.444048
| Global Round : 2 | Local Epoch : 3 | [4400/6396 (69%)]	Loss: 0.258651
| Global Round : 2 | Local Epoch : 3 | [4500/6396 (70%)]	Loss: 0.232749
| Global Round : 2 | Local Epoch : 3 | [4600/6396 (72%)]	Loss: 0.124553
| Global Round : 2 | Local Epoch : 3 | [4700/6396 (73%)]	Loss: 0.178569
| Global Round : 2 | Local Epoch : 3 | [4800/6396 (75%)]	Loss: 0.231959
| Global Round : 2 | Local Epoch : 3 | [4900/6396 (77%)]	Loss: 0.225925
| Global Round : 2 | Local Epoch : 3 | [5000/6396 (78%)]	Loss: 0.218566
| Global Round : 2 | Local Epoch : 3 | [5100/6396 (80%)]	Loss: 0.051106
| Global Round : 2 | Local Epoch : 3 | [5200/6396 (81%)]	Loss: 0.089914
| Global Round : 2 | Local Epoch : 3 | [5300/6396 (83%)]	Loss: 0.435547
| Global Round : 2 | Local Epoch : 3 | [5400/6396 (84%)]	Loss: 0.184180
| Global Round : 2 | Local Epoch : 3 | [5500/6396 (86%)]	Loss: 0.043075
| Global Round : 2 | Local Epoch : 3 | [5600/6396 (88%)]	Loss: 0.444712
| Global Round : 2 | Local Epoch : 3 | [5700/6396 (89%)]	Loss: 0.738442
| Global Round : 2 | Local Epoch : 3 | [5800/6396 (91%)]	Loss: 0.382305
| Global Round : 2 | Local Epoch : 3 | [5900/6396 (92%)]	Loss: 0.256730
| Global Round : 2 | Local Epoch : 3 | [6000/6396 (94%)]	Loss: 0.144309
| Global Round : 2 | Local Epoch : 3 | [6100/6396 (95%)]	Loss: 0.099598
| Global Round : 2 | Local Epoch : 3 | [6200/6396 (97%)]	Loss: 0.976640
| Global Round : 2 | Local Epoch : 3 | [6300/6396 (98%)]	Loss: 0.242427
| Global Round : 2 | Local Epoch : 4 | [0/6396 (0%)]	Loss: 0.044568
| Global Round : 2 | Local Epoch : 4 | [100/6396 (2%)]	Loss: 0.360417
| Global Round : 2 | Local Epoch : 4 | [200/6396 (3%)]	Loss: 0.064150
| Global Round : 2 | Local Epoch : 4 | [300/6396 (5%)]	Loss: 0.217799
| Global Round : 2 | Local Epoch : 4 | [400/6396 (6%)]	Loss: 0.081870
| Global Round : 2 | Local Epoch : 4 | [500/6396 (8%)]	Loss: 0.230294
| Global Round : 2 | Local Epoch : 4 | [600/6396 (9%)]	Loss: 0.210446
| Global Round : 2 | Local Epoch : 4 | [700/6396 (11%)]	Loss: 0.058391
| Global Round : 2 | Local Epoch : 4 | [800/6396 (12%)]	Loss: 0.339436
| Global Round : 2 | Local Epoch : 4 | [900/6396 (14%)]	Loss: 0.370499
| Global Round : 2 | Local Epoch : 4 | [1000/6396 (16%)]	Loss: 0.366747
| Global Round : 2 | Local Epoch : 4 | [1100/6396 (17%)]	Loss: 0.199733
| Global Round : 2 | Local Epoch : 4 | [1200/6396 (19%)]	Loss: 0.051067
| Global Round : 2 | Local Epoch : 4 | [1300/6396 (20%)]	Loss: 0.070291
| Global Round : 2 | Local Epoch : 4 | [1400/6396 (22%)]	Loss: 0.169833
| Global Round : 2 | Local Epoch : 4 | [1500/6396 (23%)]	Loss: 0.131058
| Global Round : 2 | Local Epoch : 4 | [1600/6396 (25%)]	Loss: 0.342866
| Global Round : 2 | Local Epoch : 4 | [1700/6396 (27%)]	Loss: 0.440801
| Global Round : 2 | Local Epoch : 4 | [1800/6396 (28%)]	Loss: 0.139865
| Global Round : 2 | Local Epoch : 4 | [1900/6396 (30%)]	Loss: 0.201327
| Global Round : 2 | Local Epoch : 4 | [2000/6396 (31%)]	Loss: 0.117840
| Global Round : 2 | Local Epoch : 4 | [2100/6396 (33%)]	Loss: 0.088078
| Global Round : 2 | Local Epoch : 4 | [2200/6396 (34%)]	Loss: 0.126232
| Global Round : 2 | Local Epoch : 4 | [2300/6396 (36%)]	Loss: 0.397351
| Global Round : 2 | Local Epoch : 4 | [2400/6396 (38%)]	Loss: 0.129726
| Global Round : 2 | Local Epoch : 4 | [2500/6396 (39%)]	Loss: 0.284760
| Global Round : 2 | Local Epoch : 4 | [2600/6396 (41%)]	Loss: 0.110257
| Global Round : 2 | Local Epoch : 4 | [2700/6396 (42%)]	Loss: 0.524708
| Global Round : 2 | Local Epoch : 4 | [2800/6396 (44%)]	Loss: 0.209468
| Global Round : 2 | Local Epoch : 4 | [2900/6396 (45%)]	Loss: 0.223264
| Global Round : 2 | Local Epoch : 4 | [3000/6396 (47%)]	Loss: 0.075377
| Global Round : 2 | Local Epoch : 4 | [3100/6396 (48%)]	Loss: 0.189271
| Global Round : 2 | Local Epoch : 4 | [3200/6396 (50%)]	Loss: 0.432655
| Global Round : 2 | Local Epoch : 4 | [3300/6396 (52%)]	Loss: 0.210721
| Global Round : 2 | Local Epoch : 4 | [3400/6396 (53%)]	Loss: 0.076179
| Global Round : 2 | Local Epoch : 4 | [3500/6396 (55%)]	Loss: 0.019741
| Global Round : 2 | Local Epoch : 4 | [3600/6396 (56%)]	Loss: 0.309013
| Global Round : 2 | Local Epoch : 4 | [3700/6396 (58%)]	Loss: 0.190857
| Global Round : 2 | Local Epoch : 4 | [3800/6396 (59%)]	Loss: 0.063010
| Global Round : 2 | Local Epoch : 4 | [3900/6396 (61%)]	Loss: 0.226682
| Global Round : 2 | Local Epoch : 4 | [4000/6396 (62%)]	Loss: 0.041285
| Global Round : 2 | Local Epoch : 4 | [4100/6396 (64%)]	Loss: 0.346045
| Global Round : 2 | Local Epoch : 4 | [4200/6396 (66%)]	Loss: 0.207988
| Global Round : 2 | Local Epoch : 4 | [4300/6396 (67%)]	Loss: 0.259563
| Global Round : 2 | Local Epoch : 4 | [4400/6396 (69%)]	Loss: 0.171709
| Global Round : 2 | Local Epoch : 4 | [4500/6396 (70%)]	Loss: 0.100737
| Global Round : 2 | Local Epoch : 4 | [4600/6396 (72%)]	Loss: 0.673248
| Global Round : 2 | Local Epoch : 4 | [4700/6396 (73%)]	Loss: 0.530556
| Global Round : 2 | Local Epoch : 4 | [4800/6396 (75%)]	Loss: 0.113984
| Global Round : 2 | Local Epoch : 4 | [4900/6396 (77%)]	Loss: 0.053614
| Global Round : 2 | Local Epoch : 4 | [5000/6396 (78%)]	Loss: 0.371624
| Global Round : 2 | Local Epoch : 4 | [5100/6396 (80%)]	Loss: 0.249749
| Global Round : 2 | Local Epoch : 4 | [5200/6396 (81%)]	Loss: 0.153578
| Global Round : 2 | Local Epoch : 4 | [5300/6396 (83%)]	Loss: 0.146843
| Global Round : 2 | Local Epoch : 4 | [5400/6396 (84%)]	Loss: 0.108538
| Global Round : 2 | Local Epoch : 4 | [5500/6396 (86%)]	Loss: 0.135485
| Global Round : 2 | Local Epoch : 4 | [5600/6396 (88%)]	Loss: 0.076534
| Global Round : 2 | Local Epoch : 4 | [5700/6396 (89%)]	Loss: 0.027994
| Global Round : 2 | Local Epoch : 4 | [5800/6396 (91%)]	Loss: 0.178731
| Global Round : 2 | Local Epoch : 4 | [5900/6396 (92%)]	Loss: 0.552841
| Global Round : 2 | Local Epoch : 4 | [6000/6396 (94%)]	Loss: 0.238226
| Global Round : 2 | Local Epoch : 4 | [6100/6396 (95%)]	Loss: 0.207189
| Global Round : 2 | Local Epoch : 4 | [6200/6396 (97%)]	Loss: 0.408952
| Global Round : 2 | Local Epoch : 4 | [6300/6396 (98%)]	Loss: 0.287280
----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.78      0.81        36
         DME       0.83      0.89      0.86        44

    accuracy                           0.84        80
   macro avg       0.84      0.83      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.80      0.83        41
         DME       0.80      0.85      0.83        39

    accuracy                           0.82        80
   macro avg       0.83      0.83      0.83        80
weighted avg       0.83      0.82      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.79      0.79        39
         DME       0.80      0.80      0.80        41

    accuracy                           0.80        80
   macro avg       0.80      0.80      0.80        80
weighted avg       0.80      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.85      0.86        46
         DME       0.80      0.82      0.81        34

    accuracy                           0.84        80
   macro avg       0.83      0.84      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.83      0.82        30
         DME       0.90      0.88      0.89        50

    accuracy                           0.86        80
   macro avg       0.85      0.86      0.85        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.86      0.82        35
         DME       0.88      0.82      0.85        45

    accuracy                           0.84        80
   macro avg       0.84      0.84      0.84        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.83      0.84        42
         DME       0.82      0.84      0.83        38

    accuracy                           0.84        80
   macro avg       0.84      0.84      0.84        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.73      0.86      0.79        35
         DME       0.87      0.76      0.81        45

    accuracy                           0.80        80
   macro avg       0.80      0.81      0.80        80
weighted avg       0.81      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.79      0.82        34
         DME       0.85      0.89      0.87        46

    accuracy                           0.85        80
   macro avg       0.85      0.84      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.84      0.85        38
         DME       0.86      0.88      0.87        42

    accuracy                           0.86        80
   macro avg       0.86      0.86      0.86        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.78      0.81        36
      DRUSEN       0.83      0.89      0.86        44

    accuracy                           0.84        80
   macro avg       0.84      0.83      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.80      0.83        41
      DRUSEN       0.80      0.85      0.83        39

    accuracy                           0.82        80
   macro avg       0.83      0.83      0.83        80
weighted avg       0.83      0.82      0.82        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.79      0.79        39
      DRUSEN       0.80      0.80      0.80        41

    accuracy                           0.80        80
   macro avg       0.80      0.80      0.80        80
weighted avg       0.80      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.85      0.86        46
      DRUSEN       0.80      0.82      0.81        34

    accuracy                           0.84        80
   macro avg       0.83      0.84      0.83        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.83      0.82        30
      DRUSEN       0.90      0.88      0.89        50

    accuracy                           0.86        80
   macro avg       0.85      0.86      0.85        80
weighted avg       0.86      0.86      0.86        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.86      0.82        35
      DRUSEN       0.88      0.82      0.85        45

    accuracy                           0.84        80
   macro avg       0.84      0.84      0.84        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.83      0.84        42
      DRUSEN       0.82      0.84      0.83        38

    accuracy                           0.84        80
   macro avg       0.84      0.84      0.84        80
weighted avg       0.84      0.84      0.84        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.73      0.86      0.79        35
      DRUSEN       0.87      0.76      0.81        45

    accuracy                           0.80        80
   macro avg       0.80      0.81      0.80        80
weighted avg       0.81      0.80      0.80        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.79      0.82        34
      DRUSEN       0.85      0.89      0.87        46

    accuracy                           0.85        80
   macro avg       0.85      0.84      0.85        80
weighted avg       0.85      0.85      0.85        80

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.84      0.85        38
      DRUSEN       0.86      0.88      0.87        42

    accuracy                           0.86        80
   macro avg       0.86      0.86      0.86        80
weighted avg       0.86      0.86      0.86        80

----------------------

Training accuracy [0.81125, 0.8275, 0.835]
########################

Client 1 Test Statistics

==========================

For client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.79      0.82        75
         DME       0.73      0.81      0.77        53

    accuracy                           0.80       128
   macro avg       0.79      0.80      0.79       128
weighted avg       0.80      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.77      0.82        71
         DME       0.75      0.86      0.80        57

    accuracy                           0.81       128
   macro avg       0.81      0.82      0.81       128
weighted avg       0.82      0.81      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.71      0.79        85
         DME       0.59      0.84      0.69        43

    accuracy                           0.75       128
   macro avg       0.74      0.77      0.74       128
weighted avg       0.79      0.75      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.76      0.83        84
         DME       0.66      0.86      0.75        44

    accuracy                           0.80       128
   macro avg       0.78      0.81      0.79       128
weighted avg       0.83      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.79      0.85        85
         DME       0.68      0.88      0.77        43

    accuracy                           0.82       128
   macro avg       0.80      0.84      0.81       128
weighted avg       0.85      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.74      0.84        78
         DME       0.71      0.96      0.81        50

    accuracy                           0.83       128
   macro avg       0.84      0.85      0.83       128
weighted avg       0.86      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.74      0.82        77
         DME       0.70      0.90      0.79        51

    accuracy                           0.80       128
   macro avg       0.81      0.82      0.80       128
weighted avg       0.83      0.80      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.77      0.81        78
         DME       0.68      0.78      0.73        50

    accuracy                           0.77       128
   macro avg       0.76      0.77      0.77       128
weighted avg       0.78      0.77      0.78       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.73      0.81        77
         DME       0.68      0.88      0.77        51

    accuracy                           0.79       128
   macro avg       0.79      0.80      0.79       128
weighted avg       0.82      0.79      0.79       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.72      0.81        72
         DME       0.72      0.93      0.81        56

    accuracy                           0.81       128
   macro avg       0.83      0.83      0.81       128
weighted avg       0.84      0.81      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.80      0.87        82
         DME       0.72      0.91      0.81        46

    accuracy                           0.84       128
   macro avg       0.83      0.86      0.84       128
weighted avg       0.86      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.77      0.82        69
         DME       0.76      0.88      0.82        59

    accuracy                           0.82       128
   macro avg       0.82      0.82      0.82       128
weighted avg       0.83      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.78      0.87        79
         DME       0.73      0.96      0.83        49

    accuracy                           0.85       128
   macro avg       0.85      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.68      0.77        69
         DME       0.71      0.90      0.79        59

    accuracy                           0.78       128
   macro avg       0.80      0.79      0.78       128
weighted avg       0.80      0.78      0.78       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.73      0.80        70
         DME       0.73      0.90      0.81        58

    accuracy                           0.80       128
   macro avg       0.81      0.81      0.80       128
weighted avg       0.82      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.80      0.82        40
         DME       0.79      0.83      0.81        36

    accuracy                           0.82        76
   macro avg       0.82      0.82      0.82        76
weighted avg       0.82      0.82      0.82        76

----------------------

==========================

Testing client 1 on client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.87      0.86        68
      DRUSEN       0.84      0.82      0.83        60

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.88      0.85        64
      DRUSEN       0.87      0.81      0.84        64

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.88      0.86        58
      DRUSEN       0.90      0.86      0.88        70

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.87      0.83        61
      DRUSEN       0.87      0.81      0.84        67

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.90      0.86        51
      DRUSEN       0.93      0.87      0.90        77

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.87      0.87        61
      DRUSEN       0.88      0.88      0.88        67

    accuracy                           0.88       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.77      0.91      0.83        55
      DRUSEN       0.92      0.79      0.85        73

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.91      0.89        67
      DRUSEN       0.90      0.85      0.87        61

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.88      0.87        66
      DRUSEN       0.87      0.85      0.86        62

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.90      0.89        61
      DRUSEN       0.91      0.90      0.90        67

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.88      0.87        75
      DRUSEN       0.82      0.79      0.81        53

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.92      0.86        65
      DRUSEN       0.91      0.78      0.84        63

    accuracy                           0.85       128
   macro avg       0.86      0.85      0.85       128
weighted avg       0.86      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.88      0.85        57
      DRUSEN       0.90      0.85      0.87        71

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.86      0.84        63
      DRUSEN       0.86      0.83      0.84        65

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.88      0.83        57
      DRUSEN       0.89      0.82      0.85        71

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.95      0.88        39
      DRUSEN       0.95      0.82      0.88        45

    accuracy                           0.88        84
   macro avg       0.89      0.89      0.88        84
weighted avg       0.89      0.88      0.88        84

----------------------

########################

Client 2 Test Statistics

==========================

For client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.87      0.86        68
      DRUSEN       0.84      0.82      0.83        60

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.88      0.85        64
      DRUSEN       0.87      0.81      0.84        64

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.88      0.86        58
      DRUSEN       0.90      0.86      0.88        70

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.87      0.83        61
      DRUSEN       0.87      0.81      0.84        67

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.90      0.86        51
      DRUSEN       0.93      0.87      0.90        77

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.87      0.87        61
      DRUSEN       0.88      0.88      0.88        67

    accuracy                           0.88       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.77      0.91      0.83        55
      DRUSEN       0.92      0.79      0.85        73

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.91      0.89        67
      DRUSEN       0.90      0.85      0.87        61

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.88      0.87        66
      DRUSEN       0.87      0.85      0.86        62

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.90      0.89        61
      DRUSEN       0.91      0.90      0.90        67

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.88      0.87        75
      DRUSEN       0.82      0.79      0.81        53

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.92      0.86        65
      DRUSEN       0.91      0.78      0.84        63

    accuracy                           0.85       128
   macro avg       0.86      0.85      0.85       128
weighted avg       0.86      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.88      0.85        57
      DRUSEN       0.90      0.85      0.87        71

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.86      0.84        63
      DRUSEN       0.86      0.83      0.84        65

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.79      0.88      0.83        57
      DRUSEN       0.89      0.82      0.85        71

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.82      0.95      0.88        39
      DRUSEN       0.95      0.82      0.88        45

    accuracy                           0.88        84
   macro avg       0.89      0.89      0.88        84
weighted avg       0.89      0.88      0.88        84

----------------------

==========================

Testing client 2 on client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.79      0.82        75
         DME       0.73      0.81      0.77        53

    accuracy                           0.80       128
   macro avg       0.79      0.80      0.79       128
weighted avg       0.80      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.77      0.82        71
         DME       0.75      0.86      0.80        57

    accuracy                           0.81       128
   macro avg       0.81      0.82      0.81       128
weighted avg       0.82      0.81      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.71      0.79        85
         DME       0.59      0.84      0.69        43

    accuracy                           0.75       128
   macro avg       0.74      0.77      0.74       128
weighted avg       0.79      0.75      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.76      0.83        84
         DME       0.66      0.86      0.75        44

    accuracy                           0.80       128
   macro avg       0.78      0.81      0.79       128
weighted avg       0.83      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.79      0.85        85
         DME       0.68      0.88      0.77        43

    accuracy                           0.82       128
   macro avg       0.80      0.84      0.81       128
weighted avg       0.85      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.74      0.84        78
         DME       0.71      0.96      0.81        50

    accuracy                           0.83       128
   macro avg       0.84      0.85      0.83       128
weighted avg       0.86      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.74      0.82        77
         DME       0.70      0.90      0.79        51

    accuracy                           0.80       128
   macro avg       0.81      0.82      0.80       128
weighted avg       0.83      0.80      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.77      0.81        78
         DME       0.68      0.78      0.73        50

    accuracy                           0.77       128
   macro avg       0.76      0.77      0.77       128
weighted avg       0.78      0.77      0.78       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.73      0.81        77
         DME       0.68      0.88      0.77        51

    accuracy                           0.79       128
   macro avg       0.79      0.80      0.79       128
weighted avg       0.82      0.79      0.79       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.72      0.81        72
         DME       0.72      0.93      0.81        56

    accuracy                           0.81       128
   macro avg       0.83      0.83      0.81       128
weighted avg       0.84      0.81      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.80      0.87        82
         DME       0.72      0.91      0.81        46

    accuracy                           0.84       128
   macro avg       0.83      0.86      0.84       128
weighted avg       0.86      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.77      0.82        69
         DME       0.76      0.88      0.82        59

    accuracy                           0.82       128
   macro avg       0.82      0.82      0.82       128
weighted avg       0.83      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.78      0.87        79
         DME       0.73      0.96      0.83        49

    accuracy                           0.85       128
   macro avg       0.85      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.68      0.77        69
         DME       0.71      0.90      0.79        59

    accuracy                           0.78       128
   macro avg       0.80      0.79      0.78       128
weighted avg       0.80      0.78      0.78       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.73      0.80        70
         DME       0.73      0.90      0.81        58

    accuracy                           0.80       128
   macro avg       0.81      0.81      0.80       128
weighted avg       0.82      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.80      0.82        40
         DME       0.79      0.83      0.81        36

    accuracy                           0.82        76
   macro avg       0.82      0.82      0.82        76
weighted avg       0.82      0.82      0.82        76

----------------------

Test accuracy on client 1 0.8061122244488977
Test accuracy on client 2 0.8597804391217565
========================================

========================================

Test on original client distribution for client 1 : 80.61%
Test on client 2 distribution for client 1 : 85.98%
Test on original client distribution for client 2 : 85.98%
Test on client 1 distribution for client 2 : 80.61%
