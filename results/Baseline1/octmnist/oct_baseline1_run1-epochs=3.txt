
Experimental details:
    Model     : cnn
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 3

    Federated parameters:
   IID
    Number of users  : 2
    Local Batch size   : 10
    Local Epochs       : 5

CNNOCTmnist(
  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): Dropout2d(p=0.5, inplace=False)
  (fc1): Linear(in_features=100820, out_features=50, bias=True)
  (fc2): Linear(in_features=50, out_features=2, bias=True)
)

 | Global Training Round : 1 |

----------------
user chosen 1
----------------
----------------
| Global Round : 0 | Local Epoch : 0 | [0/10236 (0%)]	Loss: 0.714441
| Global Round : 0 | Local Epoch : 0 | [100/10236 (1%)]	Loss: 0.958320
| Global Round : 0 | Local Epoch : 0 | [200/10236 (2%)]	Loss: 0.715827
| Global Round : 0 | Local Epoch : 0 | [300/10236 (3%)]	Loss: 0.721270
| Global Round : 0 | Local Epoch : 0 | [400/10236 (4%)]	Loss: 0.628090
| Global Round : 0 | Local Epoch : 0 | [500/10236 (5%)]	Loss: 0.632222
| Global Round : 0 | Local Epoch : 0 | [600/10236 (6%)]	Loss: 0.667767
| Global Round : 0 | Local Epoch : 0 | [700/10236 (7%)]	Loss: 0.682656
| Global Round : 0 | Local Epoch : 0 | [800/10236 (8%)]	Loss: 0.700713
| Global Round : 0 | Local Epoch : 0 | [900/10236 (9%)]	Loss: 0.668088
| Global Round : 0 | Local Epoch : 0 | [1000/10236 (10%)]	Loss: 0.688145
| Global Round : 0 | Local Epoch : 0 | [1100/10236 (11%)]	Loss: 0.709972
| Global Round : 0 | Local Epoch : 0 | [1200/10236 (12%)]	Loss: 0.682852
| Global Round : 0 | Local Epoch : 0 | [1300/10236 (13%)]	Loss: 0.688291
| Global Round : 0 | Local Epoch : 0 | [1400/10236 (14%)]	Loss: 0.743289
| Global Round : 0 | Local Epoch : 0 | [1500/10236 (15%)]	Loss: 0.696318
| Global Round : 0 | Local Epoch : 0 | [1600/10236 (16%)]	Loss: 0.702024
| Global Round : 0 | Local Epoch : 0 | [1700/10236 (17%)]	Loss: 0.689061
| Global Round : 0 | Local Epoch : 0 | [1800/10236 (18%)]	Loss: 0.689432
| Global Round : 0 | Local Epoch : 0 | [1900/10236 (19%)]	Loss: 0.658701
| Global Round : 0 | Local Epoch : 0 | [2000/10236 (20%)]	Loss: 0.660706
| Global Round : 0 | Local Epoch : 0 | [2100/10236 (21%)]	Loss: 0.680687
| Global Round : 0 | Local Epoch : 0 | [2200/10236 (21%)]	Loss: 0.724656
| Global Round : 0 | Local Epoch : 0 | [2300/10236 (22%)]	Loss: 0.644044
| Global Round : 0 | Local Epoch : 0 | [2400/10236 (23%)]	Loss: 0.767249
| Global Round : 0 | Local Epoch : 0 | [2500/10236 (24%)]	Loss: 0.687742
| Global Round : 0 | Local Epoch : 0 | [2600/10236 (25%)]	Loss: 0.709573
| Global Round : 0 | Local Epoch : 0 | [2700/10236 (26%)]	Loss: 0.666484
| Global Round : 0 | Local Epoch : 0 | [2800/10236 (27%)]	Loss: 0.682934
| Global Round : 0 | Local Epoch : 0 | [2900/10236 (28%)]	Loss: 0.705473
| Global Round : 0 | Local Epoch : 0 | [3000/10236 (29%)]	Loss: 0.668604
| Global Round : 0 | Local Epoch : 0 | [3100/10236 (30%)]	Loss: 0.745678
| Global Round : 0 | Local Epoch : 0 | [3200/10236 (31%)]	Loss: 0.674406
| Global Round : 0 | Local Epoch : 0 | [3300/10236 (32%)]	Loss: 0.540878
| Global Round : 0 | Local Epoch : 0 | [3400/10236 (33%)]	Loss: 0.692112
| Global Round : 0 | Local Epoch : 0 | [3500/10236 (34%)]	Loss: 0.711743
| Global Round : 0 | Local Epoch : 0 | [3600/10236 (35%)]	Loss: 0.689333
| Global Round : 0 | Local Epoch : 0 | [3700/10236 (36%)]	Loss: 0.608415
| Global Round : 0 | Local Epoch : 0 | [3800/10236 (37%)]	Loss: 0.794880
| Global Round : 0 | Local Epoch : 0 | [3900/10236 (38%)]	Loss: 0.679229
| Global Round : 0 | Local Epoch : 0 | [4000/10236 (39%)]	Loss: 0.688236
| Global Round : 0 | Local Epoch : 0 | [4100/10236 (40%)]	Loss: 0.636102
| Global Round : 0 | Local Epoch : 0 | [4200/10236 (41%)]	Loss: 0.672431
| Global Round : 0 | Local Epoch : 0 | [4300/10236 (42%)]	Loss: 0.709545
| Global Round : 0 | Local Epoch : 0 | [4400/10236 (43%)]	Loss: 0.662112
| Global Round : 0 | Local Epoch : 0 | [4500/10236 (44%)]	Loss: 0.665971
| Global Round : 0 | Local Epoch : 0 | [4600/10236 (45%)]	Loss: 0.638573
| Global Round : 0 | Local Epoch : 0 | [4700/10236 (46%)]	Loss: 0.772226
| Global Round : 0 | Local Epoch : 0 | [4800/10236 (47%)]	Loss: 0.708696
| Global Round : 0 | Local Epoch : 0 | [4900/10236 (48%)]	Loss: 0.631157
| Global Round : 0 | Local Epoch : 0 | [5000/10236 (49%)]	Loss: 0.583038
| Global Round : 0 | Local Epoch : 0 | [5100/10236 (50%)]	Loss: 0.662981
| Global Round : 0 | Local Epoch : 0 | [5200/10236 (51%)]	Loss: 0.719407
| Global Round : 0 | Local Epoch : 0 | [5300/10236 (52%)]	Loss: 0.642786
| Global Round : 0 | Local Epoch : 0 | [5400/10236 (53%)]	Loss: 0.674159
| Global Round : 0 | Local Epoch : 0 | [5500/10236 (54%)]	Loss: 0.706159
| Global Round : 0 | Local Epoch : 0 | [5600/10236 (55%)]	Loss: 0.586841
| Global Round : 0 | Local Epoch : 0 | [5700/10236 (56%)]	Loss: 0.621541
| Global Round : 0 | Local Epoch : 0 | [5800/10236 (57%)]	Loss: 0.722032
| Global Round : 0 | Local Epoch : 0 | [5900/10236 (58%)]	Loss: 0.693472
| Global Round : 0 | Local Epoch : 0 | [6000/10236 (59%)]	Loss: 0.641853
| Global Round : 0 | Local Epoch : 0 | [6100/10236 (60%)]	Loss: 0.682295
| Global Round : 0 | Local Epoch : 0 | [6200/10236 (61%)]	Loss: 0.623874
| Global Round : 0 | Local Epoch : 0 | [6300/10236 (62%)]	Loss: 0.676430
| Global Round : 0 | Local Epoch : 0 | [6400/10236 (62%)]	Loss: 0.681309
| Global Round : 0 | Local Epoch : 0 | [6500/10236 (63%)]	Loss: 0.671716
| Global Round : 0 | Local Epoch : 0 | [6600/10236 (64%)]	Loss: 0.673136
| Global Round : 0 | Local Epoch : 0 | [6700/10236 (65%)]	Loss: 0.639380
| Global Round : 0 | Local Epoch : 0 | [6800/10236 (66%)]	Loss: 0.696142
| Global Round : 0 | Local Epoch : 0 | [6900/10236 (67%)]	Loss: 0.694910
| Global Round : 0 | Local Epoch : 0 | [7000/10236 (68%)]	Loss: 0.657062
| Global Round : 0 | Local Epoch : 0 | [7100/10236 (69%)]	Loss: 0.660646
| Global Round : 0 | Local Epoch : 0 | [7200/10236 (70%)]	Loss: 0.635340
| Global Round : 0 | Local Epoch : 0 | [7300/10236 (71%)]	Loss: 0.669760
| Global Round : 0 | Local Epoch : 0 | [7400/10236 (72%)]	Loss: 0.655355
| Global Round : 0 | Local Epoch : 0 | [7500/10236 (73%)]	Loss: 0.639960
| Global Round : 0 | Local Epoch : 0 | [7600/10236 (74%)]	Loss: 0.670678
| Global Round : 0 | Local Epoch : 0 | [7700/10236 (75%)]	Loss: 0.597897
| Global Round : 0 | Local Epoch : 0 | [7800/10236 (76%)]	Loss: 0.675400
| Global Round : 0 | Local Epoch : 0 | [7900/10236 (77%)]	Loss: 0.718320
| Global Round : 0 | Local Epoch : 0 | [8000/10236 (78%)]	Loss: 0.592196
| Global Round : 0 | Local Epoch : 0 | [8100/10236 (79%)]	Loss: 0.687286
| Global Round : 0 | Local Epoch : 0 | [8200/10236 (80%)]	Loss: 0.584686
| Global Round : 0 | Local Epoch : 0 | [8300/10236 (81%)]	Loss: 0.491469
| Global Round : 0 | Local Epoch : 0 | [8400/10236 (82%)]	Loss: 0.806239
| Global Round : 0 | Local Epoch : 0 | [8500/10236 (83%)]	Loss: 0.702451
| Global Round : 0 | Local Epoch : 0 | [8600/10236 (84%)]	Loss: 0.581870
| Global Round : 0 | Local Epoch : 0 | [8700/10236 (85%)]	Loss: 0.673600
| Global Round : 0 | Local Epoch : 0 | [8800/10236 (86%)]	Loss: 0.587943
| Global Round : 0 | Local Epoch : 0 | [8900/10236 (87%)]	Loss: 0.643867
| Global Round : 0 | Local Epoch : 0 | [9000/10236 (88%)]	Loss: 0.677823
| Global Round : 0 | Local Epoch : 0 | [9100/10236 (89%)]	Loss: 0.609726
| Global Round : 0 | Local Epoch : 0 | [9200/10236 (90%)]	Loss: 0.750541
| Global Round : 0 | Local Epoch : 0 | [9300/10236 (91%)]	Loss: 0.447610
| Global Round : 0 | Local Epoch : 0 | [9400/10236 (92%)]	Loss: 0.591050
| Global Round : 0 | Local Epoch : 0 | [9500/10236 (93%)]	Loss: 0.756311
| Global Round : 0 | Local Epoch : 0 | [9600/10236 (94%)]	Loss: 0.505924
| Global Round : 0 | Local Epoch : 0 | [9700/10236 (95%)]	Loss: 0.750821
| Global Round : 0 | Local Epoch : 0 | [9800/10236 (96%)]	Loss: 0.798608
| Global Round : 0 | Local Epoch : 0 | [9900/10236 (97%)]	Loss: 0.572992
| Global Round : 0 | Local Epoch : 0 | [10000/10236 (98%)]	Loss: 0.613560
| Global Round : 0 | Local Epoch : 0 | [10100/10236 (99%)]	Loss: 0.743445
| Global Round : 0 | Local Epoch : 0 | [10200/10236 (100%)]	Loss: 0.576263
| Global Round : 0 | Local Epoch : 1 | [0/10236 (0%)]	Loss: 0.719142
| Global Round : 0 | Local Epoch : 1 | [100/10236 (1%)]	Loss: 0.639229
| Global Round : 0 | Local Epoch : 1 | [200/10236 (2%)]	Loss: 0.608774
| Global Round : 0 | Local Epoch : 1 | [300/10236 (3%)]	Loss: 0.598182
| Global Round : 0 | Local Epoch : 1 | [400/10236 (4%)]	Loss: 0.655437
| Global Round : 0 | Local Epoch : 1 | [500/10236 (5%)]	Loss: 0.604789
| Global Round : 0 | Local Epoch : 1 | [600/10236 (6%)]	Loss: 0.688776
| Global Round : 0 | Local Epoch : 1 | [700/10236 (7%)]	Loss: 0.487457
| Global Round : 0 | Local Epoch : 1 | [800/10236 (8%)]	Loss: 0.705476
| Global Round : 0 | Local Epoch : 1 | [900/10236 (9%)]	Loss: 0.473143
| Global Round : 0 | Local Epoch : 1 | [1000/10236 (10%)]	Loss: 0.517221
| Global Round : 0 | Local Epoch : 1 | [1100/10236 (11%)]	Loss: 0.617147
| Global Round : 0 | Local Epoch : 1 | [1200/10236 (12%)]	Loss: 0.523891
| Global Round : 0 | Local Epoch : 1 | [1300/10236 (13%)]	Loss: 0.616739
| Global Round : 0 | Local Epoch : 1 | [1400/10236 (14%)]	Loss: 0.472342
| Global Round : 0 | Local Epoch : 1 | [1500/10236 (15%)]	Loss: 0.628087
| Global Round : 0 | Local Epoch : 1 | [1600/10236 (16%)]	Loss: 0.562449
| Global Round : 0 | Local Epoch : 1 | [1700/10236 (17%)]	Loss: 0.552801
| Global Round : 0 | Local Epoch : 1 | [1800/10236 (18%)]	Loss: 0.624727
| Global Round : 0 | Local Epoch : 1 | [1900/10236 (19%)]	Loss: 0.656979
| Global Round : 0 | Local Epoch : 1 | [2000/10236 (20%)]	Loss: 0.449784
| Global Round : 0 | Local Epoch : 1 | [2100/10236 (21%)]	Loss: 0.779098
| Global Round : 0 | Local Epoch : 1 | [2200/10236 (21%)]	Loss: 0.600328
| Global Round : 0 | Local Epoch : 1 | [2300/10236 (22%)]	Loss: 0.667267
| Global Round : 0 | Local Epoch : 1 | [2400/10236 (23%)]	Loss: 0.651706
| Global Round : 0 | Local Epoch : 1 | [2500/10236 (24%)]	Loss: 0.898989
| Global Round : 0 | Local Epoch : 1 | [2600/10236 (25%)]	Loss: 0.704540
| Global Round : 0 | Local Epoch : 1 | [2700/10236 (26%)]	Loss: 0.770400
| Global Round : 0 | Local Epoch : 1 | [2800/10236 (27%)]	Loss: 0.652017
| Global Round : 0 | Local Epoch : 1 | [2900/10236 (28%)]	Loss: 0.633209
| Global Round : 0 | Local Epoch : 1 | [3000/10236 (29%)]	Loss: 0.562436
| Global Round : 0 | Local Epoch : 1 | [3100/10236 (30%)]	Loss: 0.468619
| Global Round : 0 | Local Epoch : 1 | [3200/10236 (31%)]	Loss: 0.659700
| Global Round : 0 | Local Epoch : 1 | [3300/10236 (32%)]	Loss: 0.472959
| Global Round : 0 | Local Epoch : 1 | [3400/10236 (33%)]	Loss: 0.587917
| Global Round : 0 | Local Epoch : 1 | [3500/10236 (34%)]	Loss: 0.551914
| Global Round : 0 | Local Epoch : 1 | [3600/10236 (35%)]	Loss: 0.660976
| Global Round : 0 | Local Epoch : 1 | [3700/10236 (36%)]	Loss: 0.707156
| Global Round : 0 | Local Epoch : 1 | [3800/10236 (37%)]	Loss: 0.575837
| Global Round : 0 | Local Epoch : 1 | [3900/10236 (38%)]	Loss: 0.489998
| Global Round : 0 | Local Epoch : 1 | [4000/10236 (39%)]	Loss: 1.104797
| Global Round : 0 | Local Epoch : 1 | [4100/10236 (40%)]	Loss: 0.535553
| Global Round : 0 | Local Epoch : 1 | [4200/10236 (41%)]	Loss: 0.461605
| Global Round : 0 | Local Epoch : 1 | [4300/10236 (42%)]	Loss: 0.480289
| Global Round : 0 | Local Epoch : 1 | [4400/10236 (43%)]	Loss: 0.438320
| Global Round : 0 | Local Epoch : 1 | [4500/10236 (44%)]	Loss: 0.450279
| Global Round : 0 | Local Epoch : 1 | [4600/10236 (45%)]	Loss: 0.444548
| Global Round : 0 | Local Epoch : 1 | [4700/10236 (46%)]	Loss: 0.719855
| Global Round : 0 | Local Epoch : 1 | [4800/10236 (47%)]	Loss: 0.521206
| Global Round : 0 | Local Epoch : 1 | [4900/10236 (48%)]	Loss: 0.605984
| Global Round : 0 | Local Epoch : 1 | [5000/10236 (49%)]	Loss: 0.401778
| Global Round : 0 | Local Epoch : 1 | [5100/10236 (50%)]	Loss: 0.564131
| Global Round : 0 | Local Epoch : 1 | [5200/10236 (51%)]	Loss: 0.535493
| Global Round : 0 | Local Epoch : 1 | [5300/10236 (52%)]	Loss: 0.548607
| Global Round : 0 | Local Epoch : 1 | [5400/10236 (53%)]	Loss: 0.540616
| Global Round : 0 | Local Epoch : 1 | [5500/10236 (54%)]	Loss: 0.540910
| Global Round : 0 | Local Epoch : 1 | [5600/10236 (55%)]	Loss: 0.962195
| Global Round : 0 | Local Epoch : 1 | [5700/10236 (56%)]	Loss: 0.389093
| Global Round : 0 | Local Epoch : 1 | [5800/10236 (57%)]	Loss: 0.599138
| Global Round : 0 | Local Epoch : 1 | [5900/10236 (58%)]	Loss: 0.383382
| Global Round : 0 | Local Epoch : 1 | [6000/10236 (59%)]	Loss: 0.372023
| Global Round : 0 | Local Epoch : 1 | [6100/10236 (60%)]	Loss: 0.537154
| Global Round : 0 | Local Epoch : 1 | [6200/10236 (61%)]	Loss: 0.421700
| Global Round : 0 | Local Epoch : 1 | [6300/10236 (62%)]	Loss: 0.744917
| Global Round : 0 | Local Epoch : 1 | [6400/10236 (62%)]	Loss: 0.399797
| Global Round : 0 | Local Epoch : 1 | [6500/10236 (63%)]	Loss: 0.320421
| Global Round : 0 | Local Epoch : 1 | [6600/10236 (64%)]	Loss: 0.702395
| Global Round : 0 | Local Epoch : 1 | [6700/10236 (65%)]	Loss: 0.401705
| Global Round : 0 | Local Epoch : 1 | [6800/10236 (66%)]	Loss: 0.450942
| Global Round : 0 | Local Epoch : 1 | [6900/10236 (67%)]	Loss: 0.470174
| Global Round : 0 | Local Epoch : 1 | [7000/10236 (68%)]	Loss: 0.220628
| Global Round : 0 | Local Epoch : 1 | [7100/10236 (69%)]	Loss: 0.864925
| Global Round : 0 | Local Epoch : 1 | [7200/10236 (70%)]	Loss: 0.422933
| Global Round : 0 | Local Epoch : 1 | [7300/10236 (71%)]	Loss: 0.466477
| Global Round : 0 | Local Epoch : 1 | [7400/10236 (72%)]	Loss: 0.524161
| Global Round : 0 | Local Epoch : 1 | [7500/10236 (73%)]	Loss: 0.632156
| Global Round : 0 | Local Epoch : 1 | [7600/10236 (74%)]	Loss: 0.556009
| Global Round : 0 | Local Epoch : 1 | [7700/10236 (75%)]	Loss: 0.580823
| Global Round : 0 | Local Epoch : 1 | [7800/10236 (76%)]	Loss: 0.549960
| Global Round : 0 | Local Epoch : 1 | [7900/10236 (77%)]	Loss: 0.727945
| Global Round : 0 | Local Epoch : 1 | [8000/10236 (78%)]	Loss: 0.438806
| Global Round : 0 | Local Epoch : 1 | [8100/10236 (79%)]	Loss: 0.390943
| Global Round : 0 | Local Epoch : 1 | [8200/10236 (80%)]	Loss: 0.802785
| Global Round : 0 | Local Epoch : 1 | [8300/10236 (81%)]	Loss: 0.493423
| Global Round : 0 | Local Epoch : 1 | [8400/10236 (82%)]	Loss: 0.852287
| Global Round : 0 | Local Epoch : 1 | [8500/10236 (83%)]	Loss: 0.472259
| Global Round : 0 | Local Epoch : 1 | [8600/10236 (84%)]	Loss: 0.398605
| Global Round : 0 | Local Epoch : 1 | [8700/10236 (85%)]	Loss: 0.468367
| Global Round : 0 | Local Epoch : 1 | [8800/10236 (86%)]	Loss: 0.819494
| Global Round : 0 | Local Epoch : 1 | [8900/10236 (87%)]	Loss: 0.634132
| Global Round : 0 | Local Epoch : 1 | [9000/10236 (88%)]	Loss: 0.600444
| Global Round : 0 | Local Epoch : 1 | [9100/10236 (89%)]	Loss: 0.551811
| Global Round : 0 | Local Epoch : 1 | [9200/10236 (90%)]	Loss: 0.445814
| Global Round : 0 | Local Epoch : 1 | [9300/10236 (91%)]	Loss: 0.588906
| Global Round : 0 | Local Epoch : 1 | [9400/10236 (92%)]	Loss: 0.224034
| Global Round : 0 | Local Epoch : 1 | [9500/10236 (93%)]	Loss: 0.568614
| Global Round : 0 | Local Epoch : 1 | [9600/10236 (94%)]	Loss: 0.553055
| Global Round : 0 | Local Epoch : 1 | [9700/10236 (95%)]	Loss: 0.457580
| Global Round : 0 | Local Epoch : 1 | [9800/10236 (96%)]	Loss: 0.633106
| Global Round : 0 | Local Epoch : 1 | [9900/10236 (97%)]	Loss: 0.478284
| Global Round : 0 | Local Epoch : 1 | [10000/10236 (98%)]	Loss: 0.532214
| Global Round : 0 | Local Epoch : 1 | [10100/10236 (99%)]	Loss: 0.582535
| Global Round : 0 | Local Epoch : 1 | [10200/10236 (100%)]	Loss: 0.497003
| Global Round : 0 | Local Epoch : 2 | [0/10236 (0%)]	Loss: 0.685337
| Global Round : 0 | Local Epoch : 2 | [100/10236 (1%)]	Loss: 0.383608
| Global Round : 0 | Local Epoch : 2 | [200/10236 (2%)]	Loss: 0.402485
| Global Round : 0 | Local Epoch : 2 | [300/10236 (3%)]	Loss: 0.444125
| Global Round : 0 | Local Epoch : 2 | [400/10236 (4%)]	Loss: 0.293797
| Global Round : 0 | Local Epoch : 2 | [500/10236 (5%)]	Loss: 0.391947
| Global Round : 0 | Local Epoch : 2 | [600/10236 (6%)]	Loss: 0.752421
| Global Round : 0 | Local Epoch : 2 | [700/10236 (7%)]	Loss: 0.561949
| Global Round : 0 | Local Epoch : 2 | [800/10236 (8%)]	Loss: 0.462392
| Global Round : 0 | Local Epoch : 2 | [900/10236 (9%)]	Loss: 0.372092
| Global Round : 0 | Local Epoch : 2 | [1000/10236 (10%)]	Loss: 0.758366
| Global Round : 0 | Local Epoch : 2 | [1100/10236 (11%)]	Loss: 0.482996
| Global Round : 0 | Local Epoch : 2 | [1200/10236 (12%)]	Loss: 0.612190
| Global Round : 0 | Local Epoch : 2 | [1300/10236 (13%)]	Loss: 0.747827
| Global Round : 0 | Local Epoch : 2 | [1400/10236 (14%)]	Loss: 0.500045
| Global Round : 0 | Local Epoch : 2 | [1500/10236 (15%)]	Loss: 0.494188
| Global Round : 0 | Local Epoch : 2 | [1600/10236 (16%)]	Loss: 0.381293
| Global Round : 0 | Local Epoch : 2 | [1700/10236 (17%)]	Loss: 0.532796
| Global Round : 0 | Local Epoch : 2 | [1800/10236 (18%)]	Loss: 0.410097
| Global Round : 0 | Local Epoch : 2 | [1900/10236 (19%)]	Loss: 0.505321
| Global Round : 0 | Local Epoch : 2 | [2000/10236 (20%)]	Loss: 0.515442
| Global Round : 0 | Local Epoch : 2 | [2100/10236 (21%)]	Loss: 0.318833
| Global Round : 0 | Local Epoch : 2 | [2200/10236 (21%)]	Loss: 0.488199
| Global Round : 0 | Local Epoch : 2 | [2300/10236 (22%)]	Loss: 0.721438
| Global Round : 0 | Local Epoch : 2 | [2400/10236 (23%)]	Loss: 0.342137
| Global Round : 0 | Local Epoch : 2 | [2500/10236 (24%)]	Loss: 0.915165
| Global Round : 0 | Local Epoch : 2 | [2600/10236 (25%)]	Loss: 0.413936
| Global Round : 0 | Local Epoch : 2 | [2700/10236 (26%)]	Loss: 0.708125
| Global Round : 0 | Local Epoch : 2 | [2800/10236 (27%)]	Loss: 0.597826
| Global Round : 0 | Local Epoch : 2 | [2900/10236 (28%)]	Loss: 0.569381
| Global Round : 0 | Local Epoch : 2 | [3000/10236 (29%)]	Loss: 0.499641
| Global Round : 0 | Local Epoch : 2 | [3100/10236 (30%)]	Loss: 0.447466
| Global Round : 0 | Local Epoch : 2 | [3200/10236 (31%)]	Loss: 0.434169
| Global Round : 0 | Local Epoch : 2 | [3300/10236 (32%)]	Loss: 0.411726
| Global Round : 0 | Local Epoch : 2 | [3400/10236 (33%)]	Loss: 0.324698
| Global Round : 0 | Local Epoch : 2 | [3500/10236 (34%)]	Loss: 0.291219
| Global Round : 0 | Local Epoch : 2 | [3600/10236 (35%)]	Loss: 0.208580
| Global Round : 0 | Local Epoch : 2 | [3700/10236 (36%)]	Loss: 0.404965
| Global Round : 0 | Local Epoch : 2 | [3800/10236 (37%)]	Loss: 0.288032
| Global Round : 0 | Local Epoch : 2 | [3900/10236 (38%)]	Loss: 0.372909
| Global Round : 0 | Local Epoch : 2 | [4000/10236 (39%)]	Loss: 0.397915
| Global Round : 0 | Local Epoch : 2 | [4100/10236 (40%)]	Loss: 0.405511
| Global Round : 0 | Local Epoch : 2 | [4200/10236 (41%)]	Loss: 0.348081
| Global Round : 0 | Local Epoch : 2 | [4300/10236 (42%)]	Loss: 0.287512
| Global Round : 0 | Local Epoch : 2 | [4400/10236 (43%)]	Loss: 0.264930
| Global Round : 0 | Local Epoch : 2 | [4500/10236 (44%)]	Loss: 0.685340
| Global Round : 0 | Local Epoch : 2 | [4600/10236 (45%)]	Loss: 0.471263
| Global Round : 0 | Local Epoch : 2 | [4700/10236 (46%)]	Loss: 0.589372
| Global Round : 0 | Local Epoch : 2 | [4800/10236 (47%)]	Loss: 0.420296
| Global Round : 0 | Local Epoch : 2 | [4900/10236 (48%)]	Loss: 0.315819
| Global Round : 0 | Local Epoch : 2 | [5000/10236 (49%)]	Loss: 0.469930
| Global Round : 0 | Local Epoch : 2 | [5100/10236 (50%)]	Loss: 0.579455
| Global Round : 0 | Local Epoch : 2 | [5200/10236 (51%)]	Loss: 0.483518
| Global Round : 0 | Local Epoch : 2 | [5300/10236 (52%)]	Loss: 0.833444
| Global Round : 0 | Local Epoch : 2 | [5400/10236 (53%)]	Loss: 1.056953
| Global Round : 0 | Local Epoch : 2 | [5500/10236 (54%)]	Loss: 0.441238
| Global Round : 0 | Local Epoch : 2 | [5600/10236 (55%)]	Loss: 0.708378
| Global Round : 0 | Local Epoch : 2 | [5700/10236 (56%)]	Loss: 0.330050
| Global Round : 0 | Local Epoch : 2 | [5800/10236 (57%)]	Loss: 0.730723
| Global Round : 0 | Local Epoch : 2 | [5900/10236 (58%)]	Loss: 0.580670
| Global Round : 0 | Local Epoch : 2 | [6000/10236 (59%)]	Loss: 0.422644
| Global Round : 0 | Local Epoch : 2 | [6100/10236 (60%)]	Loss: 0.349474
| Global Round : 0 | Local Epoch : 2 | [6200/10236 (61%)]	Loss: 0.406159
| Global Round : 0 | Local Epoch : 2 | [6300/10236 (62%)]	Loss: 0.539866
| Global Round : 0 | Local Epoch : 2 | [6400/10236 (62%)]	Loss: 0.312885
| Global Round : 0 | Local Epoch : 2 | [6500/10236 (63%)]	Loss: 0.576826
| Global Round : 0 | Local Epoch : 2 | [6600/10236 (64%)]	Loss: 0.496178
| Global Round : 0 | Local Epoch : 2 | [6700/10236 (65%)]	Loss: 0.402733
| Global Round : 0 | Local Epoch : 2 | [6800/10236 (66%)]	Loss: 0.336840
| Global Round : 0 | Local Epoch : 2 | [6900/10236 (67%)]	Loss: 0.447061
| Global Round : 0 | Local Epoch : 2 | [7000/10236 (68%)]	Loss: 0.462813
| Global Round : 0 | Local Epoch : 2 | [7100/10236 (69%)]	Loss: 0.556154
| Global Round : 0 | Local Epoch : 2 | [7200/10236 (70%)]	Loss: 0.443178
| Global Round : 0 | Local Epoch : 2 | [7300/10236 (71%)]	Loss: 0.702593
| Global Round : 0 | Local Epoch : 2 | [7400/10236 (72%)]	Loss: 0.914094
| Global Round : 0 | Local Epoch : 2 | [7500/10236 (73%)]	Loss: 0.558556
| Global Round : 0 | Local Epoch : 2 | [7600/10236 (74%)]	Loss: 0.427406
| Global Round : 0 | Local Epoch : 2 | [7700/10236 (75%)]	Loss: 0.553491
| Global Round : 0 | Local Epoch : 2 | [7800/10236 (76%)]	Loss: 0.503857
| Global Round : 0 | Local Epoch : 2 | [7900/10236 (77%)]	Loss: 0.458243
| Global Round : 0 | Local Epoch : 2 | [8000/10236 (78%)]	Loss: 0.458223
| Global Round : 0 | Local Epoch : 2 | [8100/10236 (79%)]	Loss: 0.339101
| Global Round : 0 | Local Epoch : 2 | [8200/10236 (80%)]	Loss: 0.270853
| Global Round : 0 | Local Epoch : 2 | [8300/10236 (81%)]	Loss: 0.539107
| Global Round : 0 | Local Epoch : 2 | [8400/10236 (82%)]	Loss: 0.621951
| Global Round : 0 | Local Epoch : 2 | [8500/10236 (83%)]	Loss: 0.611251
| Global Round : 0 | Local Epoch : 2 | [8600/10236 (84%)]	Loss: 0.474357
| Global Round : 0 | Local Epoch : 2 | [8700/10236 (85%)]	Loss: 0.505461
| Global Round : 0 | Local Epoch : 2 | [8800/10236 (86%)]	Loss: 0.299851
| Global Round : 0 | Local Epoch : 2 | [8900/10236 (87%)]	Loss: 0.944823
| Global Round : 0 | Local Epoch : 2 | [9000/10236 (88%)]	Loss: 0.284896
| Global Round : 0 | Local Epoch : 2 | [9100/10236 (89%)]	Loss: 0.665468
| Global Round : 0 | Local Epoch : 2 | [9200/10236 (90%)]	Loss: 0.433259
| Global Round : 0 | Local Epoch : 2 | [9300/10236 (91%)]	Loss: 0.516192
| Global Round : 0 | Local Epoch : 2 | [9400/10236 (92%)]	Loss: 0.310664
| Global Round : 0 | Local Epoch : 2 | [9500/10236 (93%)]	Loss: 0.462473
| Global Round : 0 | Local Epoch : 2 | [9600/10236 (94%)]	Loss: 0.884597
| Global Round : 0 | Local Epoch : 2 | [9700/10236 (95%)]	Loss: 0.381529
| Global Round : 0 | Local Epoch : 2 | [9800/10236 (96%)]	Loss: 0.236561
| Global Round : 0 | Local Epoch : 2 | [9900/10236 (97%)]	Loss: 0.500758
| Global Round : 0 | Local Epoch : 2 | [10000/10236 (98%)]	Loss: 0.331712
| Global Round : 0 | Local Epoch : 2 | [10100/10236 (99%)]	Loss: 0.953082
| Global Round : 0 | Local Epoch : 2 | [10200/10236 (100%)]	Loss: 0.449415
| Global Round : 0 | Local Epoch : 3 | [0/10236 (0%)]	Loss: 0.408050
| Global Round : 0 | Local Epoch : 3 | [100/10236 (1%)]	Loss: 0.577559
| Global Round : 0 | Local Epoch : 3 | [200/10236 (2%)]	Loss: 0.435046
| Global Round : 0 | Local Epoch : 3 | [300/10236 (3%)]	Loss: 0.407072
| Global Round : 0 | Local Epoch : 3 | [400/10236 (4%)]	Loss: 0.326204
| Global Round : 0 | Local Epoch : 3 | [500/10236 (5%)]	Loss: 0.177641
| Global Round : 0 | Local Epoch : 3 | [600/10236 (6%)]	Loss: 0.337307
| Global Round : 0 | Local Epoch : 3 | [700/10236 (7%)]	Loss: 0.272087
| Global Round : 0 | Local Epoch : 3 | [800/10236 (8%)]	Loss: 0.310986
| Global Round : 0 | Local Epoch : 3 | [900/10236 (9%)]	Loss: 0.342875
| Global Round : 0 | Local Epoch : 3 | [1000/10236 (10%)]	Loss: 0.319782
| Global Round : 0 | Local Epoch : 3 | [1100/10236 (11%)]	Loss: 0.565368
| Global Round : 0 | Local Epoch : 3 | [1200/10236 (12%)]	Loss: 0.677691
| Global Round : 0 | Local Epoch : 3 | [1300/10236 (13%)]	Loss: 0.271663
| Global Round : 0 | Local Epoch : 3 | [1400/10236 (14%)]	Loss: 0.514066
| Global Round : 0 | Local Epoch : 3 | [1500/10236 (15%)]	Loss: 0.333492
| Global Round : 0 | Local Epoch : 3 | [1600/10236 (16%)]	Loss: 0.230149
| Global Round : 0 | Local Epoch : 3 | [1700/10236 (17%)]	Loss: 0.528323
| Global Round : 0 | Local Epoch : 3 | [1800/10236 (18%)]	Loss: 0.544206
| Global Round : 0 | Local Epoch : 3 | [1900/10236 (19%)]	Loss: 0.294755
| Global Round : 0 | Local Epoch : 3 | [2000/10236 (20%)]	Loss: 0.214369
| Global Round : 0 | Local Epoch : 3 | [2100/10236 (21%)]	Loss: 0.451004
| Global Round : 0 | Local Epoch : 3 | [2200/10236 (21%)]	Loss: 0.495414
| Global Round : 0 | Local Epoch : 3 | [2300/10236 (22%)]	Loss: 0.283203
| Global Round : 0 | Local Epoch : 3 | [2400/10236 (23%)]	Loss: 0.307974
| Global Round : 0 | Local Epoch : 3 | [2500/10236 (24%)]	Loss: 0.320574
| Global Round : 0 | Local Epoch : 3 | [2600/10236 (25%)]	Loss: 0.648313
| Global Round : 0 | Local Epoch : 3 | [2700/10236 (26%)]	Loss: 0.576147
| Global Round : 0 | Local Epoch : 3 | [2800/10236 (27%)]	Loss: 0.282149
| Global Round : 0 | Local Epoch : 3 | [2900/10236 (28%)]	Loss: 0.444587
| Global Round : 0 | Local Epoch : 3 | [3000/10236 (29%)]	Loss: 0.279808
| Global Round : 0 | Local Epoch : 3 | [3100/10236 (30%)]	Loss: 0.573148
| Global Round : 0 | Local Epoch : 3 | [3200/10236 (31%)]	Loss: 0.474689
| Global Round : 0 | Local Epoch : 3 | [3300/10236 (32%)]	Loss: 0.383804
| Global Round : 0 | Local Epoch : 3 | [3400/10236 (33%)]	Loss: 0.267914
| Global Round : 0 | Local Epoch : 3 | [3500/10236 (34%)]	Loss: 0.524249
| Global Round : 0 | Local Epoch : 3 | [3600/10236 (35%)]	Loss: 0.439677
| Global Round : 0 | Local Epoch : 3 | [3700/10236 (36%)]	Loss: 0.447202
| Global Round : 0 | Local Epoch : 3 | [3800/10236 (37%)]	Loss: 0.319700
| Global Round : 0 | Local Epoch : 3 | [3900/10236 (38%)]	Loss: 0.630363
| Global Round : 0 | Local Epoch : 3 | [4000/10236 (39%)]	Loss: 0.267622
| Global Round : 0 | Local Epoch : 3 | [4100/10236 (40%)]	Loss: 0.360937
| Global Round : 0 | Local Epoch : 3 | [4200/10236 (41%)]	Loss: 0.108223
| Global Round : 0 | Local Epoch : 3 | [4300/10236 (42%)]	Loss: 0.334798
| Global Round : 0 | Local Epoch : 3 | [4400/10236 (43%)]	Loss: 0.377891
| Global Round : 0 | Local Epoch : 3 | [4500/10236 (44%)]	Loss: 0.353593
| Global Round : 0 | Local Epoch : 3 | [4600/10236 (45%)]	Loss: 0.342364
| Global Round : 0 | Local Epoch : 3 | [4700/10236 (46%)]	Loss: 0.445815
| Global Round : 0 | Local Epoch : 3 | [4800/10236 (47%)]	Loss: 0.659237
| Global Round : 0 | Local Epoch : 3 | [4900/10236 (48%)]	Loss: 0.215485
| Global Round : 0 | Local Epoch : 3 | [5000/10236 (49%)]	Loss: 0.191546
| Global Round : 0 | Local Epoch : 3 | [5100/10236 (50%)]	Loss: 0.455926
| Global Round : 0 | Local Epoch : 3 | [5200/10236 (51%)]	Loss: 0.677394
| Global Round : 0 | Local Epoch : 3 | [5300/10236 (52%)]	Loss: 0.463770
| Global Round : 0 | Local Epoch : 3 | [5400/10236 (53%)]	Loss: 0.173482
| Global Round : 0 | Local Epoch : 3 | [5500/10236 (54%)]	Loss: 0.322313
| Global Round : 0 | Local Epoch : 3 | [5600/10236 (55%)]	Loss: 0.229195
| Global Round : 0 | Local Epoch : 3 | [5700/10236 (56%)]	Loss: 0.278326
| Global Round : 0 | Local Epoch : 3 | [5800/10236 (57%)]	Loss: 0.455259
| Global Round : 0 | Local Epoch : 3 | [5900/10236 (58%)]	Loss: 0.922455
| Global Round : 0 | Local Epoch : 3 | [6000/10236 (59%)]	Loss: 0.341259
| Global Round : 0 | Local Epoch : 3 | [6100/10236 (60%)]	Loss: 0.374746
| Global Round : 0 | Local Epoch : 3 | [6200/10236 (61%)]	Loss: 0.308401
| Global Round : 0 | Local Epoch : 3 | [6300/10236 (62%)]	Loss: 0.460487
| Global Round : 0 | Local Epoch : 3 | [6400/10236 (62%)]	Loss: 0.354956
| Global Round : 0 | Local Epoch : 3 | [6500/10236 (63%)]	Loss: 0.635392
| Global Round : 0 | Local Epoch : 3 | [6600/10236 (64%)]	Loss: 0.730330
| Global Round : 0 | Local Epoch : 3 | [6700/10236 (65%)]	Loss: 0.539432
| Global Round : 0 | Local Epoch : 3 | [6800/10236 (66%)]	Loss: 0.325515
| Global Round : 0 | Local Epoch : 3 | [6900/10236 (67%)]	Loss: 0.318415
| Global Round : 0 | Local Epoch : 3 | [7000/10236 (68%)]	Loss: 0.227503
| Global Round : 0 | Local Epoch : 3 | [7100/10236 (69%)]	Loss: 0.462916
| Global Round : 0 | Local Epoch : 3 | [7200/10236 (70%)]	Loss: 0.469763
| Global Round : 0 | Local Epoch : 3 | [7300/10236 (71%)]	Loss: 0.330020
| Global Round : 0 | Local Epoch : 3 | [7400/10236 (72%)]	Loss: 0.575954
| Global Round : 0 | Local Epoch : 3 | [7500/10236 (73%)]	Loss: 0.455326
| Global Round : 0 | Local Epoch : 3 | [7600/10236 (74%)]	Loss: 0.619720
| Global Round : 0 | Local Epoch : 3 | [7700/10236 (75%)]	Loss: 0.331358
| Global Round : 0 | Local Epoch : 3 | [7800/10236 (76%)]	Loss: 0.520870
| Global Round : 0 | Local Epoch : 3 | [7900/10236 (77%)]	Loss: 0.123338
| Global Round : 0 | Local Epoch : 3 | [8000/10236 (78%)]	Loss: 0.761227
| Global Round : 0 | Local Epoch : 3 | [8100/10236 (79%)]	Loss: 0.279952
| Global Round : 0 | Local Epoch : 3 | [8200/10236 (80%)]	Loss: 0.152649
| Global Round : 0 | Local Epoch : 3 | [8300/10236 (81%)]	Loss: 0.155384
| Global Round : 0 | Local Epoch : 3 | [8400/10236 (82%)]	Loss: 0.410411
| Global Round : 0 | Local Epoch : 3 | [8500/10236 (83%)]	Loss: 1.266319
| Global Round : 0 | Local Epoch : 3 | [8600/10236 (84%)]	Loss: 0.548619
| Global Round : 0 | Local Epoch : 3 | [8700/10236 (85%)]	Loss: 0.207021
| Global Round : 0 | Local Epoch : 3 | [8800/10236 (86%)]	Loss: 0.326725
| Global Round : 0 | Local Epoch : 3 | [8900/10236 (87%)]	Loss: 0.154670
| Global Round : 0 | Local Epoch : 3 | [9000/10236 (88%)]	Loss: 0.372081
| Global Round : 0 | Local Epoch : 3 | [9100/10236 (89%)]	Loss: 0.611066
| Global Round : 0 | Local Epoch : 3 | [9200/10236 (90%)]	Loss: 0.183052
| Global Round : 0 | Local Epoch : 3 | [9300/10236 (91%)]	Loss: 0.302792
| Global Round : 0 | Local Epoch : 3 | [9400/10236 (92%)]	Loss: 0.226482
| Global Round : 0 | Local Epoch : 3 | [9500/10236 (93%)]	Loss: 0.307493
| Global Round : 0 | Local Epoch : 3 | [9600/10236 (94%)]	Loss: 0.518933
| Global Round : 0 | Local Epoch : 3 | [9700/10236 (95%)]	Loss: 0.354006
| Global Round : 0 | Local Epoch : 3 | [9800/10236 (96%)]	Loss: 0.449819
| Global Round : 0 | Local Epoch : 3 | [9900/10236 (97%)]	Loss: 0.579393
| Global Round : 0 | Local Epoch : 3 | [10000/10236 (98%)]	Loss: 0.253915
| Global Round : 0 | Local Epoch : 3 | [10100/10236 (99%)]	Loss: 0.212943
| Global Round : 0 | Local Epoch : 3 | [10200/10236 (100%)]	Loss: 0.566105
| Global Round : 0 | Local Epoch : 4 | [0/10236 (0%)]	Loss: 0.393131
| Global Round : 0 | Local Epoch : 4 | [100/10236 (1%)]	Loss: 0.546921
| Global Round : 0 | Local Epoch : 4 | [200/10236 (2%)]	Loss: 0.624590
| Global Round : 0 | Local Epoch : 4 | [300/10236 (3%)]	Loss: 0.420058
| Global Round : 0 | Local Epoch : 4 | [400/10236 (4%)]	Loss: 0.326660
| Global Round : 0 | Local Epoch : 4 | [500/10236 (5%)]	Loss: 0.521277
| Global Round : 0 | Local Epoch : 4 | [600/10236 (6%)]	Loss: 0.223609
| Global Round : 0 | Local Epoch : 4 | [700/10236 (7%)]	Loss: 0.335232
| Global Round : 0 | Local Epoch : 4 | [800/10236 (8%)]	Loss: 0.178020
| Global Round : 0 | Local Epoch : 4 | [900/10236 (9%)]	Loss: 0.949587
| Global Round : 0 | Local Epoch : 4 | [1000/10236 (10%)]	Loss: 0.181190
| Global Round : 0 | Local Epoch : 4 | [1100/10236 (11%)]	Loss: 0.313738
| Global Round : 0 | Local Epoch : 4 | [1200/10236 (12%)]	Loss: 0.532445
| Global Round : 0 | Local Epoch : 4 | [1300/10236 (13%)]	Loss: 0.553396
| Global Round : 0 | Local Epoch : 4 | [1400/10236 (14%)]	Loss: 0.343635
| Global Round : 0 | Local Epoch : 4 | [1500/10236 (15%)]	Loss: 0.423278
| Global Round : 0 | Local Epoch : 4 | [1600/10236 (16%)]	Loss: 0.244450
| Global Round : 0 | Local Epoch : 4 | [1700/10236 (17%)]	Loss: 0.553826
| Global Round : 0 | Local Epoch : 4 | [1800/10236 (18%)]	Loss: 0.190090
| Global Round : 0 | Local Epoch : 4 | [1900/10236 (19%)]	Loss: 0.760902
| Global Round : 0 | Local Epoch : 4 | [2000/10236 (20%)]	Loss: 0.484371
| Global Round : 0 | Local Epoch : 4 | [2100/10236 (21%)]	Loss: 0.163500
| Global Round : 0 | Local Epoch : 4 | [2200/10236 (21%)]	Loss: 0.716214
| Global Round : 0 | Local Epoch : 4 | [2300/10236 (22%)]	Loss: 0.176638
| Global Round : 0 | Local Epoch : 4 | [2400/10236 (23%)]	Loss: 0.417048
| Global Round : 0 | Local Epoch : 4 | [2500/10236 (24%)]	Loss: 0.465181
| Global Round : 0 | Local Epoch : 4 | [2600/10236 (25%)]	Loss: 0.371803
| Global Round : 0 | Local Epoch : 4 | [2700/10236 (26%)]	Loss: 0.804273
| Global Round : 0 | Local Epoch : 4 | [2800/10236 (27%)]	Loss: 0.297382
| Global Round : 0 | Local Epoch : 4 | [2900/10236 (28%)]	Loss: 0.360061
| Global Round : 0 | Local Epoch : 4 | [3000/10236 (29%)]	Loss: 0.171322
| Global Round : 0 | Local Epoch : 4 | [3100/10236 (30%)]	Loss: 0.404532
| Global Round : 0 | Local Epoch : 4 | [3200/10236 (31%)]	Loss: 0.257337
| Global Round : 0 | Local Epoch : 4 | [3300/10236 (32%)]	Loss: 0.226797
| Global Round : 0 | Local Epoch : 4 | [3400/10236 (33%)]	Loss: 0.159615
| Global Round : 0 | Local Epoch : 4 | [3500/10236 (34%)]	Loss: 0.200731
| Global Round : 0 | Local Epoch : 4 | [3600/10236 (35%)]	Loss: 0.685155
| Global Round : 0 | Local Epoch : 4 | [3700/10236 (36%)]	Loss: 0.462564
| Global Round : 0 | Local Epoch : 4 | [3800/10236 (37%)]	Loss: 0.328860
| Global Round : 0 | Local Epoch : 4 | [3900/10236 (38%)]	Loss: 0.346787
| Global Round : 0 | Local Epoch : 4 | [4000/10236 (39%)]	Loss: 0.493369
| Global Round : 0 | Local Epoch : 4 | [4100/10236 (40%)]	Loss: 0.277147
| Global Round : 0 | Local Epoch : 4 | [4200/10236 (41%)]	Loss: 0.688232
| Global Round : 0 | Local Epoch : 4 | [4300/10236 (42%)]	Loss: 0.222221
| Global Round : 0 | Local Epoch : 4 | [4400/10236 (43%)]	Loss: 0.747392
| Global Round : 0 | Local Epoch : 4 | [4500/10236 (44%)]	Loss: 0.194398
| Global Round : 0 | Local Epoch : 4 | [4600/10236 (45%)]	Loss: 0.175499
| Global Round : 0 | Local Epoch : 4 | [4700/10236 (46%)]	Loss: 0.631288
| Global Round : 0 | Local Epoch : 4 | [4800/10236 (47%)]	Loss: 0.487047
| Global Round : 0 | Local Epoch : 4 | [4900/10236 (48%)]	Loss: 0.449436
| Global Round : 0 | Local Epoch : 4 | [5000/10236 (49%)]	Loss: 0.419794
| Global Round : 0 | Local Epoch : 4 | [5100/10236 (50%)]	Loss: 0.357107
| Global Round : 0 | Local Epoch : 4 | [5200/10236 (51%)]	Loss: 0.303367
| Global Round : 0 | Local Epoch : 4 | [5300/10236 (52%)]	Loss: 0.495515
| Global Round : 0 | Local Epoch : 4 | [5400/10236 (53%)]	Loss: 0.651477
| Global Round : 0 | Local Epoch : 4 | [5500/10236 (54%)]	Loss: 0.265552
| Global Round : 0 | Local Epoch : 4 | [5600/10236 (55%)]	Loss: 0.185372
| Global Round : 0 | Local Epoch : 4 | [5700/10236 (56%)]	Loss: 0.648384
| Global Round : 0 | Local Epoch : 4 | [5800/10236 (57%)]	Loss: 0.575654
| Global Round : 0 | Local Epoch : 4 | [5900/10236 (58%)]	Loss: 0.238125
| Global Round : 0 | Local Epoch : 4 | [6000/10236 (59%)]	Loss: 0.580672
| Global Round : 0 | Local Epoch : 4 | [6100/10236 (60%)]	Loss: 0.529195
| Global Round : 0 | Local Epoch : 4 | [6200/10236 (61%)]	Loss: 0.790600
| Global Round : 0 | Local Epoch : 4 | [6300/10236 (62%)]	Loss: 0.591658
| Global Round : 0 | Local Epoch : 4 | [6400/10236 (62%)]	Loss: 0.204266
| Global Round : 0 | Local Epoch : 4 | [6500/10236 (63%)]	Loss: 0.489538
| Global Round : 0 | Local Epoch : 4 | [6600/10236 (64%)]	Loss: 0.362610
| Global Round : 0 | Local Epoch : 4 | [6700/10236 (65%)]	Loss: 0.525990
| Global Round : 0 | Local Epoch : 4 | [6800/10236 (66%)]	Loss: 0.388273
| Global Round : 0 | Local Epoch : 4 | [6900/10236 (67%)]	Loss: 0.437273
| Global Round : 0 | Local Epoch : 4 | [7000/10236 (68%)]	Loss: 0.162045
| Global Round : 0 | Local Epoch : 4 | [7100/10236 (69%)]	Loss: 0.562081
| Global Round : 0 | Local Epoch : 4 | [7200/10236 (70%)]	Loss: 0.278497
| Global Round : 0 | Local Epoch : 4 | [7300/10236 (71%)]	Loss: 0.576328
| Global Round : 0 | Local Epoch : 4 | [7400/10236 (72%)]	Loss: 0.659654
| Global Round : 0 | Local Epoch : 4 | [7500/10236 (73%)]	Loss: 0.385042
| Global Round : 0 | Local Epoch : 4 | [7600/10236 (74%)]	Loss: 0.622812
| Global Round : 0 | Local Epoch : 4 | [7700/10236 (75%)]	Loss: 0.429953
| Global Round : 0 | Local Epoch : 4 | [7800/10236 (76%)]	Loss: 0.430201
| Global Round : 0 | Local Epoch : 4 | [7900/10236 (77%)]	Loss: 0.230534
| Global Round : 0 | Local Epoch : 4 | [8000/10236 (78%)]	Loss: 0.394681
| Global Round : 0 | Local Epoch : 4 | [8100/10236 (79%)]	Loss: 0.392933
| Global Round : 0 | Local Epoch : 4 | [8200/10236 (80%)]	Loss: 0.725530
| Global Round : 0 | Local Epoch : 4 | [8300/10236 (81%)]	Loss: 0.236219
| Global Round : 0 | Local Epoch : 4 | [8400/10236 (82%)]	Loss: 0.286375
| Global Round : 0 | Local Epoch : 4 | [8500/10236 (83%)]	Loss: 0.255123
| Global Round : 0 | Local Epoch : 4 | [8600/10236 (84%)]	Loss: 0.806010
| Global Round : 0 | Local Epoch : 4 | [8700/10236 (85%)]	Loss: 0.299186
| Global Round : 0 | Local Epoch : 4 | [8800/10236 (86%)]	Loss: 0.195145
| Global Round : 0 | Local Epoch : 4 | [8900/10236 (87%)]	Loss: 0.143581
| Global Round : 0 | Local Epoch : 4 | [9000/10236 (88%)]	Loss: 0.322197
| Global Round : 0 | Local Epoch : 4 | [9100/10236 (89%)]	Loss: 0.448433
| Global Round : 0 | Local Epoch : 4 | [9200/10236 (90%)]	Loss: 0.278290
| Global Round : 0 | Local Epoch : 4 | [9300/10236 (91%)]	Loss: 0.305852
| Global Round : 0 | Local Epoch : 4 | [9400/10236 (92%)]	Loss: 0.390575
| Global Round : 0 | Local Epoch : 4 | [9500/10236 (93%)]	Loss: 0.276359
| Global Round : 0 | Local Epoch : 4 | [9600/10236 (94%)]	Loss: 0.469202
| Global Round : 0 | Local Epoch : 4 | [9700/10236 (95%)]	Loss: 0.315478
| Global Round : 0 | Local Epoch : 4 | [9800/10236 (96%)]	Loss: 0.275023
| Global Round : 0 | Local Epoch : 4 | [9900/10236 (97%)]	Loss: 0.360753
| Global Round : 0 | Local Epoch : 4 | [10000/10236 (98%)]	Loss: 0.405872
| Global Round : 0 | Local Epoch : 4 | [10100/10236 (99%)]	Loss: 0.843894
| Global Round : 0 | Local Epoch : 4 | [10200/10236 (100%)]	Loss: 0.315451
----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.77      0.78        64
         DME       0.78      0.81      0.79        64

    accuracy                           0.79       128
   macro avg       0.79      0.79      0.79       128
weighted avg       0.79      0.79      0.79       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.90      0.88        63
         DME       0.90      0.86      0.88        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.78      0.95      0.86        63
         DME       0.94      0.74      0.83        65

    accuracy                           0.84       128
   macro avg       0.86      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.90      0.88        62
         DME       0.90      0.85      0.88        66

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.84      0.82        68
         DME       0.81      0.77      0.79        60

    accuracy                           0.80       128
   macro avg       0.80      0.80      0.80       128
weighted avg       0.80      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.80      0.80        61
         DME       0.82      0.82      0.82        67

    accuracy                           0.81       128
   macro avg       0.81      0.81      0.81       128
weighted avg       0.81      0.81      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.92      0.88        66
         DME       0.91      0.81      0.85        62

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.89      0.86        57
         DME       0.91      0.86      0.88        71

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.92      0.88        63
         DME       0.92      0.83      0.87        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.86      0.87        65
         DME       0.86      0.87      0.87        63

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.77      0.78        64
      DRUSEN       0.78      0.81      0.79        64

    accuracy                           0.79       128
   macro avg       0.79      0.79      0.79       128
weighted avg       0.79      0.79      0.79       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.90      0.88        63
      DRUSEN       0.90      0.86      0.88        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.78      0.95      0.86        63
      DRUSEN       0.94      0.74      0.83        65

    accuracy                           0.84       128
   macro avg       0.86      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.85      0.90      0.88        62
      DRUSEN       0.90      0.85      0.88        66

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.84      0.82        68
      DRUSEN       0.81      0.77      0.79        60

    accuracy                           0.80       128
   macro avg       0.80      0.80      0.80       128
weighted avg       0.80      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.80      0.80        61
      DRUSEN       0.82      0.82      0.82        67

    accuracy                           0.81       128
   macro avg       0.81      0.81      0.81       128
weighted avg       0.81      0.81      0.81       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.92      0.88        66
      DRUSEN       0.91      0.81      0.85        62

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.89      0.86        57
      DRUSEN       0.91      0.86      0.88        71

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.84      0.92      0.88        63
      DRUSEN       0.92      0.83      0.87        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.86      0.87        65
      DRUSEN       0.86      0.87      0.87        63

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

Training accuracy [0.84921875]

 | Global Training Round : 2 |

----------------
user chosen 2
----------------
----------------
| Global Round : 1 | Local Epoch : 0 | [0/10244 (0%)]	Loss: 0.378329
| Global Round : 1 | Local Epoch : 0 | [100/10244 (1%)]	Loss: 0.803288
| Global Round : 1 | Local Epoch : 0 | [200/10244 (2%)]	Loss: 0.269649
| Global Round : 1 | Local Epoch : 0 | [300/10244 (3%)]	Loss: 0.550780
| Global Round : 1 | Local Epoch : 0 | [400/10244 (4%)]	Loss: 0.488353
| Global Round : 1 | Local Epoch : 0 | [500/10244 (5%)]	Loss: 0.288723
| Global Round : 1 | Local Epoch : 0 | [600/10244 (6%)]	Loss: 0.222791
| Global Round : 1 | Local Epoch : 0 | [700/10244 (7%)]	Loss: 0.226628
| Global Round : 1 | Local Epoch : 0 | [800/10244 (8%)]	Loss: 0.226653
| Global Round : 1 | Local Epoch : 0 | [900/10244 (9%)]	Loss: 0.453205
| Global Round : 1 | Local Epoch : 0 | [1000/10244 (10%)]	Loss: 0.345845
| Global Round : 1 | Local Epoch : 0 | [1100/10244 (11%)]	Loss: 0.396551
| Global Round : 1 | Local Epoch : 0 | [1200/10244 (12%)]	Loss: 0.487903
| Global Round : 1 | Local Epoch : 0 | [1300/10244 (13%)]	Loss: 0.379614
| Global Round : 1 | Local Epoch : 0 | [1400/10244 (14%)]	Loss: 0.911967
| Global Round : 1 | Local Epoch : 0 | [1500/10244 (15%)]	Loss: 0.519941
| Global Round : 1 | Local Epoch : 0 | [1600/10244 (16%)]	Loss: 0.209866
| Global Round : 1 | Local Epoch : 0 | [1700/10244 (17%)]	Loss: 0.170180
| Global Round : 1 | Local Epoch : 0 | [1800/10244 (18%)]	Loss: 0.190422
| Global Round : 1 | Local Epoch : 0 | [1900/10244 (19%)]	Loss: 0.248210
| Global Round : 1 | Local Epoch : 0 | [2000/10244 (20%)]	Loss: 0.405312
| Global Round : 1 | Local Epoch : 0 | [2100/10244 (20%)]	Loss: 0.227033
| Global Round : 1 | Local Epoch : 0 | [2200/10244 (21%)]	Loss: 0.500440
| Global Round : 1 | Local Epoch : 0 | [2300/10244 (22%)]	Loss: 0.149535
| Global Round : 1 | Local Epoch : 0 | [2400/10244 (23%)]	Loss: 0.218679
| Global Round : 1 | Local Epoch : 0 | [2500/10244 (24%)]	Loss: 0.422318
| Global Round : 1 | Local Epoch : 0 | [2600/10244 (25%)]	Loss: 0.237685
| Global Round : 1 | Local Epoch : 0 | [2700/10244 (26%)]	Loss: 0.443100
| Global Round : 1 | Local Epoch : 0 | [2800/10244 (27%)]	Loss: 0.235174
| Global Round : 1 | Local Epoch : 0 | [2900/10244 (28%)]	Loss: 0.254867
| Global Round : 1 | Local Epoch : 0 | [3000/10244 (29%)]	Loss: 0.182807
| Global Round : 1 | Local Epoch : 0 | [3100/10244 (30%)]	Loss: 0.383472
| Global Round : 1 | Local Epoch : 0 | [3200/10244 (31%)]	Loss: 0.466640
| Global Round : 1 | Local Epoch : 0 | [3300/10244 (32%)]	Loss: 0.540188
| Global Round : 1 | Local Epoch : 0 | [3400/10244 (33%)]	Loss: 0.195530
| Global Round : 1 | Local Epoch : 0 | [3500/10244 (34%)]	Loss: 0.437266
| Global Round : 1 | Local Epoch : 0 | [3600/10244 (35%)]	Loss: 0.271590
| Global Round : 1 | Local Epoch : 0 | [3700/10244 (36%)]	Loss: 0.612043
| Global Round : 1 | Local Epoch : 0 | [3800/10244 (37%)]	Loss: 0.269117
| Global Round : 1 | Local Epoch : 0 | [3900/10244 (38%)]	Loss: 0.772017
| Global Round : 1 | Local Epoch : 0 | [4000/10244 (39%)]	Loss: 0.272090
| Global Round : 1 | Local Epoch : 0 | [4100/10244 (40%)]	Loss: 0.424586
| Global Round : 1 | Local Epoch : 0 | [4200/10244 (41%)]	Loss: 0.324680
| Global Round : 1 | Local Epoch : 0 | [4300/10244 (42%)]	Loss: 0.835641
| Global Round : 1 | Local Epoch : 0 | [4400/10244 (43%)]	Loss: 0.380877
| Global Round : 1 | Local Epoch : 0 | [4500/10244 (44%)]	Loss: 0.436303
| Global Round : 1 | Local Epoch : 0 | [4600/10244 (45%)]	Loss: 0.421123
| Global Round : 1 | Local Epoch : 0 | [4700/10244 (46%)]	Loss: 0.223190
| Global Round : 1 | Local Epoch : 0 | [4800/10244 (47%)]	Loss: 0.608613
| Global Round : 1 | Local Epoch : 0 | [4900/10244 (48%)]	Loss: 0.359978
| Global Round : 1 | Local Epoch : 0 | [5000/10244 (49%)]	Loss: 0.532927
| Global Round : 1 | Local Epoch : 0 | [5100/10244 (50%)]	Loss: 0.234405
| Global Round : 1 | Local Epoch : 0 | [5200/10244 (51%)]	Loss: 0.163971
| Global Round : 1 | Local Epoch : 0 | [5300/10244 (52%)]	Loss: 0.240255
| Global Round : 1 | Local Epoch : 0 | [5400/10244 (53%)]	Loss: 0.165425
| Global Round : 1 | Local Epoch : 0 | [5500/10244 (54%)]	Loss: 0.361134
| Global Round : 1 | Local Epoch : 0 | [5600/10244 (55%)]	Loss: 0.426848
| Global Round : 1 | Local Epoch : 0 | [5700/10244 (56%)]	Loss: 0.453573
| Global Round : 1 | Local Epoch : 0 | [5800/10244 (57%)]	Loss: 0.375620
| Global Round : 1 | Local Epoch : 0 | [5900/10244 (58%)]	Loss: 0.476117
| Global Round : 1 | Local Epoch : 0 | [6000/10244 (59%)]	Loss: 0.443236
| Global Round : 1 | Local Epoch : 0 | [6100/10244 (60%)]	Loss: 0.303892
| Global Round : 1 | Local Epoch : 0 | [6200/10244 (60%)]	Loss: 0.494343
| Global Round : 1 | Local Epoch : 0 | [6300/10244 (61%)]	Loss: 0.254218
| Global Round : 1 | Local Epoch : 0 | [6400/10244 (62%)]	Loss: 0.501158
| Global Round : 1 | Local Epoch : 0 | [6500/10244 (63%)]	Loss: 0.197852
| Global Round : 1 | Local Epoch : 0 | [6600/10244 (64%)]	Loss: 0.276393
| Global Round : 1 | Local Epoch : 0 | [6700/10244 (65%)]	Loss: 0.296851
| Global Round : 1 | Local Epoch : 0 | [6800/10244 (66%)]	Loss: 0.631805
| Global Round : 1 | Local Epoch : 0 | [6900/10244 (67%)]	Loss: 0.439195
| Global Round : 1 | Local Epoch : 0 | [7000/10244 (68%)]	Loss: 0.400115
| Global Round : 1 | Local Epoch : 0 | [7100/10244 (69%)]	Loss: 0.566479
| Global Round : 1 | Local Epoch : 0 | [7200/10244 (70%)]	Loss: 0.275232
| Global Round : 1 | Local Epoch : 0 | [7300/10244 (71%)]	Loss: 0.645716
| Global Round : 1 | Local Epoch : 0 | [7400/10244 (72%)]	Loss: 0.323543
| Global Round : 1 | Local Epoch : 0 | [7500/10244 (73%)]	Loss: 0.536342
| Global Round : 1 | Local Epoch : 0 | [7600/10244 (74%)]	Loss: 0.349431
| Global Round : 1 | Local Epoch : 0 | [7700/10244 (75%)]	Loss: 1.105954
| Global Round : 1 | Local Epoch : 0 | [7800/10244 (76%)]	Loss: 0.372054
| Global Round : 1 | Local Epoch : 0 | [7900/10244 (77%)]	Loss: 0.319740
| Global Round : 1 | Local Epoch : 0 | [8000/10244 (78%)]	Loss: 0.261534
| Global Round : 1 | Local Epoch : 0 | [8100/10244 (79%)]	Loss: 0.468850
| Global Round : 1 | Local Epoch : 0 | [8200/10244 (80%)]	Loss: 0.455952
| Global Round : 1 | Local Epoch : 0 | [8300/10244 (81%)]	Loss: 0.210734
| Global Round : 1 | Local Epoch : 0 | [8400/10244 (82%)]	Loss: 0.365687
| Global Round : 1 | Local Epoch : 0 | [8500/10244 (83%)]	Loss: 0.738032
| Global Round : 1 | Local Epoch : 0 | [8600/10244 (84%)]	Loss: 0.593144
| Global Round : 1 | Local Epoch : 0 | [8700/10244 (85%)]	Loss: 0.326612
| Global Round : 1 | Local Epoch : 0 | [8800/10244 (86%)]	Loss: 0.625675
| Global Round : 1 | Local Epoch : 0 | [8900/10244 (87%)]	Loss: 0.229351
| Global Round : 1 | Local Epoch : 0 | [9000/10244 (88%)]	Loss: 0.240205
| Global Round : 1 | Local Epoch : 0 | [9100/10244 (89%)]	Loss: 0.546455
| Global Round : 1 | Local Epoch : 0 | [9200/10244 (90%)]	Loss: 0.345096
| Global Round : 1 | Local Epoch : 0 | [9300/10244 (91%)]	Loss: 0.509917
| Global Round : 1 | Local Epoch : 0 | [9400/10244 (92%)]	Loss: 0.524198
| Global Round : 1 | Local Epoch : 0 | [9500/10244 (93%)]	Loss: 0.524993
| Global Round : 1 | Local Epoch : 0 | [9600/10244 (94%)]	Loss: 0.481868
| Global Round : 1 | Local Epoch : 0 | [9700/10244 (95%)]	Loss: 0.177390
| Global Round : 1 | Local Epoch : 0 | [9800/10244 (96%)]	Loss: 0.382751
| Global Round : 1 | Local Epoch : 0 | [9900/10244 (97%)]	Loss: 0.119316
| Global Round : 1 | Local Epoch : 0 | [10000/10244 (98%)]	Loss: 0.205013
| Global Round : 1 | Local Epoch : 0 | [10100/10244 (99%)]	Loss: 1.333164
| Global Round : 1 | Local Epoch : 0 | [10200/10244 (100%)]	Loss: 0.150385
| Global Round : 1 | Local Epoch : 1 | [0/10244 (0%)]	Loss: 0.150804
| Global Round : 1 | Local Epoch : 1 | [100/10244 (1%)]	Loss: 0.331806
| Global Round : 1 | Local Epoch : 1 | [200/10244 (2%)]	Loss: 0.304629
| Global Round : 1 | Local Epoch : 1 | [300/10244 (3%)]	Loss: 0.444008
| Global Round : 1 | Local Epoch : 1 | [400/10244 (4%)]	Loss: 0.202123
| Global Round : 1 | Local Epoch : 1 | [500/10244 (5%)]	Loss: 0.378208
| Global Round : 1 | Local Epoch : 1 | [600/10244 (6%)]	Loss: 0.213071
| Global Round : 1 | Local Epoch : 1 | [700/10244 (7%)]	Loss: 0.286090
| Global Round : 1 | Local Epoch : 1 | [800/10244 (8%)]	Loss: 0.210213
| Global Round : 1 | Local Epoch : 1 | [900/10244 (9%)]	Loss: 0.234091
| Global Round : 1 | Local Epoch : 1 | [1000/10244 (10%)]	Loss: 0.271841
| Global Round : 1 | Local Epoch : 1 | [1100/10244 (11%)]	Loss: 0.762128
| Global Round : 1 | Local Epoch : 1 | [1200/10244 (12%)]	Loss: 0.119022
| Global Round : 1 | Local Epoch : 1 | [1300/10244 (13%)]	Loss: 0.238715
| Global Round : 1 | Local Epoch : 1 | [1400/10244 (14%)]	Loss: 0.262430
| Global Round : 1 | Local Epoch : 1 | [1500/10244 (15%)]	Loss: 0.567895
| Global Round : 1 | Local Epoch : 1 | [1600/10244 (16%)]	Loss: 0.450168
| Global Round : 1 | Local Epoch : 1 | [1700/10244 (17%)]	Loss: 0.220594
| Global Round : 1 | Local Epoch : 1 | [1800/10244 (18%)]	Loss: 0.300087
| Global Round : 1 | Local Epoch : 1 | [1900/10244 (19%)]	Loss: 0.239968
| Global Round : 1 | Local Epoch : 1 | [2000/10244 (20%)]	Loss: 0.591322
| Global Round : 1 | Local Epoch : 1 | [2100/10244 (20%)]	Loss: 0.804071
| Global Round : 1 | Local Epoch : 1 | [2200/10244 (21%)]	Loss: 0.358411
| Global Round : 1 | Local Epoch : 1 | [2300/10244 (22%)]	Loss: 0.449550
| Global Round : 1 | Local Epoch : 1 | [2400/10244 (23%)]	Loss: 0.407284
| Global Round : 1 | Local Epoch : 1 | [2500/10244 (24%)]	Loss: 0.305086
| Global Round : 1 | Local Epoch : 1 | [2600/10244 (25%)]	Loss: 0.345572
| Global Round : 1 | Local Epoch : 1 | [2700/10244 (26%)]	Loss: 0.367286
| Global Round : 1 | Local Epoch : 1 | [2800/10244 (27%)]	Loss: 0.528120
| Global Round : 1 | Local Epoch : 1 | [2900/10244 (28%)]	Loss: 0.223477
| Global Round : 1 | Local Epoch : 1 | [3000/10244 (29%)]	Loss: 0.141900
| Global Round : 1 | Local Epoch : 1 | [3100/10244 (30%)]	Loss: 0.448398
| Global Round : 1 | Local Epoch : 1 | [3200/10244 (31%)]	Loss: 0.239948
| Global Round : 1 | Local Epoch : 1 | [3300/10244 (32%)]	Loss: 0.388248
| Global Round : 1 | Local Epoch : 1 | [3400/10244 (33%)]	Loss: 0.314644
| Global Round : 1 | Local Epoch : 1 | [3500/10244 (34%)]	Loss: 0.270024
| Global Round : 1 | Local Epoch : 1 | [3600/10244 (35%)]	Loss: 0.448548
| Global Round : 1 | Local Epoch : 1 | [3700/10244 (36%)]	Loss: 0.694116
| Global Round : 1 | Local Epoch : 1 | [3800/10244 (37%)]	Loss: 0.698253
| Global Round : 1 | Local Epoch : 1 | [3900/10244 (38%)]	Loss: 0.615213
| Global Round : 1 | Local Epoch : 1 | [4000/10244 (39%)]	Loss: 0.167433
| Global Round : 1 | Local Epoch : 1 | [4100/10244 (40%)]	Loss: 0.154768
| Global Round : 1 | Local Epoch : 1 | [4200/10244 (41%)]	Loss: 0.400798
| Global Round : 1 | Local Epoch : 1 | [4300/10244 (42%)]	Loss: 0.370471
| Global Round : 1 | Local Epoch : 1 | [4400/10244 (43%)]	Loss: 0.501998
| Global Round : 1 | Local Epoch : 1 | [4500/10244 (44%)]	Loss: 0.954431
| Global Round : 1 | Local Epoch : 1 | [4600/10244 (45%)]	Loss: 0.209720
| Global Round : 1 | Local Epoch : 1 | [4700/10244 (46%)]	Loss: 0.134673
| Global Round : 1 | Local Epoch : 1 | [4800/10244 (47%)]	Loss: 0.364760
| Global Round : 1 | Local Epoch : 1 | [4900/10244 (48%)]	Loss: 0.379891
| Global Round : 1 | Local Epoch : 1 | [5000/10244 (49%)]	Loss: 0.338612
| Global Round : 1 | Local Epoch : 1 | [5100/10244 (50%)]	Loss: 0.147197
| Global Round : 1 | Local Epoch : 1 | [5200/10244 (51%)]	Loss: 0.553644
| Global Round : 1 | Local Epoch : 1 | [5300/10244 (52%)]	Loss: 0.198591
| Global Round : 1 | Local Epoch : 1 | [5400/10244 (53%)]	Loss: 0.305019
| Global Round : 1 | Local Epoch : 1 | [5500/10244 (54%)]	Loss: 0.282389
| Global Round : 1 | Local Epoch : 1 | [5600/10244 (55%)]	Loss: 0.396301
| Global Round : 1 | Local Epoch : 1 | [5700/10244 (56%)]	Loss: 0.470359
| Global Round : 1 | Local Epoch : 1 | [5800/10244 (57%)]	Loss: 0.434023
| Global Round : 1 | Local Epoch : 1 | [5900/10244 (58%)]	Loss: 0.112311
| Global Round : 1 | Local Epoch : 1 | [6000/10244 (59%)]	Loss: 0.431976
| Global Round : 1 | Local Epoch : 1 | [6100/10244 (60%)]	Loss: 0.250751
| Global Round : 1 | Local Epoch : 1 | [6200/10244 (60%)]	Loss: 0.414311
| Global Round : 1 | Local Epoch : 1 | [6300/10244 (61%)]	Loss: 0.163498
| Global Round : 1 | Local Epoch : 1 | [6400/10244 (62%)]	Loss: 0.144675
| Global Round : 1 | Local Epoch : 1 | [6500/10244 (63%)]	Loss: 0.738695
| Global Round : 1 | Local Epoch : 1 | [6600/10244 (64%)]	Loss: 0.473602
| Global Round : 1 | Local Epoch : 1 | [6700/10244 (65%)]	Loss: 0.510305
| Global Round : 1 | Local Epoch : 1 | [6800/10244 (66%)]	Loss: 0.301600
| Global Round : 1 | Local Epoch : 1 | [6900/10244 (67%)]	Loss: 0.307951
| Global Round : 1 | Local Epoch : 1 | [7000/10244 (68%)]	Loss: 0.188729
| Global Round : 1 | Local Epoch : 1 | [7100/10244 (69%)]	Loss: 0.069266
| Global Round : 1 | Local Epoch : 1 | [7200/10244 (70%)]	Loss: 0.265658
| Global Round : 1 | Local Epoch : 1 | [7300/10244 (71%)]	Loss: 0.380929
| Global Round : 1 | Local Epoch : 1 | [7400/10244 (72%)]	Loss: 0.303609
| Global Round : 1 | Local Epoch : 1 | [7500/10244 (73%)]	Loss: 0.121782
| Global Round : 1 | Local Epoch : 1 | [7600/10244 (74%)]	Loss: 0.214594
| Global Round : 1 | Local Epoch : 1 | [7700/10244 (75%)]	Loss: 0.676772
| Global Round : 1 | Local Epoch : 1 | [7800/10244 (76%)]	Loss: 0.538004
| Global Round : 1 | Local Epoch : 1 | [7900/10244 (77%)]	Loss: 0.290153
| Global Round : 1 | Local Epoch : 1 | [8000/10244 (78%)]	Loss: 0.452241
| Global Round : 1 | Local Epoch : 1 | [8100/10244 (79%)]	Loss: 0.311460
| Global Round : 1 | Local Epoch : 1 | [8200/10244 (80%)]	Loss: 0.395501
| Global Round : 1 | Local Epoch : 1 | [8300/10244 (81%)]	Loss: 0.806121
| Global Round : 1 | Local Epoch : 1 | [8400/10244 (82%)]	Loss: 0.320488
| Global Round : 1 | Local Epoch : 1 | [8500/10244 (83%)]	Loss: 0.716627
| Global Round : 1 | Local Epoch : 1 | [8600/10244 (84%)]	Loss: 0.445429
| Global Round : 1 | Local Epoch : 1 | [8700/10244 (85%)]	Loss: 0.340187
| Global Round : 1 | Local Epoch : 1 | [8800/10244 (86%)]	Loss: 0.236316
| Global Round : 1 | Local Epoch : 1 | [8900/10244 (87%)]	Loss: 0.131891
| Global Round : 1 | Local Epoch : 1 | [9000/10244 (88%)]	Loss: 0.561860
| Global Round : 1 | Local Epoch : 1 | [9100/10244 (89%)]	Loss: 0.305522
| Global Round : 1 | Local Epoch : 1 | [9200/10244 (90%)]	Loss: 0.203966
| Global Round : 1 | Local Epoch : 1 | [9300/10244 (91%)]	Loss: 0.303360
| Global Round : 1 | Local Epoch : 1 | [9400/10244 (92%)]	Loss: 0.602514
| Global Round : 1 | Local Epoch : 1 | [9500/10244 (93%)]	Loss: 0.144040
| Global Round : 1 | Local Epoch : 1 | [9600/10244 (94%)]	Loss: 0.258997
| Global Round : 1 | Local Epoch : 1 | [9700/10244 (95%)]	Loss: 0.449957
| Global Round : 1 | Local Epoch : 1 | [9800/10244 (96%)]	Loss: 0.711776
| Global Round : 1 | Local Epoch : 1 | [9900/10244 (97%)]	Loss: 0.407320
| Global Round : 1 | Local Epoch : 1 | [10000/10244 (98%)]	Loss: 0.317433
| Global Round : 1 | Local Epoch : 1 | [10100/10244 (99%)]	Loss: 0.661968
| Global Round : 1 | Local Epoch : 1 | [10200/10244 (100%)]	Loss: 0.153762
| Global Round : 1 | Local Epoch : 2 | [0/10244 (0%)]	Loss: 0.093498
| Global Round : 1 | Local Epoch : 2 | [100/10244 (1%)]	Loss: 0.332104
| Global Round : 1 | Local Epoch : 2 | [200/10244 (2%)]	Loss: 0.741102
| Global Round : 1 | Local Epoch : 2 | [300/10244 (3%)]	Loss: 0.328469
| Global Round : 1 | Local Epoch : 2 | [400/10244 (4%)]	Loss: 0.682473
| Global Round : 1 | Local Epoch : 2 | [500/10244 (5%)]	Loss: 0.586097
| Global Round : 1 | Local Epoch : 2 | [600/10244 (6%)]	Loss: 0.315821
| Global Round : 1 | Local Epoch : 2 | [700/10244 (7%)]	Loss: 0.091430
| Global Round : 1 | Local Epoch : 2 | [800/10244 (8%)]	Loss: 0.265706
| Global Round : 1 | Local Epoch : 2 | [900/10244 (9%)]	Loss: 0.322769
| Global Round : 1 | Local Epoch : 2 | [1000/10244 (10%)]	Loss: 0.162311
| Global Round : 1 | Local Epoch : 2 | [1100/10244 (11%)]	Loss: 0.293247
| Global Round : 1 | Local Epoch : 2 | [1200/10244 (12%)]	Loss: 0.240058
| Global Round : 1 | Local Epoch : 2 | [1300/10244 (13%)]	Loss: 0.590368
| Global Round : 1 | Local Epoch : 2 | [1400/10244 (14%)]	Loss: 0.148471
| Global Round : 1 | Local Epoch : 2 | [1500/10244 (15%)]	Loss: 0.418404
| Global Round : 1 | Local Epoch : 2 | [1600/10244 (16%)]	Loss: 0.335209
| Global Round : 1 | Local Epoch : 2 | [1700/10244 (17%)]	Loss: 0.475781
| Global Round : 1 | Local Epoch : 2 | [1800/10244 (18%)]	Loss: 0.832474
| Global Round : 1 | Local Epoch : 2 | [1900/10244 (19%)]	Loss: 0.058291
| Global Round : 1 | Local Epoch : 2 | [2000/10244 (20%)]	Loss: 0.351774
| Global Round : 1 | Local Epoch : 2 | [2100/10244 (20%)]	Loss: 0.403230
| Global Round : 1 | Local Epoch : 2 | [2200/10244 (21%)]	Loss: 0.769422
| Global Round : 1 | Local Epoch : 2 | [2300/10244 (22%)]	Loss: 0.460019
| Global Round : 1 | Local Epoch : 2 | [2400/10244 (23%)]	Loss: 0.123978
| Global Round : 1 | Local Epoch : 2 | [2500/10244 (24%)]	Loss: 0.127289
| Global Round : 1 | Local Epoch : 2 | [2600/10244 (25%)]	Loss: 0.165590
| Global Round : 1 | Local Epoch : 2 | [2700/10244 (26%)]	Loss: 0.168657
| Global Round : 1 | Local Epoch : 2 | [2800/10244 (27%)]	Loss: 0.616736
| Global Round : 1 | Local Epoch : 2 | [2900/10244 (28%)]	Loss: 0.569698
| Global Round : 1 | Local Epoch : 2 | [3000/10244 (29%)]	Loss: 0.550793
| Global Round : 1 | Local Epoch : 2 | [3100/10244 (30%)]	Loss: 0.497114
| Global Round : 1 | Local Epoch : 2 | [3200/10244 (31%)]	Loss: 0.234115
| Global Round : 1 | Local Epoch : 2 | [3300/10244 (32%)]	Loss: 0.742415
| Global Round : 1 | Local Epoch : 2 | [3400/10244 (33%)]	Loss: 0.213626
| Global Round : 1 | Local Epoch : 2 | [3500/10244 (34%)]	Loss: 0.299384
| Global Round : 1 | Local Epoch : 2 | [3600/10244 (35%)]	Loss: 0.515168
| Global Round : 1 | Local Epoch : 2 | [3700/10244 (36%)]	Loss: 0.348420
| Global Round : 1 | Local Epoch : 2 | [3800/10244 (37%)]	Loss: 0.118575
| Global Round : 1 | Local Epoch : 2 | [3900/10244 (38%)]	Loss: 0.359176
| Global Round : 1 | Local Epoch : 2 | [4000/10244 (39%)]	Loss: 0.200977
| Global Round : 1 | Local Epoch : 2 | [4100/10244 (40%)]	Loss: 0.278651
| Global Round : 1 | Local Epoch : 2 | [4200/10244 (41%)]	Loss: 0.119821
| Global Round : 1 | Local Epoch : 2 | [4300/10244 (42%)]	Loss: 0.213727
| Global Round : 1 | Local Epoch : 2 | [4400/10244 (43%)]	Loss: 0.433215
| Global Round : 1 | Local Epoch : 2 | [4500/10244 (44%)]	Loss: 0.094132
| Global Round : 1 | Local Epoch : 2 | [4600/10244 (45%)]	Loss: 0.187851
| Global Round : 1 | Local Epoch : 2 | [4700/10244 (46%)]	Loss: 0.178969
| Global Round : 1 | Local Epoch : 2 | [4800/10244 (47%)]	Loss: 0.263737
| Global Round : 1 | Local Epoch : 2 | [4900/10244 (48%)]	Loss: 0.211476
| Global Round : 1 | Local Epoch : 2 | [5000/10244 (49%)]	Loss: 0.186657
| Global Round : 1 | Local Epoch : 2 | [5100/10244 (50%)]	Loss: 0.476147
| Global Round : 1 | Local Epoch : 2 | [5200/10244 (51%)]	Loss: 0.142869
| Global Round : 1 | Local Epoch : 2 | [5300/10244 (52%)]	Loss: 0.082891
| Global Round : 1 | Local Epoch : 2 | [5400/10244 (53%)]	Loss: 0.249444
| Global Round : 1 | Local Epoch : 2 | [5500/10244 (54%)]	Loss: 0.250803
| Global Round : 1 | Local Epoch : 2 | [5600/10244 (55%)]	Loss: 0.185097
| Global Round : 1 | Local Epoch : 2 | [5700/10244 (56%)]	Loss: 0.222233
| Global Round : 1 | Local Epoch : 2 | [5800/10244 (57%)]	Loss: 0.299098
| Global Round : 1 | Local Epoch : 2 | [5900/10244 (58%)]	Loss: 0.182393
| Global Round : 1 | Local Epoch : 2 | [6000/10244 (59%)]	Loss: 0.299702
| Global Round : 1 | Local Epoch : 2 | [6100/10244 (60%)]	Loss: 0.403013
| Global Round : 1 | Local Epoch : 2 | [6200/10244 (60%)]	Loss: 0.315050
| Global Round : 1 | Local Epoch : 2 | [6300/10244 (61%)]	Loss: 0.237366
| Global Round : 1 | Local Epoch : 2 | [6400/10244 (62%)]	Loss: 0.280625
| Global Round : 1 | Local Epoch : 2 | [6500/10244 (63%)]	Loss: 0.230144
| Global Round : 1 | Local Epoch : 2 | [6600/10244 (64%)]	Loss: 1.023633
| Global Round : 1 | Local Epoch : 2 | [6700/10244 (65%)]	Loss: 0.372207
| Global Round : 1 | Local Epoch : 2 | [6800/10244 (66%)]	Loss: 0.474679
| Global Round : 1 | Local Epoch : 2 | [6900/10244 (67%)]	Loss: 0.229927
| Global Round : 1 | Local Epoch : 2 | [7000/10244 (68%)]	Loss: 0.314144
| Global Round : 1 | Local Epoch : 2 | [7100/10244 (69%)]	Loss: 0.787130
| Global Round : 1 | Local Epoch : 2 | [7200/10244 (70%)]	Loss: 0.351865
| Global Round : 1 | Local Epoch : 2 | [7300/10244 (71%)]	Loss: 0.111489
| Global Round : 1 | Local Epoch : 2 | [7400/10244 (72%)]	Loss: 0.102609
| Global Round : 1 | Local Epoch : 2 | [7500/10244 (73%)]	Loss: 0.070212
| Global Round : 1 | Local Epoch : 2 | [7600/10244 (74%)]	Loss: 0.378254
| Global Round : 1 | Local Epoch : 2 | [7700/10244 (75%)]	Loss: 0.424278
| Global Round : 1 | Local Epoch : 2 | [7800/10244 (76%)]	Loss: 0.103479
| Global Round : 1 | Local Epoch : 2 | [7900/10244 (77%)]	Loss: 0.488956
| Global Round : 1 | Local Epoch : 2 | [8000/10244 (78%)]	Loss: 0.359402
| Global Round : 1 | Local Epoch : 2 | [8100/10244 (79%)]	Loss: 0.223924
| Global Round : 1 | Local Epoch : 2 | [8200/10244 (80%)]	Loss: 0.066397
| Global Round : 1 | Local Epoch : 2 | [8300/10244 (81%)]	Loss: 0.155309
| Global Round : 1 | Local Epoch : 2 | [8400/10244 (82%)]	Loss: 0.278462
| Global Round : 1 | Local Epoch : 2 | [8500/10244 (83%)]	Loss: 0.331234
| Global Round : 1 | Local Epoch : 2 | [8600/10244 (84%)]	Loss: 0.334512
| Global Round : 1 | Local Epoch : 2 | [8700/10244 (85%)]	Loss: 0.113697
| Global Round : 1 | Local Epoch : 2 | [8800/10244 (86%)]	Loss: 0.363657
| Global Round : 1 | Local Epoch : 2 | [8900/10244 (87%)]	Loss: 0.278235
| Global Round : 1 | Local Epoch : 2 | [9000/10244 (88%)]	Loss: 0.202461
| Global Round : 1 | Local Epoch : 2 | [9100/10244 (89%)]	Loss: 0.163494
| Global Round : 1 | Local Epoch : 2 | [9200/10244 (90%)]	Loss: 0.355422
| Global Round : 1 | Local Epoch : 2 | [9300/10244 (91%)]	Loss: 0.264502
| Global Round : 1 | Local Epoch : 2 | [9400/10244 (92%)]	Loss: 0.196181
| Global Round : 1 | Local Epoch : 2 | [9500/10244 (93%)]	Loss: 0.195476
| Global Round : 1 | Local Epoch : 2 | [9600/10244 (94%)]	Loss: 0.493935
| Global Round : 1 | Local Epoch : 2 | [9700/10244 (95%)]	Loss: 0.543332
| Global Round : 1 | Local Epoch : 2 | [9800/10244 (96%)]	Loss: 0.254777
| Global Round : 1 | Local Epoch : 2 | [9900/10244 (97%)]	Loss: 0.357807
| Global Round : 1 | Local Epoch : 2 | [10000/10244 (98%)]	Loss: 1.137280
| Global Round : 1 | Local Epoch : 2 | [10100/10244 (99%)]	Loss: 0.170335
| Global Round : 1 | Local Epoch : 2 | [10200/10244 (100%)]	Loss: 0.086611
| Global Round : 1 | Local Epoch : 3 | [0/10244 (0%)]	Loss: 0.036298
| Global Round : 1 | Local Epoch : 3 | [100/10244 (1%)]	Loss: 0.155148
| Global Round : 1 | Local Epoch : 3 | [200/10244 (2%)]	Loss: 0.341509
| Global Round : 1 | Local Epoch : 3 | [300/10244 (3%)]	Loss: 0.188699
| Global Round : 1 | Local Epoch : 3 | [400/10244 (4%)]	Loss: 0.170650
| Global Round : 1 | Local Epoch : 3 | [500/10244 (5%)]	Loss: 0.285525
| Global Round : 1 | Local Epoch : 3 | [600/10244 (6%)]	Loss: 0.214532
| Global Round : 1 | Local Epoch : 3 | [700/10244 (7%)]	Loss: 0.082710
| Global Round : 1 | Local Epoch : 3 | [800/10244 (8%)]	Loss: 0.312239
| Global Round : 1 | Local Epoch : 3 | [900/10244 (9%)]	Loss: 0.198304
| Global Round : 1 | Local Epoch : 3 | [1000/10244 (10%)]	Loss: 0.317434
| Global Round : 1 | Local Epoch : 3 | [1100/10244 (11%)]	Loss: 0.179757
| Global Round : 1 | Local Epoch : 3 | [1200/10244 (12%)]	Loss: 0.043497
| Global Round : 1 | Local Epoch : 3 | [1300/10244 (13%)]	Loss: 0.081611
| Global Round : 1 | Local Epoch : 3 | [1400/10244 (14%)]	Loss: 0.138517
| Global Round : 1 | Local Epoch : 3 | [1500/10244 (15%)]	Loss: 0.152772
| Global Round : 1 | Local Epoch : 3 | [1600/10244 (16%)]	Loss: 0.057111
| Global Round : 1 | Local Epoch : 3 | [1700/10244 (17%)]	Loss: 0.083877
| Global Round : 1 | Local Epoch : 3 | [1800/10244 (18%)]	Loss: 0.095144
| Global Round : 1 | Local Epoch : 3 | [1900/10244 (19%)]	Loss: 0.147221
| Global Round : 1 | Local Epoch : 3 | [2000/10244 (20%)]	Loss: 0.188238
| Global Round : 1 | Local Epoch : 3 | [2100/10244 (20%)]	Loss: 0.378668
| Global Round : 1 | Local Epoch : 3 | [2200/10244 (21%)]	Loss: 0.452025
| Global Round : 1 | Local Epoch : 3 | [2300/10244 (22%)]	Loss: 0.185938
| Global Round : 1 | Local Epoch : 3 | [2400/10244 (23%)]	Loss: 0.210748
| Global Round : 1 | Local Epoch : 3 | [2500/10244 (24%)]	Loss: 0.489910
| Global Round : 1 | Local Epoch : 3 | [2600/10244 (25%)]	Loss: 0.151872
| Global Round : 1 | Local Epoch : 3 | [2700/10244 (26%)]	Loss: 0.121990
| Global Round : 1 | Local Epoch : 3 | [2800/10244 (27%)]	Loss: 0.288857
| Global Round : 1 | Local Epoch : 3 | [2900/10244 (28%)]	Loss: 0.667708
| Global Round : 1 | Local Epoch : 3 | [3000/10244 (29%)]	Loss: 0.387555
| Global Round : 1 | Local Epoch : 3 | [3100/10244 (30%)]	Loss: 0.363455
| Global Round : 1 | Local Epoch : 3 | [3200/10244 (31%)]	Loss: 1.054374
| Global Round : 1 | Local Epoch : 3 | [3300/10244 (32%)]	Loss: 0.258962
| Global Round : 1 | Local Epoch : 3 | [3400/10244 (33%)]	Loss: 0.145816
| Global Round : 1 | Local Epoch : 3 | [3500/10244 (34%)]	Loss: 0.143426
| Global Round : 1 | Local Epoch : 3 | [3600/10244 (35%)]	Loss: 0.384609
| Global Round : 1 | Local Epoch : 3 | [3700/10244 (36%)]	Loss: 0.185184
| Global Round : 1 | Local Epoch : 3 | [3800/10244 (37%)]	Loss: 0.529094
| Global Round : 1 | Local Epoch : 3 | [3900/10244 (38%)]	Loss: 0.650952
| Global Round : 1 | Local Epoch : 3 | [4000/10244 (39%)]	Loss: 0.275606
| Global Round : 1 | Local Epoch : 3 | [4100/10244 (40%)]	Loss: 0.141300
| Global Round : 1 | Local Epoch : 3 | [4200/10244 (41%)]	Loss: 0.174933
| Global Round : 1 | Local Epoch : 3 | [4300/10244 (42%)]	Loss: 0.095682
| Global Round : 1 | Local Epoch : 3 | [4400/10244 (43%)]	Loss: 0.192486
| Global Round : 1 | Local Epoch : 3 | [4500/10244 (44%)]	Loss: 0.161387
| Global Round : 1 | Local Epoch : 3 | [4600/10244 (45%)]	Loss: 0.139135
| Global Round : 1 | Local Epoch : 3 | [4700/10244 (46%)]	Loss: 0.345961
| Global Round : 1 | Local Epoch : 3 | [4800/10244 (47%)]	Loss: 0.950787
| Global Round : 1 | Local Epoch : 3 | [4900/10244 (48%)]	Loss: 0.277651
| Global Round : 1 | Local Epoch : 3 | [5000/10244 (49%)]	Loss: 0.111922
| Global Round : 1 | Local Epoch : 3 | [5100/10244 (50%)]	Loss: 0.252318
| Global Round : 1 | Local Epoch : 3 | [5200/10244 (51%)]	Loss: 0.504483
| Global Round : 1 | Local Epoch : 3 | [5300/10244 (52%)]	Loss: 0.144244
| Global Round : 1 | Local Epoch : 3 | [5400/10244 (53%)]	Loss: 0.335425
| Global Round : 1 | Local Epoch : 3 | [5500/10244 (54%)]	Loss: 0.080629
| Global Round : 1 | Local Epoch : 3 | [5600/10244 (55%)]	Loss: 0.309527
| Global Round : 1 | Local Epoch : 3 | [5700/10244 (56%)]	Loss: 0.092972
| Global Round : 1 | Local Epoch : 3 | [5800/10244 (57%)]	Loss: 0.804342
| Global Round : 1 | Local Epoch : 3 | [5900/10244 (58%)]	Loss: 0.479451
| Global Round : 1 | Local Epoch : 3 | [6000/10244 (59%)]	Loss: 0.193979
| Global Round : 1 | Local Epoch : 3 | [6100/10244 (60%)]	Loss: 0.277241
| Global Round : 1 | Local Epoch : 3 | [6200/10244 (60%)]	Loss: 0.776698
| Global Round : 1 | Local Epoch : 3 | [6300/10244 (61%)]	Loss: 0.297257
| Global Round : 1 | Local Epoch : 3 | [6400/10244 (62%)]	Loss: 0.233157
| Global Round : 1 | Local Epoch : 3 | [6500/10244 (63%)]	Loss: 0.120629
| Global Round : 1 | Local Epoch : 3 | [6600/10244 (64%)]	Loss: 0.279463
| Global Round : 1 | Local Epoch : 3 | [6700/10244 (65%)]	Loss: 0.175361
| Global Round : 1 | Local Epoch : 3 | [6800/10244 (66%)]	Loss: 0.113728
| Global Round : 1 | Local Epoch : 3 | [6900/10244 (67%)]	Loss: 0.726173
| Global Round : 1 | Local Epoch : 3 | [7000/10244 (68%)]	Loss: 0.429789
| Global Round : 1 | Local Epoch : 3 | [7100/10244 (69%)]	Loss: 0.212394
| Global Round : 1 | Local Epoch : 3 | [7200/10244 (70%)]	Loss: 0.345074
| Global Round : 1 | Local Epoch : 3 | [7300/10244 (71%)]	Loss: 0.186175
| Global Round : 1 | Local Epoch : 3 | [7400/10244 (72%)]	Loss: 0.098919
| Global Round : 1 | Local Epoch : 3 | [7500/10244 (73%)]	Loss: 0.535233
| Global Round : 1 | Local Epoch : 3 | [7600/10244 (74%)]	Loss: 0.376603
| Global Round : 1 | Local Epoch : 3 | [7700/10244 (75%)]	Loss: 0.079751
| Global Round : 1 | Local Epoch : 3 | [7800/10244 (76%)]	Loss: 0.239530
| Global Round : 1 | Local Epoch : 3 | [7900/10244 (77%)]	Loss: 0.285065
| Global Round : 1 | Local Epoch : 3 | [8000/10244 (78%)]	Loss: 0.082037
| Global Round : 1 | Local Epoch : 3 | [8100/10244 (79%)]	Loss: 0.313546
| Global Round : 1 | Local Epoch : 3 | [8200/10244 (80%)]	Loss: 0.284989
| Global Round : 1 | Local Epoch : 3 | [8300/10244 (81%)]	Loss: 0.134274
| Global Round : 1 | Local Epoch : 3 | [8400/10244 (82%)]	Loss: 0.665550
| Global Round : 1 | Local Epoch : 3 | [8500/10244 (83%)]	Loss: 0.054740
| Global Round : 1 | Local Epoch : 3 | [8600/10244 (84%)]	Loss: 0.659520
| Global Round : 1 | Local Epoch : 3 | [8700/10244 (85%)]	Loss: 0.205514
| Global Round : 1 | Local Epoch : 3 | [8800/10244 (86%)]	Loss: 0.361638
| Global Round : 1 | Local Epoch : 3 | [8900/10244 (87%)]	Loss: 0.295746
| Global Round : 1 | Local Epoch : 3 | [9000/10244 (88%)]	Loss: 0.377501
| Global Round : 1 | Local Epoch : 3 | [9100/10244 (89%)]	Loss: 0.441286
| Global Round : 1 | Local Epoch : 3 | [9200/10244 (90%)]	Loss: 0.482768
| Global Round : 1 | Local Epoch : 3 | [9300/10244 (91%)]	Loss: 0.673855
| Global Round : 1 | Local Epoch : 3 | [9400/10244 (92%)]	Loss: 0.380991
| Global Round : 1 | Local Epoch : 3 | [9500/10244 (93%)]	Loss: 0.165015
| Global Round : 1 | Local Epoch : 3 | [9600/10244 (94%)]	Loss: 0.425763
| Global Round : 1 | Local Epoch : 3 | [9700/10244 (95%)]	Loss: 0.272336
| Global Round : 1 | Local Epoch : 3 | [9800/10244 (96%)]	Loss: 0.473875
| Global Round : 1 | Local Epoch : 3 | [9900/10244 (97%)]	Loss: 0.098724
| Global Round : 1 | Local Epoch : 3 | [10000/10244 (98%)]	Loss: 0.169969
| Global Round : 1 | Local Epoch : 3 | [10100/10244 (99%)]	Loss: 0.180718
| Global Round : 1 | Local Epoch : 3 | [10200/10244 (100%)]	Loss: 0.528574
| Global Round : 1 | Local Epoch : 4 | [0/10244 (0%)]	Loss: 0.404801
| Global Round : 1 | Local Epoch : 4 | [100/10244 (1%)]	Loss: 0.214592
| Global Round : 1 | Local Epoch : 4 | [200/10244 (2%)]	Loss: 0.048727
| Global Round : 1 | Local Epoch : 4 | [300/10244 (3%)]	Loss: 0.146632
| Global Round : 1 | Local Epoch : 4 | [400/10244 (4%)]	Loss: 0.648614
| Global Round : 1 | Local Epoch : 4 | [500/10244 (5%)]	Loss: 0.156113
| Global Round : 1 | Local Epoch : 4 | [600/10244 (6%)]	Loss: 0.459982
| Global Round : 1 | Local Epoch : 4 | [700/10244 (7%)]	Loss: 0.284227
| Global Round : 1 | Local Epoch : 4 | [800/10244 (8%)]	Loss: 0.160592
| Global Round : 1 | Local Epoch : 4 | [900/10244 (9%)]	Loss: 0.064454
| Global Round : 1 | Local Epoch : 4 | [1000/10244 (10%)]	Loss: 0.131833
| Global Round : 1 | Local Epoch : 4 | [1100/10244 (11%)]	Loss: 0.117193
| Global Round : 1 | Local Epoch : 4 | [1200/10244 (12%)]	Loss: 0.035296
| Global Round : 1 | Local Epoch : 4 | [1300/10244 (13%)]	Loss: 0.282810
| Global Round : 1 | Local Epoch : 4 | [1400/10244 (14%)]	Loss: 0.152592
| Global Round : 1 | Local Epoch : 4 | [1500/10244 (15%)]	Loss: 0.387468
| Global Round : 1 | Local Epoch : 4 | [1600/10244 (16%)]	Loss: 0.355105
| Global Round : 1 | Local Epoch : 4 | [1700/10244 (17%)]	Loss: 0.123951
| Global Round : 1 | Local Epoch : 4 | [1800/10244 (18%)]	Loss: 0.343870
| Global Round : 1 | Local Epoch : 4 | [1900/10244 (19%)]	Loss: 0.096635
| Global Round : 1 | Local Epoch : 4 | [2000/10244 (20%)]	Loss: 0.058823
| Global Round : 1 | Local Epoch : 4 | [2100/10244 (20%)]	Loss: 0.377688
| Global Round : 1 | Local Epoch : 4 | [2200/10244 (21%)]	Loss: 0.064475
| Global Round : 1 | Local Epoch : 4 | [2300/10244 (22%)]	Loss: 0.427834
| Global Round : 1 | Local Epoch : 4 | [2400/10244 (23%)]	Loss: 0.211126
| Global Round : 1 | Local Epoch : 4 | [2500/10244 (24%)]	Loss: 0.459173
| Global Round : 1 | Local Epoch : 4 | [2600/10244 (25%)]	Loss: 0.266951
| Global Round : 1 | Local Epoch : 4 | [2700/10244 (26%)]	Loss: 0.149974
| Global Round : 1 | Local Epoch : 4 | [2800/10244 (27%)]	Loss: 0.029658
| Global Round : 1 | Local Epoch : 4 | [2900/10244 (28%)]	Loss: 0.059516
| Global Round : 1 | Local Epoch : 4 | [3000/10244 (29%)]	Loss: 0.090284
| Global Round : 1 | Local Epoch : 4 | [3100/10244 (30%)]	Loss: 1.403906
| Global Round : 1 | Local Epoch : 4 | [3200/10244 (31%)]	Loss: 0.459866
| Global Round : 1 | Local Epoch : 4 | [3300/10244 (32%)]	Loss: 0.585368
| Global Round : 1 | Local Epoch : 4 | [3400/10244 (33%)]	Loss: 0.310068
| Global Round : 1 | Local Epoch : 4 | [3500/10244 (34%)]	Loss: 0.129831
| Global Round : 1 | Local Epoch : 4 | [3600/10244 (35%)]	Loss: 0.249588
| Global Round : 1 | Local Epoch : 4 | [3700/10244 (36%)]	Loss: 0.595584
| Global Round : 1 | Local Epoch : 4 | [3800/10244 (37%)]	Loss: 0.149714
| Global Round : 1 | Local Epoch : 4 | [3900/10244 (38%)]	Loss: 0.294998
| Global Round : 1 | Local Epoch : 4 | [4000/10244 (39%)]	Loss: 0.079647
| Global Round : 1 | Local Epoch : 4 | [4100/10244 (40%)]	Loss: 0.137413
| Global Round : 1 | Local Epoch : 4 | [4200/10244 (41%)]	Loss: 0.100390
| Global Round : 1 | Local Epoch : 4 | [4300/10244 (42%)]	Loss: 0.125272
| Global Round : 1 | Local Epoch : 4 | [4400/10244 (43%)]	Loss: 0.861358
| Global Round : 1 | Local Epoch : 4 | [4500/10244 (44%)]	Loss: 0.114203
| Global Round : 1 | Local Epoch : 4 | [4600/10244 (45%)]	Loss: 0.133514
| Global Round : 1 | Local Epoch : 4 | [4700/10244 (46%)]	Loss: 0.133880
| Global Round : 1 | Local Epoch : 4 | [4800/10244 (47%)]	Loss: 0.221635
| Global Round : 1 | Local Epoch : 4 | [4900/10244 (48%)]	Loss: 0.189849
| Global Round : 1 | Local Epoch : 4 | [5000/10244 (49%)]	Loss: 0.195718
| Global Round : 1 | Local Epoch : 4 | [5100/10244 (50%)]	Loss: 0.886643
| Global Round : 1 | Local Epoch : 4 | [5200/10244 (51%)]	Loss: 0.103440
| Global Round : 1 | Local Epoch : 4 | [5300/10244 (52%)]	Loss: 0.398360
| Global Round : 1 | Local Epoch : 4 | [5400/10244 (53%)]	Loss: 0.254950
| Global Round : 1 | Local Epoch : 4 | [5500/10244 (54%)]	Loss: 0.208512
| Global Round : 1 | Local Epoch : 4 | [5600/10244 (55%)]	Loss: 0.400394
| Global Round : 1 | Local Epoch : 4 | [5700/10244 (56%)]	Loss: 0.090853
| Global Round : 1 | Local Epoch : 4 | [5800/10244 (57%)]	Loss: 0.275086
| Global Round : 1 | Local Epoch : 4 | [5900/10244 (58%)]	Loss: 0.213908
| Global Round : 1 | Local Epoch : 4 | [6000/10244 (59%)]	Loss: 0.141225
| Global Round : 1 | Local Epoch : 4 | [6100/10244 (60%)]	Loss: 0.276701
| Global Round : 1 | Local Epoch : 4 | [6200/10244 (60%)]	Loss: 0.100177
| Global Round : 1 | Local Epoch : 4 | [6300/10244 (61%)]	Loss: 0.124687
| Global Round : 1 | Local Epoch : 4 | [6400/10244 (62%)]	Loss: 0.190338
| Global Round : 1 | Local Epoch : 4 | [6500/10244 (63%)]	Loss: 0.101385
| Global Round : 1 | Local Epoch : 4 | [6600/10244 (64%)]	Loss: 0.097651
| Global Round : 1 | Local Epoch : 4 | [6700/10244 (65%)]	Loss: 0.063881
| Global Round : 1 | Local Epoch : 4 | [6800/10244 (66%)]	Loss: 0.101452
| Global Round : 1 | Local Epoch : 4 | [6900/10244 (67%)]	Loss: 0.183446
| Global Round : 1 | Local Epoch : 4 | [7000/10244 (68%)]	Loss: 0.429792
| Global Round : 1 | Local Epoch : 4 | [7100/10244 (69%)]	Loss: 0.516650
| Global Round : 1 | Local Epoch : 4 | [7200/10244 (70%)]	Loss: 0.079439
| Global Round : 1 | Local Epoch : 4 | [7300/10244 (71%)]	Loss: 0.061862
| Global Round : 1 | Local Epoch : 4 | [7400/10244 (72%)]	Loss: 0.171869
| Global Round : 1 | Local Epoch : 4 | [7500/10244 (73%)]	Loss: 0.365908
| Global Round : 1 | Local Epoch : 4 | [7600/10244 (74%)]	Loss: 0.089847
| Global Round : 1 | Local Epoch : 4 | [7700/10244 (75%)]	Loss: 0.345131
| Global Round : 1 | Local Epoch : 4 | [7800/10244 (76%)]	Loss: 0.790934
| Global Round : 1 | Local Epoch : 4 | [7900/10244 (77%)]	Loss: 0.403721
| Global Round : 1 | Local Epoch : 4 | [8000/10244 (78%)]	Loss: 0.673222
| Global Round : 1 | Local Epoch : 4 | [8100/10244 (79%)]	Loss: 0.234318
| Global Round : 1 | Local Epoch : 4 | [8200/10244 (80%)]	Loss: 0.125589
| Global Round : 1 | Local Epoch : 4 | [8300/10244 (81%)]	Loss: 0.121750
| Global Round : 1 | Local Epoch : 4 | [8400/10244 (82%)]	Loss: 0.282371
| Global Round : 1 | Local Epoch : 4 | [8500/10244 (83%)]	Loss: 0.150512
| Global Round : 1 | Local Epoch : 4 | [8600/10244 (84%)]	Loss: 0.580227
| Global Round : 1 | Local Epoch : 4 | [8700/10244 (85%)]	Loss: 0.089868
| Global Round : 1 | Local Epoch : 4 | [8800/10244 (86%)]	Loss: 0.102294
| Global Round : 1 | Local Epoch : 4 | [8900/10244 (87%)]	Loss: 0.325618
| Global Round : 1 | Local Epoch : 4 | [9000/10244 (88%)]	Loss: 1.055869
| Global Round : 1 | Local Epoch : 4 | [9100/10244 (89%)]	Loss: 0.308892
| Global Round : 1 | Local Epoch : 4 | [9200/10244 (90%)]	Loss: 0.238943
| Global Round : 1 | Local Epoch : 4 | [9300/10244 (91%)]	Loss: 0.108963
| Global Round : 1 | Local Epoch : 4 | [9400/10244 (92%)]	Loss: 0.145001
| Global Round : 1 | Local Epoch : 4 | [9500/10244 (93%)]	Loss: 0.055801
| Global Round : 1 | Local Epoch : 4 | [9600/10244 (94%)]	Loss: 0.237004
| Global Round : 1 | Local Epoch : 4 | [9700/10244 (95%)]	Loss: 0.517033
| Global Round : 1 | Local Epoch : 4 | [9800/10244 (96%)]	Loss: 0.352071
| Global Round : 1 | Local Epoch : 4 | [9900/10244 (97%)]	Loss: 0.241014
| Global Round : 1 | Local Epoch : 4 | [10000/10244 (98%)]	Loss: 0.208696
| Global Round : 1 | Local Epoch : 4 | [10100/10244 (99%)]	Loss: 0.193412
| Global Round : 1 | Local Epoch : 4 | [10200/10244 (100%)]	Loss: 0.150973
----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.88      0.92        68
         DME       0.88      0.97      0.92        60

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.93      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.89      0.91        54
         DME       0.92      0.96      0.94        74

    accuracy                           0.93       128
   macro avg       0.93      0.92      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.78      0.84        65
         DME       0.80      0.90      0.85        63

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.90      0.92        63
         DME       0.91      0.94      0.92        65

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.84      0.86        67
         DME       0.83      0.89      0.86        61

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.91      0.92        66
         DME       0.91      0.94      0.92        62

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.83      0.89        65
         DME       0.85      0.95      0.90        63

    accuracy                           0.89       128
   macro avg       0.90      0.89      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.90      0.93        70
         DME       0.89      0.95      0.92        58

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        70
         DME       0.77      0.95      0.85        58

    accuracy                           0.85       128
   macro avg       0.86      0.86      0.85       128
weighted avg       0.87      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        75
         DME       0.75      0.94      0.83        53

    accuracy                           0.84       128
   macro avg       0.85      0.86      0.84       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
         DME       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.88      0.92        68
      DRUSEN       0.88      0.97      0.92        60

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.93      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.89      0.91        54
      DRUSEN       0.92      0.96      0.94        74

    accuracy                           0.93       128
   macro avg       0.93      0.92      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.78      0.84        65
      DRUSEN       0.80      0.90      0.85        63

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.90      0.92        63
      DRUSEN       0.91      0.94      0.92        65

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.84      0.86        67
      DRUSEN       0.83      0.89      0.86        61

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.91      0.92        66
      DRUSEN       0.91      0.94      0.92        62

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.83      0.89        65
      DRUSEN       0.85      0.95      0.90        63

    accuracy                           0.89       128
   macro avg       0.90      0.89      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.90      0.93        70
      DRUSEN       0.89      0.95      0.92        58

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        70
      DRUSEN       0.77      0.95      0.85        58

    accuracy                           0.85       128
   macro avg       0.86      0.86      0.85       128
weighted avg       0.87      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.77      0.85        75
      DRUSEN       0.75      0.94      0.83        53

    accuracy                           0.84       128
   macro avg       0.85      0.86      0.84       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
      DRUSEN       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

Training accuracy [0.84921875, 0.8907103825136612]
 
Avg Training Stats after 2 global rounds:
Training Loss : 0.42278124080620116
Train Accuracy: 89.07% 


 | Global Training Round : 3 |

----------------
user chosen 2
----------------
----------------
| Global Round : 2 | Local Epoch : 0 | [0/10244 (0%)]	Loss: 0.104521
| Global Round : 2 | Local Epoch : 0 | [100/10244 (1%)]	Loss: 0.087300
| Global Round : 2 | Local Epoch : 0 | [200/10244 (2%)]	Loss: 0.160954
| Global Round : 2 | Local Epoch : 0 | [300/10244 (3%)]	Loss: 0.082843
| Global Round : 2 | Local Epoch : 0 | [400/10244 (4%)]	Loss: 0.230101
| Global Round : 2 | Local Epoch : 0 | [500/10244 (5%)]	Loss: 0.241474
| Global Round : 2 | Local Epoch : 0 | [600/10244 (6%)]	Loss: 0.545577
| Global Round : 2 | Local Epoch : 0 | [700/10244 (7%)]	Loss: 0.401394
| Global Round : 2 | Local Epoch : 0 | [800/10244 (8%)]	Loss: 0.274002
| Global Round : 2 | Local Epoch : 0 | [900/10244 (9%)]	Loss: 0.085181
| Global Round : 2 | Local Epoch : 0 | [1000/10244 (10%)]	Loss: 0.191881
| Global Round : 2 | Local Epoch : 0 | [1100/10244 (11%)]	Loss: 0.100556
| Global Round : 2 | Local Epoch : 0 | [1200/10244 (12%)]	Loss: 0.287800
| Global Round : 2 | Local Epoch : 0 | [1300/10244 (13%)]	Loss: 0.344722
| Global Round : 2 | Local Epoch : 0 | [1400/10244 (14%)]	Loss: 0.152174
| Global Round : 2 | Local Epoch : 0 | [1500/10244 (15%)]	Loss: 0.037598
| Global Round : 2 | Local Epoch : 0 | [1600/10244 (16%)]	Loss: 0.283468
| Global Round : 2 | Local Epoch : 0 | [1700/10244 (17%)]	Loss: 0.387630
| Global Round : 2 | Local Epoch : 0 | [1800/10244 (18%)]	Loss: 0.419738
| Global Round : 2 | Local Epoch : 0 | [1900/10244 (19%)]	Loss: 0.101410
| Global Round : 2 | Local Epoch : 0 | [2000/10244 (20%)]	Loss: 0.200396
| Global Round : 2 | Local Epoch : 0 | [2100/10244 (20%)]	Loss: 0.482930
| Global Round : 2 | Local Epoch : 0 | [2200/10244 (21%)]	Loss: 0.111274
| Global Round : 2 | Local Epoch : 0 | [2300/10244 (22%)]	Loss: 0.087965
| Global Round : 2 | Local Epoch : 0 | [2400/10244 (23%)]	Loss: 0.547329
| Global Round : 2 | Local Epoch : 0 | [2500/10244 (24%)]	Loss: 0.226176
| Global Round : 2 | Local Epoch : 0 | [2600/10244 (25%)]	Loss: 0.157801
| Global Round : 2 | Local Epoch : 0 | [2700/10244 (26%)]	Loss: 0.193195
| Global Round : 2 | Local Epoch : 0 | [2800/10244 (27%)]	Loss: 0.255076
| Global Round : 2 | Local Epoch : 0 | [2900/10244 (28%)]	Loss: 0.118357
| Global Round : 2 | Local Epoch : 0 | [3000/10244 (29%)]	Loss: 0.077679
| Global Round : 2 | Local Epoch : 0 | [3100/10244 (30%)]	Loss: 0.239990
| Global Round : 2 | Local Epoch : 0 | [3200/10244 (31%)]	Loss: 0.539761
| Global Round : 2 | Local Epoch : 0 | [3300/10244 (32%)]	Loss: 0.159950
| Global Round : 2 | Local Epoch : 0 | [3400/10244 (33%)]	Loss: 0.125107
| Global Round : 2 | Local Epoch : 0 | [3500/10244 (34%)]	Loss: 0.303066
| Global Round : 2 | Local Epoch : 0 | [3600/10244 (35%)]	Loss: 0.820478
| Global Round : 2 | Local Epoch : 0 | [3700/10244 (36%)]	Loss: 0.065418
| Global Round : 2 | Local Epoch : 0 | [3800/10244 (37%)]	Loss: 0.324786
| Global Round : 2 | Local Epoch : 0 | [3900/10244 (38%)]	Loss: 0.024265
| Global Round : 2 | Local Epoch : 0 | [4000/10244 (39%)]	Loss: 0.031177
| Global Round : 2 | Local Epoch : 0 | [4100/10244 (40%)]	Loss: 0.198501
| Global Round : 2 | Local Epoch : 0 | [4200/10244 (41%)]	Loss: 0.113527
| Global Round : 2 | Local Epoch : 0 | [4300/10244 (42%)]	Loss: 0.836824
| Global Round : 2 | Local Epoch : 0 | [4400/10244 (43%)]	Loss: 0.157068
| Global Round : 2 | Local Epoch : 0 | [4500/10244 (44%)]	Loss: 0.142430
| Global Round : 2 | Local Epoch : 0 | [4600/10244 (45%)]	Loss: 0.618636
| Global Round : 2 | Local Epoch : 0 | [4700/10244 (46%)]	Loss: 0.065574
| Global Round : 2 | Local Epoch : 0 | [4800/10244 (47%)]	Loss: 0.209433
| Global Round : 2 | Local Epoch : 0 | [4900/10244 (48%)]	Loss: 0.089501
| Global Round : 2 | Local Epoch : 0 | [5000/10244 (49%)]	Loss: 0.037383
| Global Round : 2 | Local Epoch : 0 | [5100/10244 (50%)]	Loss: 0.122452
| Global Round : 2 | Local Epoch : 0 | [5200/10244 (51%)]	Loss: 0.049902
| Global Round : 2 | Local Epoch : 0 | [5300/10244 (52%)]	Loss: 0.350647
| Global Round : 2 | Local Epoch : 0 | [5400/10244 (53%)]	Loss: 0.175544
| Global Round : 2 | Local Epoch : 0 | [5500/10244 (54%)]	Loss: 0.013872
| Global Round : 2 | Local Epoch : 0 | [5600/10244 (55%)]	Loss: 0.148302
| Global Round : 2 | Local Epoch : 0 | [5700/10244 (56%)]	Loss: 0.255081
| Global Round : 2 | Local Epoch : 0 | [5800/10244 (57%)]	Loss: 0.069409
| Global Round : 2 | Local Epoch : 0 | [5900/10244 (58%)]	Loss: 0.248212
| Global Round : 2 | Local Epoch : 0 | [6000/10244 (59%)]	Loss: 0.035683
| Global Round : 2 | Local Epoch : 0 | [6100/10244 (60%)]	Loss: 0.294106
| Global Round : 2 | Local Epoch : 0 | [6200/10244 (60%)]	Loss: 0.052704
| Global Round : 2 | Local Epoch : 0 | [6300/10244 (61%)]	Loss: 0.061545
| Global Round : 2 | Local Epoch : 0 | [6400/10244 (62%)]	Loss: 0.205938
| Global Round : 2 | Local Epoch : 0 | [6500/10244 (63%)]	Loss: 0.266540
| Global Round : 2 | Local Epoch : 0 | [6600/10244 (64%)]	Loss: 0.066969
| Global Round : 2 | Local Epoch : 0 | [6700/10244 (65%)]	Loss: 0.139219
| Global Round : 2 | Local Epoch : 0 | [6800/10244 (66%)]	Loss: 0.505426
| Global Round : 2 | Local Epoch : 0 | [6900/10244 (67%)]	Loss: 0.252946
| Global Round : 2 | Local Epoch : 0 | [7000/10244 (68%)]	Loss: 0.020521
| Global Round : 2 | Local Epoch : 0 | [7100/10244 (69%)]	Loss: 0.070518
| Global Round : 2 | Local Epoch : 0 | [7200/10244 (70%)]	Loss: 0.248101
| Global Round : 2 | Local Epoch : 0 | [7300/10244 (71%)]	Loss: 0.327460
| Global Round : 2 | Local Epoch : 0 | [7400/10244 (72%)]	Loss: 1.894648
| Global Round : 2 | Local Epoch : 0 | [7500/10244 (73%)]	Loss: 0.569619
| Global Round : 2 | Local Epoch : 0 | [7600/10244 (74%)]	Loss: 0.061170
| Global Round : 2 | Local Epoch : 0 | [7700/10244 (75%)]	Loss: 0.032564
| Global Round : 2 | Local Epoch : 0 | [7800/10244 (76%)]	Loss: 0.146677
| Global Round : 2 | Local Epoch : 0 | [7900/10244 (77%)]	Loss: 0.076294
| Global Round : 2 | Local Epoch : 0 | [8000/10244 (78%)]	Loss: 0.431870
| Global Round : 2 | Local Epoch : 0 | [8100/10244 (79%)]	Loss: 0.515072
| Global Round : 2 | Local Epoch : 0 | [8200/10244 (80%)]	Loss: 0.309767
| Global Round : 2 | Local Epoch : 0 | [8300/10244 (81%)]	Loss: 0.130245
| Global Round : 2 | Local Epoch : 0 | [8400/10244 (82%)]	Loss: 0.141149
| Global Round : 2 | Local Epoch : 0 | [8500/10244 (83%)]	Loss: 0.273413
| Global Round : 2 | Local Epoch : 0 | [8600/10244 (84%)]	Loss: 0.196974
| Global Round : 2 | Local Epoch : 0 | [8700/10244 (85%)]	Loss: 1.008255
| Global Round : 2 | Local Epoch : 0 | [8800/10244 (86%)]	Loss: 0.280757
| Global Round : 2 | Local Epoch : 0 | [8900/10244 (87%)]	Loss: 0.348566
| Global Round : 2 | Local Epoch : 0 | [9000/10244 (88%)]	Loss: 0.058742
| Global Round : 2 | Local Epoch : 0 | [9100/10244 (89%)]	Loss: 0.182857
| Global Round : 2 | Local Epoch : 0 | [9200/10244 (90%)]	Loss: 0.100920
| Global Round : 2 | Local Epoch : 0 | [9300/10244 (91%)]	Loss: 0.089348
| Global Round : 2 | Local Epoch : 0 | [9400/10244 (92%)]	Loss: 0.386341
| Global Round : 2 | Local Epoch : 0 | [9500/10244 (93%)]	Loss: 0.524121
| Global Round : 2 | Local Epoch : 0 | [9600/10244 (94%)]	Loss: 0.261680
| Global Round : 2 | Local Epoch : 0 | [9700/10244 (95%)]	Loss: 0.098116
| Global Round : 2 | Local Epoch : 0 | [9800/10244 (96%)]	Loss: 0.323867
| Global Round : 2 | Local Epoch : 0 | [9900/10244 (97%)]	Loss: 0.224518
| Global Round : 2 | Local Epoch : 0 | [10000/10244 (98%)]	Loss: 0.107695
| Global Round : 2 | Local Epoch : 0 | [10100/10244 (99%)]	Loss: 0.371129
| Global Round : 2 | Local Epoch : 0 | [10200/10244 (100%)]	Loss: 0.161993
| Global Round : 2 | Local Epoch : 1 | [0/10244 (0%)]	Loss: 0.189594
| Global Round : 2 | Local Epoch : 1 | [100/10244 (1%)]	Loss: 0.316278
| Global Round : 2 | Local Epoch : 1 | [200/10244 (2%)]	Loss: 0.102285
| Global Round : 2 | Local Epoch : 1 | [300/10244 (3%)]	Loss: 0.136862
| Global Round : 2 | Local Epoch : 1 | [400/10244 (4%)]	Loss: 0.084204
| Global Round : 2 | Local Epoch : 1 | [500/10244 (5%)]	Loss: 0.446165
| Global Round : 2 | Local Epoch : 1 | [600/10244 (6%)]	Loss: 0.223431
| Global Round : 2 | Local Epoch : 1 | [700/10244 (7%)]	Loss: 0.058383
| Global Round : 2 | Local Epoch : 1 | [800/10244 (8%)]	Loss: 0.056468
| Global Round : 2 | Local Epoch : 1 | [900/10244 (9%)]	Loss: 0.084802
| Global Round : 2 | Local Epoch : 1 | [1000/10244 (10%)]	Loss: 0.041102
| Global Round : 2 | Local Epoch : 1 | [1100/10244 (11%)]	Loss: 0.200279
| Global Round : 2 | Local Epoch : 1 | [1200/10244 (12%)]	Loss: 0.292700
| Global Round : 2 | Local Epoch : 1 | [1300/10244 (13%)]	Loss: 0.160369
| Global Round : 2 | Local Epoch : 1 | [1400/10244 (14%)]	Loss: 0.028999
| Global Round : 2 | Local Epoch : 1 | [1500/10244 (15%)]	Loss: 0.151449
| Global Round : 2 | Local Epoch : 1 | [1600/10244 (16%)]	Loss: 0.086293
| Global Round : 2 | Local Epoch : 1 | [1700/10244 (17%)]	Loss: 0.116308
| Global Round : 2 | Local Epoch : 1 | [1800/10244 (18%)]	Loss: 0.066281
| Global Round : 2 | Local Epoch : 1 | [1900/10244 (19%)]	Loss: 0.261012
| Global Round : 2 | Local Epoch : 1 | [2000/10244 (20%)]	Loss: 0.393774
| Global Round : 2 | Local Epoch : 1 | [2100/10244 (20%)]	Loss: 0.436226
| Global Round : 2 | Local Epoch : 1 | [2200/10244 (21%)]	Loss: 0.676346
| Global Round : 2 | Local Epoch : 1 | [2300/10244 (22%)]	Loss: 0.178152
| Global Round : 2 | Local Epoch : 1 | [2400/10244 (23%)]	Loss: 0.168716
| Global Round : 2 | Local Epoch : 1 | [2500/10244 (24%)]	Loss: 0.071724
| Global Round : 2 | Local Epoch : 1 | [2600/10244 (25%)]	Loss: 0.037905
| Global Round : 2 | Local Epoch : 1 | [2700/10244 (26%)]	Loss: 0.056837
| Global Round : 2 | Local Epoch : 1 | [2800/10244 (27%)]	Loss: 0.164138
| Global Round : 2 | Local Epoch : 1 | [2900/10244 (28%)]	Loss: 0.422412
| Global Round : 2 | Local Epoch : 1 | [3000/10244 (29%)]	Loss: 0.076717
| Global Round : 2 | Local Epoch : 1 | [3100/10244 (30%)]	Loss: 0.139718
| Global Round : 2 | Local Epoch : 1 | [3200/10244 (31%)]	Loss: 0.760081
| Global Round : 2 | Local Epoch : 1 | [3300/10244 (32%)]	Loss: 0.163553
| Global Round : 2 | Local Epoch : 1 | [3400/10244 (33%)]	Loss: 0.211313
| Global Round : 2 | Local Epoch : 1 | [3500/10244 (34%)]	Loss: 0.070986
| Global Round : 2 | Local Epoch : 1 | [3600/10244 (35%)]	Loss: 0.071679
| Global Round : 2 | Local Epoch : 1 | [3700/10244 (36%)]	Loss: 0.141446
| Global Round : 2 | Local Epoch : 1 | [3800/10244 (37%)]	Loss: 0.191672
| Global Round : 2 | Local Epoch : 1 | [3900/10244 (38%)]	Loss: 0.249425
| Global Round : 2 | Local Epoch : 1 | [4000/10244 (39%)]	Loss: 0.072337
| Global Round : 2 | Local Epoch : 1 | [4100/10244 (40%)]	Loss: 0.015835
| Global Round : 2 | Local Epoch : 1 | [4200/10244 (41%)]	Loss: 0.110658
| Global Round : 2 | Local Epoch : 1 | [4300/10244 (42%)]	Loss: 0.218788
| Global Round : 2 | Local Epoch : 1 | [4400/10244 (43%)]	Loss: 0.152710
| Global Round : 2 | Local Epoch : 1 | [4500/10244 (44%)]	Loss: 0.024307
| Global Round : 2 | Local Epoch : 1 | [4600/10244 (45%)]	Loss: 0.196461
| Global Round : 2 | Local Epoch : 1 | [4700/10244 (46%)]	Loss: 0.296510
| Global Round : 2 | Local Epoch : 1 | [4800/10244 (47%)]	Loss: 0.037591
| Global Round : 2 | Local Epoch : 1 | [4900/10244 (48%)]	Loss: 0.295280
| Global Round : 2 | Local Epoch : 1 | [5000/10244 (49%)]	Loss: 0.146265
| Global Round : 2 | Local Epoch : 1 | [5100/10244 (50%)]	Loss: 0.111194
| Global Round : 2 | Local Epoch : 1 | [5200/10244 (51%)]	Loss: 0.092087
| Global Round : 2 | Local Epoch : 1 | [5300/10244 (52%)]	Loss: 0.105143
| Global Round : 2 | Local Epoch : 1 | [5400/10244 (53%)]	Loss: 0.296765
| Global Round : 2 | Local Epoch : 1 | [5500/10244 (54%)]	Loss: 0.066759
| Global Round : 2 | Local Epoch : 1 | [5600/10244 (55%)]	Loss: 0.177253
| Global Round : 2 | Local Epoch : 1 | [5700/10244 (56%)]	Loss: 0.035991
| Global Round : 2 | Local Epoch : 1 | [5800/10244 (57%)]	Loss: 0.042208
| Global Round : 2 | Local Epoch : 1 | [5900/10244 (58%)]	Loss: 0.294163
| Global Round : 2 | Local Epoch : 1 | [6000/10244 (59%)]	Loss: 0.067723
| Global Round : 2 | Local Epoch : 1 | [6100/10244 (60%)]	Loss: 0.014548
| Global Round : 2 | Local Epoch : 1 | [6200/10244 (60%)]	Loss: 0.160448
| Global Round : 2 | Local Epoch : 1 | [6300/10244 (61%)]	Loss: 0.147792
| Global Round : 2 | Local Epoch : 1 | [6400/10244 (62%)]	Loss: 0.407556
| Global Round : 2 | Local Epoch : 1 | [6500/10244 (63%)]	Loss: 0.082506
| Global Round : 2 | Local Epoch : 1 | [6600/10244 (64%)]	Loss: 0.241792
| Global Round : 2 | Local Epoch : 1 | [6700/10244 (65%)]	Loss: 0.044651
| Global Round : 2 | Local Epoch : 1 | [6800/10244 (66%)]	Loss: 0.226089
| Global Round : 2 | Local Epoch : 1 | [6900/10244 (67%)]	Loss: 0.242864
| Global Round : 2 | Local Epoch : 1 | [7000/10244 (68%)]	Loss: 0.348851
| Global Round : 2 | Local Epoch : 1 | [7100/10244 (69%)]	Loss: 0.013086
| Global Round : 2 | Local Epoch : 1 | [7200/10244 (70%)]	Loss: 0.198608
| Global Round : 2 | Local Epoch : 1 | [7300/10244 (71%)]	Loss: 0.077608
| Global Round : 2 | Local Epoch : 1 | [7400/10244 (72%)]	Loss: 0.195665
| Global Round : 2 | Local Epoch : 1 | [7500/10244 (73%)]	Loss: 0.101203
| Global Round : 2 | Local Epoch : 1 | [7600/10244 (74%)]	Loss: 0.214127
| Global Round : 2 | Local Epoch : 1 | [7700/10244 (75%)]	Loss: 0.600205
| Global Round : 2 | Local Epoch : 1 | [7800/10244 (76%)]	Loss: 0.505832
| Global Round : 2 | Local Epoch : 1 | [7900/10244 (77%)]	Loss: 0.096333
| Global Round : 2 | Local Epoch : 1 | [8000/10244 (78%)]	Loss: 0.024018
| Global Round : 2 | Local Epoch : 1 | [8100/10244 (79%)]	Loss: 0.108169
| Global Round : 2 | Local Epoch : 1 | [8200/10244 (80%)]	Loss: 0.120676
| Global Round : 2 | Local Epoch : 1 | [8300/10244 (81%)]	Loss: 0.165835
| Global Round : 2 | Local Epoch : 1 | [8400/10244 (82%)]	Loss: 0.375644
| Global Round : 2 | Local Epoch : 1 | [8500/10244 (83%)]	Loss: 0.069694
| Global Round : 2 | Local Epoch : 1 | [8600/10244 (84%)]	Loss: 0.287657
| Global Round : 2 | Local Epoch : 1 | [8700/10244 (85%)]	Loss: 0.026419
| Global Round : 2 | Local Epoch : 1 | [8800/10244 (86%)]	Loss: 0.142829
| Global Round : 2 | Local Epoch : 1 | [8900/10244 (87%)]	Loss: 0.030718
| Global Round : 2 | Local Epoch : 1 | [9000/10244 (88%)]	Loss: 0.252878
| Global Round : 2 | Local Epoch : 1 | [9100/10244 (89%)]	Loss: 0.445994
| Global Round : 2 | Local Epoch : 1 | [9200/10244 (90%)]	Loss: 0.042252
| Global Round : 2 | Local Epoch : 1 | [9300/10244 (91%)]	Loss: 0.165294
| Global Round : 2 | Local Epoch : 1 | [9400/10244 (92%)]	Loss: 0.148827
| Global Round : 2 | Local Epoch : 1 | [9500/10244 (93%)]	Loss: 0.330830
| Global Round : 2 | Local Epoch : 1 | [9600/10244 (94%)]	Loss: 0.178313
| Global Round : 2 | Local Epoch : 1 | [9700/10244 (95%)]	Loss: 0.081414
| Global Round : 2 | Local Epoch : 1 | [9800/10244 (96%)]	Loss: 0.963552
| Global Round : 2 | Local Epoch : 1 | [9900/10244 (97%)]	Loss: 0.263013
| Global Round : 2 | Local Epoch : 1 | [10000/10244 (98%)]	Loss: 0.252807
| Global Round : 2 | Local Epoch : 1 | [10100/10244 (99%)]	Loss: 0.608801
| Global Round : 2 | Local Epoch : 1 | [10200/10244 (100%)]	Loss: 0.069181
| Global Round : 2 | Local Epoch : 2 | [0/10244 (0%)]	Loss: 0.083822
| Global Round : 2 | Local Epoch : 2 | [100/10244 (1%)]	Loss: 0.089712
| Global Round : 2 | Local Epoch : 2 | [200/10244 (2%)]	Loss: 0.196995
| Global Round : 2 | Local Epoch : 2 | [300/10244 (3%)]	Loss: 0.157562
| Global Round : 2 | Local Epoch : 2 | [400/10244 (4%)]	Loss: 0.193904
| Global Round : 2 | Local Epoch : 2 | [500/10244 (5%)]	Loss: 0.058560
| Global Round : 2 | Local Epoch : 2 | [600/10244 (6%)]	Loss: 0.522124
| Global Round : 2 | Local Epoch : 2 | [700/10244 (7%)]	Loss: 0.257108
| Global Round : 2 | Local Epoch : 2 | [800/10244 (8%)]	Loss: 0.183515
| Global Round : 2 | Local Epoch : 2 | [900/10244 (9%)]	Loss: 0.141606
| Global Round : 2 | Local Epoch : 2 | [1000/10244 (10%)]	Loss: 0.156822
| Global Round : 2 | Local Epoch : 2 | [1100/10244 (11%)]	Loss: 0.595512
| Global Round : 2 | Local Epoch : 2 | [1200/10244 (12%)]	Loss: 0.021935
| Global Round : 2 | Local Epoch : 2 | [1300/10244 (13%)]	Loss: 0.050985
| Global Round : 2 | Local Epoch : 2 | [1400/10244 (14%)]	Loss: 0.088161
| Global Round : 2 | Local Epoch : 2 | [1500/10244 (15%)]	Loss: 0.040069
| Global Round : 2 | Local Epoch : 2 | [1600/10244 (16%)]	Loss: 0.220421
| Global Round : 2 | Local Epoch : 2 | [1700/10244 (17%)]	Loss: 0.065291
| Global Round : 2 | Local Epoch : 2 | [1800/10244 (18%)]	Loss: 0.165642
| Global Round : 2 | Local Epoch : 2 | [1900/10244 (19%)]	Loss: 1.165886
| Global Round : 2 | Local Epoch : 2 | [2000/10244 (20%)]	Loss: 0.161398
| Global Round : 2 | Local Epoch : 2 | [2100/10244 (20%)]	Loss: 0.089015
| Global Round : 2 | Local Epoch : 2 | [2200/10244 (21%)]	Loss: 0.121729
| Global Round : 2 | Local Epoch : 2 | [2300/10244 (22%)]	Loss: 0.094148
| Global Round : 2 | Local Epoch : 2 | [2400/10244 (23%)]	Loss: 0.233118
| Global Round : 2 | Local Epoch : 2 | [2500/10244 (24%)]	Loss: 0.106998
| Global Round : 2 | Local Epoch : 2 | [2600/10244 (25%)]	Loss: 0.348812
| Global Round : 2 | Local Epoch : 2 | [2700/10244 (26%)]	Loss: 0.452956
| Global Round : 2 | Local Epoch : 2 | [2800/10244 (27%)]	Loss: 0.215788
| Global Round : 2 | Local Epoch : 2 | [2900/10244 (28%)]	Loss: 0.176194
| Global Round : 2 | Local Epoch : 2 | [3000/10244 (29%)]	Loss: 0.311930
| Global Round : 2 | Local Epoch : 2 | [3100/10244 (30%)]	Loss: 0.082740
| Global Round : 2 | Local Epoch : 2 | [3200/10244 (31%)]	Loss: 0.408150
| Global Round : 2 | Local Epoch : 2 | [3300/10244 (32%)]	Loss: 0.130137
| Global Round : 2 | Local Epoch : 2 | [3400/10244 (33%)]	Loss: 0.082764
| Global Round : 2 | Local Epoch : 2 | [3500/10244 (34%)]	Loss: 0.091631
| Global Round : 2 | Local Epoch : 2 | [3600/10244 (35%)]	Loss: 0.057718
| Global Round : 2 | Local Epoch : 2 | [3700/10244 (36%)]	Loss: 0.446470
| Global Round : 2 | Local Epoch : 2 | [3800/10244 (37%)]	Loss: 0.256027
| Global Round : 2 | Local Epoch : 2 | [3900/10244 (38%)]	Loss: 0.551303
| Global Round : 2 | Local Epoch : 2 | [4000/10244 (39%)]	Loss: 0.178407
| Global Round : 2 | Local Epoch : 2 | [4100/10244 (40%)]	Loss: 0.090146
| Global Round : 2 | Local Epoch : 2 | [4200/10244 (41%)]	Loss: 0.241855
| Global Round : 2 | Local Epoch : 2 | [4300/10244 (42%)]	Loss: 0.423135
| Global Round : 2 | Local Epoch : 2 | [4400/10244 (43%)]	Loss: 0.160063
| Global Round : 2 | Local Epoch : 2 | [4500/10244 (44%)]	Loss: 0.047246
| Global Round : 2 | Local Epoch : 2 | [4600/10244 (45%)]	Loss: 0.080987
| Global Round : 2 | Local Epoch : 2 | [4700/10244 (46%)]	Loss: 0.427465
| Global Round : 2 | Local Epoch : 2 | [4800/10244 (47%)]	Loss: 0.127671
| Global Round : 2 | Local Epoch : 2 | [4900/10244 (48%)]	Loss: 0.281261
| Global Round : 2 | Local Epoch : 2 | [5000/10244 (49%)]	Loss: 0.537709
| Global Round : 2 | Local Epoch : 2 | [5100/10244 (50%)]	Loss: 0.034308
| Global Round : 2 | Local Epoch : 2 | [5200/10244 (51%)]	Loss: 0.070669
| Global Round : 2 | Local Epoch : 2 | [5300/10244 (52%)]	Loss: 0.055222
| Global Round : 2 | Local Epoch : 2 | [5400/10244 (53%)]	Loss: 0.254812
| Global Round : 2 | Local Epoch : 2 | [5500/10244 (54%)]	Loss: 0.281276
| Global Round : 2 | Local Epoch : 2 | [5600/10244 (55%)]	Loss: 0.029575
| Global Round : 2 | Local Epoch : 2 | [5700/10244 (56%)]	Loss: 0.253789
| Global Round : 2 | Local Epoch : 2 | [5800/10244 (57%)]	Loss: 0.033275
| Global Round : 2 | Local Epoch : 2 | [5900/10244 (58%)]	Loss: 0.056756
| Global Round : 2 | Local Epoch : 2 | [6000/10244 (59%)]	Loss: 0.158100
| Global Round : 2 | Local Epoch : 2 | [6100/10244 (60%)]	Loss: 0.075184
| Global Round : 2 | Local Epoch : 2 | [6200/10244 (60%)]	Loss: 1.176018
| Global Round : 2 | Local Epoch : 2 | [6300/10244 (61%)]	Loss: 0.058045
| Global Round : 2 | Local Epoch : 2 | [6400/10244 (62%)]	Loss: 0.094449
| Global Round : 2 | Local Epoch : 2 | [6500/10244 (63%)]	Loss: 0.164919
| Global Round : 2 | Local Epoch : 2 | [6600/10244 (64%)]	Loss: 0.083295
| Global Round : 2 | Local Epoch : 2 | [6700/10244 (65%)]	Loss: 0.032387
| Global Round : 2 | Local Epoch : 2 | [6800/10244 (66%)]	Loss: 0.613755
| Global Round : 2 | Local Epoch : 2 | [6900/10244 (67%)]	Loss: 0.069555
| Global Round : 2 | Local Epoch : 2 | [7000/10244 (68%)]	Loss: 0.068848
| Global Round : 2 | Local Epoch : 2 | [7100/10244 (69%)]	Loss: 0.366212
| Global Round : 2 | Local Epoch : 2 | [7200/10244 (70%)]	Loss: 0.151375
| Global Round : 2 | Local Epoch : 2 | [7300/10244 (71%)]	Loss: 0.017319
| Global Round : 2 | Local Epoch : 2 | [7400/10244 (72%)]	Loss: 0.743379
| Global Round : 2 | Local Epoch : 2 | [7500/10244 (73%)]	Loss: 0.068359
| Global Round : 2 | Local Epoch : 2 | [7600/10244 (74%)]	Loss: 0.245057
| Global Round : 2 | Local Epoch : 2 | [7700/10244 (75%)]	Loss: 0.118953
| Global Round : 2 | Local Epoch : 2 | [7800/10244 (76%)]	Loss: 0.130121
| Global Round : 2 | Local Epoch : 2 | [7900/10244 (77%)]	Loss: 0.027424
| Global Round : 2 | Local Epoch : 2 | [8000/10244 (78%)]	Loss: 0.077998
| Global Round : 2 | Local Epoch : 2 | [8100/10244 (79%)]	Loss: 0.104368
| Global Round : 2 | Local Epoch : 2 | [8200/10244 (80%)]	Loss: 0.183558
| Global Round : 2 | Local Epoch : 2 | [8300/10244 (81%)]	Loss: 0.252892
| Global Round : 2 | Local Epoch : 2 | [8400/10244 (82%)]	Loss: 0.135726
| Global Round : 2 | Local Epoch : 2 | [8500/10244 (83%)]	Loss: 0.069303
| Global Round : 2 | Local Epoch : 2 | [8600/10244 (84%)]	Loss: 0.039275
| Global Round : 2 | Local Epoch : 2 | [8700/10244 (85%)]	Loss: 0.142775
| Global Round : 2 | Local Epoch : 2 | [8800/10244 (86%)]	Loss: 0.339646
| Global Round : 2 | Local Epoch : 2 | [8900/10244 (87%)]	Loss: 0.038484
| Global Round : 2 | Local Epoch : 2 | [9000/10244 (88%)]	Loss: 0.129412
| Global Round : 2 | Local Epoch : 2 | [9100/10244 (89%)]	Loss: 0.043986
| Global Round : 2 | Local Epoch : 2 | [9200/10244 (90%)]	Loss: 0.169067
| Global Round : 2 | Local Epoch : 2 | [9300/10244 (91%)]	Loss: 0.239310
| Global Round : 2 | Local Epoch : 2 | [9400/10244 (92%)]	Loss: 0.242585
| Global Round : 2 | Local Epoch : 2 | [9500/10244 (93%)]	Loss: 0.263779
| Global Round : 2 | Local Epoch : 2 | [9600/10244 (94%)]	Loss: 0.182688
| Global Round : 2 | Local Epoch : 2 | [9700/10244 (95%)]	Loss: 0.094391
| Global Round : 2 | Local Epoch : 2 | [9800/10244 (96%)]	Loss: 0.098761
| Global Round : 2 | Local Epoch : 2 | [9900/10244 (97%)]	Loss: 0.200390
| Global Round : 2 | Local Epoch : 2 | [10000/10244 (98%)]	Loss: 0.149395
| Global Round : 2 | Local Epoch : 2 | [10100/10244 (99%)]	Loss: 0.300390
| Global Round : 2 | Local Epoch : 2 | [10200/10244 (100%)]	Loss: 0.111062
| Global Round : 2 | Local Epoch : 3 | [0/10244 (0%)]	Loss: 0.106642
| Global Round : 2 | Local Epoch : 3 | [100/10244 (1%)]	Loss: 0.049008
| Global Round : 2 | Local Epoch : 3 | [200/10244 (2%)]	Loss: 0.045109
| Global Round : 2 | Local Epoch : 3 | [300/10244 (3%)]	Loss: 0.063186
| Global Round : 2 | Local Epoch : 3 | [400/10244 (4%)]	Loss: 0.507860
| Global Round : 2 | Local Epoch : 3 | [500/10244 (5%)]	Loss: 0.019285
| Global Round : 2 | Local Epoch : 3 | [600/10244 (6%)]	Loss: 0.239846
| Global Round : 2 | Local Epoch : 3 | [700/10244 (7%)]	Loss: 0.351796
| Global Round : 2 | Local Epoch : 3 | [800/10244 (8%)]	Loss: 0.009923
| Global Round : 2 | Local Epoch : 3 | [900/10244 (9%)]	Loss: 0.050732
| Global Round : 2 | Local Epoch : 3 | [1000/10244 (10%)]	Loss: 0.016920
| Global Round : 2 | Local Epoch : 3 | [1100/10244 (11%)]	Loss: 0.053623
| Global Round : 2 | Local Epoch : 3 | [1200/10244 (12%)]	Loss: 0.440494
| Global Round : 2 | Local Epoch : 3 | [1300/10244 (13%)]	Loss: 0.076612
| Global Round : 2 | Local Epoch : 3 | [1400/10244 (14%)]	Loss: 0.164620
| Global Round : 2 | Local Epoch : 3 | [1500/10244 (15%)]	Loss: 0.039158
| Global Round : 2 | Local Epoch : 3 | [1600/10244 (16%)]	Loss: 0.187822
| Global Round : 2 | Local Epoch : 3 | [1700/10244 (17%)]	Loss: 0.207080
| Global Round : 2 | Local Epoch : 3 | [1800/10244 (18%)]	Loss: 0.258862
| Global Round : 2 | Local Epoch : 3 | [1900/10244 (19%)]	Loss: 0.092454
| Global Round : 2 | Local Epoch : 3 | [2000/10244 (20%)]	Loss: 0.023060
| Global Round : 2 | Local Epoch : 3 | [2100/10244 (20%)]	Loss: 0.035930
| Global Round : 2 | Local Epoch : 3 | [2200/10244 (21%)]	Loss: 0.194196
| Global Round : 2 | Local Epoch : 3 | [2300/10244 (22%)]	Loss: 0.008386
| Global Round : 2 | Local Epoch : 3 | [2400/10244 (23%)]	Loss: 0.284830
| Global Round : 2 | Local Epoch : 3 | [2500/10244 (24%)]	Loss: 0.162024
| Global Round : 2 | Local Epoch : 3 | [2600/10244 (25%)]	Loss: 0.053681
| Global Round : 2 | Local Epoch : 3 | [2700/10244 (26%)]	Loss: 0.143630
| Global Round : 2 | Local Epoch : 3 | [2800/10244 (27%)]	Loss: 0.073737
| Global Round : 2 | Local Epoch : 3 | [2900/10244 (28%)]	Loss: 0.054248
| Global Round : 2 | Local Epoch : 3 | [3000/10244 (29%)]	Loss: 0.017534
| Global Round : 2 | Local Epoch : 3 | [3100/10244 (30%)]	Loss: 0.263718
| Global Round : 2 | Local Epoch : 3 | [3200/10244 (31%)]	Loss: 0.209566
| Global Round : 2 | Local Epoch : 3 | [3300/10244 (32%)]	Loss: 0.067033
| Global Round : 2 | Local Epoch : 3 | [3400/10244 (33%)]	Loss: 0.318436
| Global Round : 2 | Local Epoch : 3 | [3500/10244 (34%)]	Loss: 0.197501
| Global Round : 2 | Local Epoch : 3 | [3600/10244 (35%)]	Loss: 0.171944
| Global Round : 2 | Local Epoch : 3 | [3700/10244 (36%)]	Loss: 0.031652
| Global Round : 2 | Local Epoch : 3 | [3800/10244 (37%)]	Loss: 0.295380
| Global Round : 2 | Local Epoch : 3 | [3900/10244 (38%)]	Loss: 0.027700
| Global Round : 2 | Local Epoch : 3 | [4000/10244 (39%)]	Loss: 0.617175
| Global Round : 2 | Local Epoch : 3 | [4100/10244 (40%)]	Loss: 0.152077
| Global Round : 2 | Local Epoch : 3 | [4200/10244 (41%)]	Loss: 0.103635
| Global Round : 2 | Local Epoch : 3 | [4300/10244 (42%)]	Loss: 0.132203
| Global Round : 2 | Local Epoch : 3 | [4400/10244 (43%)]	Loss: 0.043867
| Global Round : 2 | Local Epoch : 3 | [4500/10244 (44%)]	Loss: 0.196447
| Global Round : 2 | Local Epoch : 3 | [4600/10244 (45%)]	Loss: 0.141226
| Global Round : 2 | Local Epoch : 3 | [4700/10244 (46%)]	Loss: 0.015886
| Global Round : 2 | Local Epoch : 3 | [4800/10244 (47%)]	Loss: 0.327341
| Global Round : 2 | Local Epoch : 3 | [4900/10244 (48%)]	Loss: 0.192140
| Global Round : 2 | Local Epoch : 3 | [5000/10244 (49%)]	Loss: 0.072095
| Global Round : 2 | Local Epoch : 3 | [5100/10244 (50%)]	Loss: 0.037912
| Global Round : 2 | Local Epoch : 3 | [5200/10244 (51%)]	Loss: 0.690756
| Global Round : 2 | Local Epoch : 3 | [5300/10244 (52%)]	Loss: 0.021658
| Global Round : 2 | Local Epoch : 3 | [5400/10244 (53%)]	Loss: 0.057709
| Global Round : 2 | Local Epoch : 3 | [5500/10244 (54%)]	Loss: 0.147713
| Global Round : 2 | Local Epoch : 3 | [5600/10244 (55%)]	Loss: 0.208597
| Global Round : 2 | Local Epoch : 3 | [5700/10244 (56%)]	Loss: 0.135856
| Global Round : 2 | Local Epoch : 3 | [5800/10244 (57%)]	Loss: 0.443892
| Global Round : 2 | Local Epoch : 3 | [5900/10244 (58%)]	Loss: 0.661733
| Global Round : 2 | Local Epoch : 3 | [6000/10244 (59%)]	Loss: 0.014033
| Global Round : 2 | Local Epoch : 3 | [6100/10244 (60%)]	Loss: 0.114957
| Global Round : 2 | Local Epoch : 3 | [6200/10244 (60%)]	Loss: 0.335283
| Global Round : 2 | Local Epoch : 3 | [6300/10244 (61%)]	Loss: 0.089300
| Global Round : 2 | Local Epoch : 3 | [6400/10244 (62%)]	Loss: 0.093667
| Global Round : 2 | Local Epoch : 3 | [6500/10244 (63%)]	Loss: 0.113027
| Global Round : 2 | Local Epoch : 3 | [6600/10244 (64%)]	Loss: 0.139960
| Global Round : 2 | Local Epoch : 3 | [6700/10244 (65%)]	Loss: 0.476681
| Global Round : 2 | Local Epoch : 3 | [6800/10244 (66%)]	Loss: 0.020102
| Global Round : 2 | Local Epoch : 3 | [6900/10244 (67%)]	Loss: 0.122333
| Global Round : 2 | Local Epoch : 3 | [7000/10244 (68%)]	Loss: 0.209221
| Global Round : 2 | Local Epoch : 3 | [7100/10244 (69%)]	Loss: 0.147829
| Global Round : 2 | Local Epoch : 3 | [7200/10244 (70%)]	Loss: 0.018486
| Global Round : 2 | Local Epoch : 3 | [7300/10244 (71%)]	Loss: 0.427100
| Global Round : 2 | Local Epoch : 3 | [7400/10244 (72%)]	Loss: 0.014618
| Global Round : 2 | Local Epoch : 3 | [7500/10244 (73%)]	Loss: 0.171984
| Global Round : 2 | Local Epoch : 3 | [7600/10244 (74%)]	Loss: 0.096897
| Global Round : 2 | Local Epoch : 3 | [7700/10244 (75%)]	Loss: 0.219588
| Global Round : 2 | Local Epoch : 3 | [7800/10244 (76%)]	Loss: 0.223775
| Global Round : 2 | Local Epoch : 3 | [7900/10244 (77%)]	Loss: 0.081689
| Global Round : 2 | Local Epoch : 3 | [8000/10244 (78%)]	Loss: 0.227068
| Global Round : 2 | Local Epoch : 3 | [8100/10244 (79%)]	Loss: 0.266126
| Global Round : 2 | Local Epoch : 3 | [8200/10244 (80%)]	Loss: 0.163457
| Global Round : 2 | Local Epoch : 3 | [8300/10244 (81%)]	Loss: 0.073845
| Global Round : 2 | Local Epoch : 3 | [8400/10244 (82%)]	Loss: 0.008276
| Global Round : 2 | Local Epoch : 3 | [8500/10244 (83%)]	Loss: 0.086788
| Global Round : 2 | Local Epoch : 3 | [8600/10244 (84%)]	Loss: 0.123290
| Global Round : 2 | Local Epoch : 3 | [8700/10244 (85%)]	Loss: 0.074891
| Global Round : 2 | Local Epoch : 3 | [8800/10244 (86%)]	Loss: 0.237935
| Global Round : 2 | Local Epoch : 3 | [8900/10244 (87%)]	Loss: 0.266180
| Global Round : 2 | Local Epoch : 3 | [9000/10244 (88%)]	Loss: 0.213705
| Global Round : 2 | Local Epoch : 3 | [9100/10244 (89%)]	Loss: 0.093321
| Global Round : 2 | Local Epoch : 3 | [9200/10244 (90%)]	Loss: 0.096624
| Global Round : 2 | Local Epoch : 3 | [9300/10244 (91%)]	Loss: 0.576457
| Global Round : 2 | Local Epoch : 3 | [9400/10244 (92%)]	Loss: 0.445322
| Global Round : 2 | Local Epoch : 3 | [9500/10244 (93%)]	Loss: 0.312706
| Global Round : 2 | Local Epoch : 3 | [9600/10244 (94%)]	Loss: 0.183438
| Global Round : 2 | Local Epoch : 3 | [9700/10244 (95%)]	Loss: 0.137439
| Global Round : 2 | Local Epoch : 3 | [9800/10244 (96%)]	Loss: 0.108621
| Global Round : 2 | Local Epoch : 3 | [9900/10244 (97%)]	Loss: 0.024863
| Global Round : 2 | Local Epoch : 3 | [10000/10244 (98%)]	Loss: 0.283972
| Global Round : 2 | Local Epoch : 3 | [10100/10244 (99%)]	Loss: 0.423196
| Global Round : 2 | Local Epoch : 3 | [10200/10244 (100%)]	Loss: 0.239152
| Global Round : 2 | Local Epoch : 4 | [0/10244 (0%)]	Loss: 0.023371
| Global Round : 2 | Local Epoch : 4 | [100/10244 (1%)]	Loss: 0.216213
| Global Round : 2 | Local Epoch : 4 | [200/10244 (2%)]	Loss: 0.188442
| Global Round : 2 | Local Epoch : 4 | [300/10244 (3%)]	Loss: 0.230343
| Global Round : 2 | Local Epoch : 4 | [400/10244 (4%)]	Loss: 0.204164
| Global Round : 2 | Local Epoch : 4 | [500/10244 (5%)]	Loss: 0.086727
| Global Round : 2 | Local Epoch : 4 | [600/10244 (6%)]	Loss: 0.086993
| Global Round : 2 | Local Epoch : 4 | [700/10244 (7%)]	Loss: 0.074367
| Global Round : 2 | Local Epoch : 4 | [800/10244 (8%)]	Loss: 0.284881
| Global Round : 2 | Local Epoch : 4 | [900/10244 (9%)]	Loss: 0.049831
| Global Round : 2 | Local Epoch : 4 | [1000/10244 (10%)]	Loss: 0.084626
| Global Round : 2 | Local Epoch : 4 | [1100/10244 (11%)]	Loss: 0.046978
| Global Round : 2 | Local Epoch : 4 | [1200/10244 (12%)]	Loss: 0.069413
| Global Round : 2 | Local Epoch : 4 | [1300/10244 (13%)]	Loss: 0.211453
| Global Round : 2 | Local Epoch : 4 | [1400/10244 (14%)]	Loss: 0.198484
| Global Round : 2 | Local Epoch : 4 | [1500/10244 (15%)]	Loss: 0.034330
| Global Round : 2 | Local Epoch : 4 | [1600/10244 (16%)]	Loss: 0.177177
| Global Round : 2 | Local Epoch : 4 | [1700/10244 (17%)]	Loss: 0.704348
| Global Round : 2 | Local Epoch : 4 | [1800/10244 (18%)]	Loss: 0.024371
| Global Round : 2 | Local Epoch : 4 | [1900/10244 (19%)]	Loss: 0.233853
| Global Round : 2 | Local Epoch : 4 | [2000/10244 (20%)]	Loss: 0.064051
| Global Round : 2 | Local Epoch : 4 | [2100/10244 (20%)]	Loss: 0.046234
| Global Round : 2 | Local Epoch : 4 | [2200/10244 (21%)]	Loss: 0.120762
| Global Round : 2 | Local Epoch : 4 | [2300/10244 (22%)]	Loss: 0.227830
| Global Round : 2 | Local Epoch : 4 | [2400/10244 (23%)]	Loss: 0.180104
| Global Round : 2 | Local Epoch : 4 | [2500/10244 (24%)]	Loss: 0.184980
| Global Round : 2 | Local Epoch : 4 | [2600/10244 (25%)]	Loss: 0.074569
| Global Round : 2 | Local Epoch : 4 | [2700/10244 (26%)]	Loss: 0.046688
| Global Round : 2 | Local Epoch : 4 | [2800/10244 (27%)]	Loss: 0.011722
| Global Round : 2 | Local Epoch : 4 | [2900/10244 (28%)]	Loss: 0.170659
| Global Round : 2 | Local Epoch : 4 | [3000/10244 (29%)]	Loss: 0.046110
| Global Round : 2 | Local Epoch : 4 | [3100/10244 (30%)]	Loss: 0.005008
| Global Round : 2 | Local Epoch : 4 | [3200/10244 (31%)]	Loss: 0.004809
| Global Round : 2 | Local Epoch : 4 | [3300/10244 (32%)]	Loss: 0.043505
| Global Round : 2 | Local Epoch : 4 | [3400/10244 (33%)]	Loss: 0.095845
| Global Round : 2 | Local Epoch : 4 | [3500/10244 (34%)]	Loss: 0.219136
| Global Round : 2 | Local Epoch : 4 | [3600/10244 (35%)]	Loss: 0.053138
| Global Round : 2 | Local Epoch : 4 | [3700/10244 (36%)]	Loss: 0.052793
| Global Round : 2 | Local Epoch : 4 | [3800/10244 (37%)]	Loss: 0.283756
| Global Round : 2 | Local Epoch : 4 | [3900/10244 (38%)]	Loss: 0.006476
| Global Round : 2 | Local Epoch : 4 | [4000/10244 (39%)]	Loss: 0.031867
| Global Round : 2 | Local Epoch : 4 | [4100/10244 (40%)]	Loss: 0.263201
| Global Round : 2 | Local Epoch : 4 | [4200/10244 (41%)]	Loss: 0.025926
| Global Round : 2 | Local Epoch : 4 | [4300/10244 (42%)]	Loss: 0.515320
| Global Round : 2 | Local Epoch : 4 | [4400/10244 (43%)]	Loss: 0.037463
| Global Round : 2 | Local Epoch : 4 | [4500/10244 (44%)]	Loss: 0.137574
| Global Round : 2 | Local Epoch : 4 | [4600/10244 (45%)]	Loss: 0.034236
| Global Round : 2 | Local Epoch : 4 | [4700/10244 (46%)]	Loss: 0.060476
| Global Round : 2 | Local Epoch : 4 | [4800/10244 (47%)]	Loss: 0.361190
| Global Round : 2 | Local Epoch : 4 | [4900/10244 (48%)]	Loss: 0.239611
| Global Round : 2 | Local Epoch : 4 | [5000/10244 (49%)]	Loss: 0.033781
| Global Round : 2 | Local Epoch : 4 | [5100/10244 (50%)]	Loss: 0.201977
| Global Round : 2 | Local Epoch : 4 | [5200/10244 (51%)]	Loss: 0.421905
| Global Round : 2 | Local Epoch : 4 | [5300/10244 (52%)]	Loss: 0.153332
| Global Round : 2 | Local Epoch : 4 | [5400/10244 (53%)]	Loss: 0.009309
| Global Round : 2 | Local Epoch : 4 | [5500/10244 (54%)]	Loss: 0.372670
| Global Round : 2 | Local Epoch : 4 | [5600/10244 (55%)]	Loss: 0.032982
| Global Round : 2 | Local Epoch : 4 | [5700/10244 (56%)]	Loss: 0.061321
| Global Round : 2 | Local Epoch : 4 | [5800/10244 (57%)]	Loss: 0.121704
| Global Round : 2 | Local Epoch : 4 | [5900/10244 (58%)]	Loss: 0.002917
| Global Round : 2 | Local Epoch : 4 | [6000/10244 (59%)]	Loss: 0.312587
| Global Round : 2 | Local Epoch : 4 | [6100/10244 (60%)]	Loss: 0.058557
| Global Round : 2 | Local Epoch : 4 | [6200/10244 (60%)]	Loss: 0.313921
| Global Round : 2 | Local Epoch : 4 | [6300/10244 (61%)]	Loss: 0.215225
| Global Round : 2 | Local Epoch : 4 | [6400/10244 (62%)]	Loss: 0.062777
| Global Round : 2 | Local Epoch : 4 | [6500/10244 (63%)]	Loss: 0.050758
| Global Round : 2 | Local Epoch : 4 | [6600/10244 (64%)]	Loss: 0.114293
| Global Round : 2 | Local Epoch : 4 | [6700/10244 (65%)]	Loss: 0.091473
| Global Round : 2 | Local Epoch : 4 | [6800/10244 (66%)]	Loss: 0.128649
| Global Round : 2 | Local Epoch : 4 | [6900/10244 (67%)]	Loss: 0.040653
| Global Round : 2 | Local Epoch : 4 | [7000/10244 (68%)]	Loss: 0.159620
| Global Round : 2 | Local Epoch : 4 | [7100/10244 (69%)]	Loss: 0.165665
| Global Round : 2 | Local Epoch : 4 | [7200/10244 (70%)]	Loss: 0.374292
| Global Round : 2 | Local Epoch : 4 | [7300/10244 (71%)]	Loss: 0.253040
| Global Round : 2 | Local Epoch : 4 | [7400/10244 (72%)]	Loss: 0.132380
| Global Round : 2 | Local Epoch : 4 | [7500/10244 (73%)]	Loss: 0.215559
| Global Round : 2 | Local Epoch : 4 | [7600/10244 (74%)]	Loss: 0.087575
| Global Round : 2 | Local Epoch : 4 | [7700/10244 (75%)]	Loss: 0.061252
| Global Round : 2 | Local Epoch : 4 | [7800/10244 (76%)]	Loss: 0.022297
| Global Round : 2 | Local Epoch : 4 | [7900/10244 (77%)]	Loss: 0.067426
| Global Round : 2 | Local Epoch : 4 | [8000/10244 (78%)]	Loss: 0.010776
| Global Round : 2 | Local Epoch : 4 | [8100/10244 (79%)]	Loss: 0.006587
| Global Round : 2 | Local Epoch : 4 | [8200/10244 (80%)]	Loss: 0.011210
| Global Round : 2 | Local Epoch : 4 | [8300/10244 (81%)]	Loss: 0.070489
| Global Round : 2 | Local Epoch : 4 | [8400/10244 (82%)]	Loss: 0.025129
| Global Round : 2 | Local Epoch : 4 | [8500/10244 (83%)]	Loss: 0.027952
| Global Round : 2 | Local Epoch : 4 | [8600/10244 (84%)]	Loss: 0.190117
| Global Round : 2 | Local Epoch : 4 | [8700/10244 (85%)]	Loss: 0.014599
| Global Round : 2 | Local Epoch : 4 | [8800/10244 (86%)]	Loss: 0.227306
| Global Round : 2 | Local Epoch : 4 | [8900/10244 (87%)]	Loss: 0.094946
| Global Round : 2 | Local Epoch : 4 | [9000/10244 (88%)]	Loss: 0.084426
| Global Round : 2 | Local Epoch : 4 | [9100/10244 (89%)]	Loss: 0.049162
| Global Round : 2 | Local Epoch : 4 | [9200/10244 (90%)]	Loss: 0.016285
| Global Round : 2 | Local Epoch : 4 | [9300/10244 (91%)]	Loss: 0.021149
| Global Round : 2 | Local Epoch : 4 | [9400/10244 (92%)]	Loss: 0.046307
| Global Round : 2 | Local Epoch : 4 | [9500/10244 (93%)]	Loss: 0.102168
| Global Round : 2 | Local Epoch : 4 | [9600/10244 (94%)]	Loss: 0.182087
| Global Round : 2 | Local Epoch : 4 | [9700/10244 (95%)]	Loss: 0.036496
| Global Round : 2 | Local Epoch : 4 | [9800/10244 (96%)]	Loss: 0.205785
| Global Round : 2 | Local Epoch : 4 | [9900/10244 (97%)]	Loss: 0.076154
| Global Round : 2 | Local Epoch : 4 | [10000/10244 (98%)]	Loss: 0.077213
| Global Round : 2 | Local Epoch : 4 | [10100/10244 (99%)]	Loss: 0.622175
| Global Round : 2 | Local Epoch : 4 | [10200/10244 (100%)]	Loss: 0.050640
----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.91      0.94        66
         DME       0.91      0.97      0.94        62

    accuracy                           0.94       128
   macro avg       0.94      0.94      0.94       128
weighted avg       0.94      0.94      0.94       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.91      0.93        54
         DME       0.94      0.97      0.95        74

    accuracy                           0.95       128
   macro avg       0.95      0.94      0.94       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.86      0.88        59
         DME       0.89      0.91      0.90        69

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.91      0.93        64
         DME       0.91      0.95      0.93        64

    accuracy                           0.93       128
   macro avg       0.93      0.93      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.85      0.89        68
         DME       0.85      0.92      0.88        60

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        67
         DME       0.89      0.93      0.91        61

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.85      0.86        59
         DME       0.87      0.90      0.89        69

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        69
         DME       0.89      0.93      0.91        59

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.83      0.88        64
         DME       0.85      0.94      0.89        64

    accuracy                           0.88       128
   macro avg       0.89      0.88      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.83      0.88        69
         DME       0.82      0.93      0.87        59

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
         DME       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.91      0.94        66
      DRUSEN       0.91      0.97      0.94        62

    accuracy                           0.94       128
   macro avg       0.94      0.94      0.94       128
weighted avg       0.94      0.94      0.94       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.91      0.93        54
      DRUSEN       0.94      0.97      0.95        74

    accuracy                           0.95       128
   macro avg       0.95      0.94      0.94       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.86      0.88        59
      DRUSEN       0.89      0.91      0.90        69

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.91      0.93        64
      DRUSEN       0.91      0.95      0.93        64

    accuracy                           0.93       128
   macro avg       0.93      0.93      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.85      0.89        68
      DRUSEN       0.85      0.92      0.88        60

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        67
      DRUSEN       0.89      0.93      0.91        61

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.85      0.86        59
      DRUSEN       0.87      0.90      0.89        69

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        69
      DRUSEN       0.89      0.93      0.91        59

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.83      0.88        64
      DRUSEN       0.85      0.94      0.89        64

    accuracy                           0.88       128
   macro avg       0.89      0.88      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.83      0.88        69
      DRUSEN       0.82      0.93      0.87        59

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
      DRUSEN       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

Training accuracy [0.84921875, 0.8907103825136612, 0.9047619047619048]
########################

Client 1 Test Statistics

==========================

For client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.68      0.78        92
         DME       0.50      0.81      0.62        36

    accuracy                           0.72       128
   macro avg       0.70      0.75      0.70       128
weighted avg       0.79      0.72      0.73       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.78      0.87        87
         DME       0.67      0.95      0.79        41

    accuracy                           0.84       128
   macro avg       0.82      0.87      0.83       128
weighted avg       0.88      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.73      0.84        82
         DME       0.67      0.98      0.80        46

    accuracy                           0.82       128
   macro avg       0.83      0.85      0.82       128
weighted avg       0.87      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.70      0.82        73
         DME       0.71      0.98      0.82        55

    accuracy                           0.82       128
   macro avg       0.85      0.84      0.82       128
weighted avg       0.86      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.77      0.84        82
         DME       0.68      0.89      0.77        46

    accuracy                           0.81       128
   macro avg       0.80      0.83      0.81       128
weighted avg       0.84      0.81      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.77      0.86        77
         DME       0.74      0.98      0.84        51

    accuracy                           0.85       128
   macro avg       0.86      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.78      0.87        83
         DME       0.71      0.98      0.82        45

    accuracy                           0.85       128
   macro avg       0.85      0.88      0.85       128
weighted avg       0.89      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.73      0.81        66
         DME       0.76      0.94      0.84        62

    accuracy                           0.83       128
   macro avg       0.84      0.83      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.83      0.89        82
         DME       0.76      0.96      0.85        46

    accuracy                           0.88       128
   macro avg       0.87      0.89      0.87       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.77      0.87        84
         DME       0.69      0.98      0.81        44

    accuracy                           0.84       128
   macro avg       0.84      0.88      0.84       128
weighted avg       0.88      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.73      0.82        84
         DME       0.64      0.93      0.76        44

    accuracy                           0.80       128
   macro avg       0.80      0.83      0.79       128
weighted avg       0.85      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.75      0.85        84
         DME       0.67      0.95      0.79        44

    accuracy                           0.82       128
   macro avg       0.82      0.85      0.82       128
weighted avg       0.87      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.75      0.85        73
         DME       0.75      0.98      0.85        55

    accuracy                           0.85       128
   macro avg       0.87      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.67      0.78        87
         DME       0.57      0.93      0.70        41

    accuracy                           0.75       128
   macro avg       0.76      0.80      0.74       128
weighted avg       0.83      0.75      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.71      0.81        80
         DME       0.66      0.92      0.77        48

    accuracy                           0.79       128
   macro avg       0.80      0.81      0.79       128
weighted avg       0.83      0.79      0.79       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.99      0.84      0.91        90
         DME       0.73      0.97      0.83        38

    accuracy                           0.88       128
   macro avg       0.86      0.91      0.87       128
weighted avg       0.91      0.88      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.76      0.84        84
         DME       0.67      0.91      0.77        44

    accuracy                           0.81       128
   macro avg       0.80      0.84      0.81       128
weighted avg       0.85      0.81      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.76      0.85        79
         DME       0.71      0.96      0.82        49

    accuracy                           0.84       128
   macro avg       0.84      0.86      0.83       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.66      0.78        82
         DME       0.61      0.93      0.74        46

    accuracy                           0.76       128
   macro avg       0.78      0.80      0.76       128
weighted avg       0.82      0.76      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.79      0.87        81
         DME       0.73      0.96      0.83        47

    accuracy                           0.85       128
   macro avg       0.85      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.78      0.88        81
         DME       0.72      1.00      0.84        47

    accuracy                           0.86       128
   macro avg       0.86      0.89      0.86       128
weighted avg       0.90      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.67      0.77        82
         DME       0.60      0.89      0.72        46

    accuracy                           0.75       128
   macro avg       0.76      0.78      0.75       128
weighted avg       0.80      0.75      0.75       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.77      0.85        83
         DME       0.68      0.91      0.78        45

    accuracy                           0.82       128
   macro avg       0.81      0.84      0.81       128
weighted avg       0.85      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.78      0.88        86
         DME       0.69      1.00      0.82        42

    accuracy                           0.85       128
   macro avg       0.84      0.89      0.85       128
weighted avg       0.90      0.85      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.81      0.88        85
         DME       0.72      0.95      0.82        43

    accuracy                           0.86       128
   macro avg       0.85      0.88      0.85       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.33      0.50         3
         DME       0.50      1.00      0.67         2

    accuracy                           0.60         5
   macro avg       0.75      0.67      0.58         5
weighted avg       0.80      0.60      0.57         5

----------------------

==========================

Testing client 1 on client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.93      0.94        55
      DRUSEN       0.95      0.96      0.95        73

    accuracy                           0.95       128
   macro avg       0.95      0.94      0.94       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.89      0.91        64
      DRUSEN       0.90      0.94      0.92        64

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.90      0.93        77
      DRUSEN       0.86      0.96      0.91        51

    accuracy                           0.92       128
   macro avg       0.92      0.93      0.92       128
weighted avg       0.93      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.84      0.87        74
      DRUSEN       0.80      0.89      0.84        54

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.86      0.92        71
      DRUSEN       0.85      0.98      0.91        57

    accuracy                           0.91       128
   macro avg       0.92      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        73
      DRUSEN       0.88      0.93      0.90        55

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.86      0.90        66
      DRUSEN       0.87      0.94      0.90        62

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.92      0.93        71
      DRUSEN       0.90      0.93      0.91        57

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.92      0.91        64
      DRUSEN       0.92      0.89      0.90        64

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.85      0.90        61
      DRUSEN       0.88      0.97      0.92        67

    accuracy                           0.91       128
   macro avg       0.92      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.87      0.89        55
      DRUSEN       0.91      0.93      0.92        73

    accuracy                           0.91       128
   macro avg       0.91      0.90      0.90       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.92      0.93        63
      DRUSEN       0.92      0.94      0.93        65

    accuracy                           0.93       128
   macro avg       0.93      0.93      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        69
      DRUSEN       0.89      0.93      0.91        59

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        82
      DRUSEN       0.84      0.89      0.86        46

    accuracy                           0.90       128
   macro avg       0.89      0.90      0.89       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.94      0.95        72
      DRUSEN       0.93      0.95      0.94        56

    accuracy                           0.95       128
   macro avg       0.94      0.95      0.94       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.87      0.89        60
      DRUSEN       0.89      0.93      0.91        68

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.88      0.92        75
      DRUSEN       0.85      0.96      0.90        53

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.90      0.90        68
      DRUSEN       0.89      0.90      0.89        60

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.84      0.89        77
      DRUSEN       0.80      0.92      0.85        51

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.85      0.89        62
      DRUSEN       0.87      0.94      0.91        66

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.89      0.89        61
      DRUSEN       0.90      0.91      0.90        67

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.83      0.86        59
      DRUSEN       0.86      0.91      0.89        69

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.85      0.90        75
      DRUSEN       0.82      0.92      0.87        53

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.99      0.87      0.93        78
      DRUSEN       0.83      0.98      0.90        50

    accuracy                           0.91       128
   macro avg       0.91      0.93      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.90      0.91        61
      DRUSEN       0.90      0.92      0.91        62

    accuracy                           0.91       123
   macro avg       0.91      0.91      0.91       123
weighted avg       0.91      0.91      0.91       123

----------------------

########################

Client 2 Test Statistics

==========================

For client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.93      0.94        55
      DRUSEN       0.95      0.96      0.95        73

    accuracy                           0.95       128
   macro avg       0.95      0.94      0.94       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.89      0.91        64
      DRUSEN       0.90      0.94      0.92        64

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.90      0.93        77
      DRUSEN       0.86      0.96      0.91        51

    accuracy                           0.92       128
   macro avg       0.92      0.93      0.92       128
weighted avg       0.93      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.84      0.87        74
      DRUSEN       0.80      0.89      0.84        54

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.86      0.92        71
      DRUSEN       0.85      0.98      0.91        57

    accuracy                           0.91       128
   macro avg       0.92      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        73
      DRUSEN       0.88      0.93      0.90        55

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.86      0.90        66
      DRUSEN       0.87      0.94      0.90        62

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.92      0.93        71
      DRUSEN       0.90      0.93      0.91        57

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.92      0.91        64
      DRUSEN       0.92      0.89      0.90        64

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.85      0.90        61
      DRUSEN       0.88      0.97      0.92        67

    accuracy                           0.91       128
   macro avg       0.92      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.87      0.89        55
      DRUSEN       0.91      0.93      0.92        73

    accuracy                           0.91       128
   macro avg       0.91      0.90      0.90       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.92      0.93        63
      DRUSEN       0.92      0.94      0.93        65

    accuracy                           0.93       128
   macro avg       0.93      0.93      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        69
      DRUSEN       0.89      0.93      0.91        59

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.90      0.92        82
      DRUSEN       0.84      0.89      0.86        46

    accuracy                           0.90       128
   macro avg       0.89      0.90      0.89       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.94      0.95        72
      DRUSEN       0.93      0.95      0.94        56

    accuracy                           0.95       128
   macro avg       0.94      0.95      0.94       128
weighted avg       0.95      0.95      0.95       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.87      0.89        60
      DRUSEN       0.89      0.93      0.91        68

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.88      0.92        75
      DRUSEN       0.85      0.96      0.90        53

    accuracy                           0.91       128
   macro avg       0.91      0.92      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.90      0.90        68
      DRUSEN       0.89      0.90      0.89        60

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.84      0.89        77
      DRUSEN       0.80      0.92      0.85        51

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.85      0.89        62
      DRUSEN       0.87      0.94      0.91        66

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.89      0.89        61
      DRUSEN       0.90      0.91      0.90        67

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.83      0.86        59
      DRUSEN       0.86      0.91      0.89        69

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.85      0.90        75
      DRUSEN       0.82      0.92      0.87        53

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.99      0.87      0.93        78
      DRUSEN       0.83      0.98      0.90        50

    accuracy                           0.91       128
   macro avg       0.91      0.93      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.90      0.91        61
      DRUSEN       0.90      0.92      0.91        62

    accuracy                           0.91       123
   macro avg       0.91      0.91      0.91       123
weighted avg       0.91      0.91      0.91       123

----------------------

==========================

Testing client 2 on client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.68      0.78        92
         DME       0.50      0.81      0.62        36

    accuracy                           0.72       128
   macro avg       0.70      0.75      0.70       128
weighted avg       0.79      0.72      0.73       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.78      0.87        87
         DME       0.67      0.95      0.79        41

    accuracy                           0.84       128
   macro avg       0.82      0.87      0.83       128
weighted avg       0.88      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.73      0.84        82
         DME       0.67      0.98      0.80        46

    accuracy                           0.82       128
   macro avg       0.83      0.85      0.82       128
weighted avg       0.87      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.70      0.82        73
         DME       0.71      0.98      0.82        55

    accuracy                           0.82       128
   macro avg       0.85      0.84      0.82       128
weighted avg       0.86      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.77      0.84        82
         DME       0.68      0.89      0.77        46

    accuracy                           0.81       128
   macro avg       0.80      0.83      0.81       128
weighted avg       0.84      0.81      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.77      0.86        77
         DME       0.74      0.98      0.84        51

    accuracy                           0.85       128
   macro avg       0.86      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.78      0.87        83
         DME       0.71      0.98      0.82        45

    accuracy                           0.85       128
   macro avg       0.85      0.88      0.85       128
weighted avg       0.89      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.73      0.81        66
         DME       0.76      0.94      0.84        62

    accuracy                           0.83       128
   macro avg       0.84      0.83      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.83      0.89        82
         DME       0.76      0.96      0.85        46

    accuracy                           0.88       128
   macro avg       0.87      0.89      0.87       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.77      0.87        84
         DME       0.69      0.98      0.81        44

    accuracy                           0.84       128
   macro avg       0.84      0.88      0.84       128
weighted avg       0.88      0.84      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.73      0.82        84
         DME       0.64      0.93      0.76        44

    accuracy                           0.80       128
   macro avg       0.80      0.83      0.79       128
weighted avg       0.85      0.80      0.80       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.75      0.85        84
         DME       0.67      0.95      0.79        44

    accuracy                           0.82       128
   macro avg       0.82      0.85      0.82       128
weighted avg       0.87      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.75      0.85        73
         DME       0.75      0.98      0.85        55

    accuracy                           0.85       128
   macro avg       0.87      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.67      0.78        87
         DME       0.57      0.93      0.70        41

    accuracy                           0.75       128
   macro avg       0.76      0.80      0.74       128
weighted avg       0.83      0.75      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.71      0.81        80
         DME       0.66      0.92      0.77        48

    accuracy                           0.79       128
   macro avg       0.80      0.81      0.79       128
weighted avg       0.83      0.79      0.79       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.99      0.84      0.91        90
         DME       0.73      0.97      0.83        38

    accuracy                           0.88       128
   macro avg       0.86      0.91      0.87       128
weighted avg       0.91      0.88      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.76      0.84        84
         DME       0.67      0.91      0.77        44

    accuracy                           0.81       128
   macro avg       0.80      0.84      0.81       128
weighted avg       0.85      0.81      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.76      0.85        79
         DME       0.71      0.96      0.82        49

    accuracy                           0.84       128
   macro avg       0.84      0.86      0.83       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.66      0.78        82
         DME       0.61      0.93      0.74        46

    accuracy                           0.76       128
   macro avg       0.78      0.80      0.76       128
weighted avg       0.82      0.76      0.76       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.79      0.87        81
         DME       0.73      0.96      0.83        47

    accuracy                           0.85       128
   macro avg       0.85      0.87      0.85       128
weighted avg       0.88      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.78      0.88        81
         DME       0.72      1.00      0.84        47

    accuracy                           0.86       128
   macro avg       0.86      0.89      0.86       128
weighted avg       0.90      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.67      0.77        82
         DME       0.60      0.89      0.72        46

    accuracy                           0.75       128
   macro avg       0.76      0.78      0.75       128
weighted avg       0.80      0.75      0.75       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.77      0.85        83
         DME       0.68      0.91      0.78        45

    accuracy                           0.82       128
   macro avg       0.81      0.84      0.81       128
weighted avg       0.85      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.78      0.88        86
         DME       0.69      1.00      0.82        42

    accuracy                           0.85       128
   macro avg       0.84      0.89      0.85       128
weighted avg       0.90      0.85      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.81      0.88        85
         DME       0.72      0.95      0.82        43

    accuracy                           0.86       128
   macro avg       0.85      0.88      0.85       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.33      0.50         3
         DME       0.50      1.00      0.67         2

    accuracy                           0.60         5
   macro avg       0.75      0.67      0.58         5
weighted avg       0.80      0.60      0.57         5

----------------------

Test accuracy on client 1 0.8215288611544462
Test accuracy on client 2 0.9067292644757433
========================================

========================================

Test on original client distribution for client 1 : 82.15%
Test on client 2 distribution for client 1 : 90.67%
Test on original client distribution for client 2 : 90.67%
Test on client 1 distribution for client 2 : 82.15%
