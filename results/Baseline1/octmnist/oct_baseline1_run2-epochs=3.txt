
Experimental details:
    Model     : cnn
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 3

    Federated parameters:
   IID
    Number of users  : 2
    Local Batch size   : 10
    Local Epochs       : 5

CNNOCTmnist(
  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): Dropout2d(p=0.5, inplace=False)
  (fc1): Linear(in_features=100820, out_features=50, bias=True)
  (fc2): Linear(in_features=50, out_features=2, bias=True)
)

 | Global Training Round : 1 |

----------------
user chosen 1
----------------
----------------
| Global Round : 0 | Local Epoch : 0 | [0/10242 (0%)]	Loss: 0.663033
| Global Round : 0 | Local Epoch : 0 | [100/10242 (1%)]	Loss: 0.647653
| Global Round : 0 | Local Epoch : 0 | [200/10242 (2%)]	Loss: 0.760017
| Global Round : 0 | Local Epoch : 0 | [300/10242 (3%)]	Loss: 0.754142
| Global Round : 0 | Local Epoch : 0 | [400/10242 (4%)]	Loss: 0.767479
| Global Round : 0 | Local Epoch : 0 | [500/10242 (5%)]	Loss: 0.668003
| Global Round : 0 | Local Epoch : 0 | [600/10242 (6%)]	Loss: 0.677875
| Global Round : 0 | Local Epoch : 0 | [700/10242 (7%)]	Loss: 0.706744
| Global Round : 0 | Local Epoch : 0 | [800/10242 (8%)]	Loss: 0.714011
| Global Round : 0 | Local Epoch : 0 | [900/10242 (9%)]	Loss: 0.674547
| Global Round : 0 | Local Epoch : 0 | [1000/10242 (10%)]	Loss: 0.663413
| Global Round : 0 | Local Epoch : 0 | [1100/10242 (11%)]	Loss: 0.680584
| Global Round : 0 | Local Epoch : 0 | [1200/10242 (12%)]	Loss: 0.604710
| Global Round : 0 | Local Epoch : 0 | [1300/10242 (13%)]	Loss: 0.594330
| Global Round : 0 | Local Epoch : 0 | [1400/10242 (14%)]	Loss: 0.660700
| Global Round : 0 | Local Epoch : 0 | [1500/10242 (15%)]	Loss: 0.635787
| Global Round : 0 | Local Epoch : 0 | [1600/10242 (16%)]	Loss: 0.692801
| Global Round : 0 | Local Epoch : 0 | [1700/10242 (17%)]	Loss: 0.706077
| Global Round : 0 | Local Epoch : 0 | [1800/10242 (18%)]	Loss: 0.681828
| Global Round : 0 | Local Epoch : 0 | [1900/10242 (19%)]	Loss: 0.741960
| Global Round : 0 | Local Epoch : 0 | [2000/10242 (20%)]	Loss: 0.710119
| Global Round : 0 | Local Epoch : 0 | [2100/10242 (20%)]	Loss: 0.726074
| Global Round : 0 | Local Epoch : 0 | [2200/10242 (21%)]	Loss: 0.636796
| Global Round : 0 | Local Epoch : 0 | [2300/10242 (22%)]	Loss: 0.658179
| Global Round : 0 | Local Epoch : 0 | [2400/10242 (23%)]	Loss: 0.715793
| Global Round : 0 | Local Epoch : 0 | [2500/10242 (24%)]	Loss: 0.795981
| Global Round : 0 | Local Epoch : 0 | [2600/10242 (25%)]	Loss: 0.644895
| Global Round : 0 | Local Epoch : 0 | [2700/10242 (26%)]	Loss: 0.677086
| Global Round : 0 | Local Epoch : 0 | [2800/10242 (27%)]	Loss: 0.697480
| Global Round : 0 | Local Epoch : 0 | [2900/10242 (28%)]	Loss: 0.679493
| Global Round : 0 | Local Epoch : 0 | [3000/10242 (29%)]	Loss: 0.687011
| Global Round : 0 | Local Epoch : 0 | [3100/10242 (30%)]	Loss: 0.866948
| Global Round : 0 | Local Epoch : 0 | [3200/10242 (31%)]	Loss: 0.683736
| Global Round : 0 | Local Epoch : 0 | [3300/10242 (32%)]	Loss: 0.678966
| Global Round : 0 | Local Epoch : 0 | [3400/10242 (33%)]	Loss: 0.695510
| Global Round : 0 | Local Epoch : 0 | [3500/10242 (34%)]	Loss: 0.719810
| Global Round : 0 | Local Epoch : 0 | [3600/10242 (35%)]	Loss: 0.772697
| Global Round : 0 | Local Epoch : 0 | [3700/10242 (36%)]	Loss: 0.668810
| Global Round : 0 | Local Epoch : 0 | [3800/10242 (37%)]	Loss: 0.695164
| Global Round : 0 | Local Epoch : 0 | [3900/10242 (38%)]	Loss: 0.674655
| Global Round : 0 | Local Epoch : 0 | [4000/10242 (39%)]	Loss: 0.671002
| Global Round : 0 | Local Epoch : 0 | [4100/10242 (40%)]	Loss: 0.713759
| Global Round : 0 | Local Epoch : 0 | [4200/10242 (41%)]	Loss: 0.677414
| Global Round : 0 | Local Epoch : 0 | [4300/10242 (42%)]	Loss: 0.704528
| Global Round : 0 | Local Epoch : 0 | [4400/10242 (43%)]	Loss: 0.658787
| Global Round : 0 | Local Epoch : 0 | [4500/10242 (44%)]	Loss: 0.658891
| Global Round : 0 | Local Epoch : 0 | [4600/10242 (45%)]	Loss: 0.674693
| Global Round : 0 | Local Epoch : 0 | [4700/10242 (46%)]	Loss: 0.627986
| Global Round : 0 | Local Epoch : 0 | [4800/10242 (47%)]	Loss: 0.717229
| Global Round : 0 | Local Epoch : 0 | [4900/10242 (48%)]	Loss: 0.647236
| Global Round : 0 | Local Epoch : 0 | [5000/10242 (49%)]	Loss: 0.687119
| Global Round : 0 | Local Epoch : 0 | [5100/10242 (50%)]	Loss: 0.679679
| Global Round : 0 | Local Epoch : 0 | [5200/10242 (51%)]	Loss: 0.848956
| Global Round : 0 | Local Epoch : 0 | [5300/10242 (52%)]	Loss: 0.470151
| Global Round : 0 | Local Epoch : 0 | [5400/10242 (53%)]	Loss: 0.670486
| Global Round : 0 | Local Epoch : 0 | [5500/10242 (54%)]	Loss: 0.697026
| Global Round : 0 | Local Epoch : 0 | [5600/10242 (55%)]	Loss: 0.640310
| Global Round : 0 | Local Epoch : 0 | [5700/10242 (56%)]	Loss: 0.580941
| Global Round : 0 | Local Epoch : 0 | [5800/10242 (57%)]	Loss: 0.572113
| Global Round : 0 | Local Epoch : 0 | [5900/10242 (58%)]	Loss: 0.626119
| Global Round : 0 | Local Epoch : 0 | [6000/10242 (59%)]	Loss: 0.860591
| Global Round : 0 | Local Epoch : 0 | [6100/10242 (60%)]	Loss: 0.673482
| Global Round : 0 | Local Epoch : 0 | [6200/10242 (60%)]	Loss: 0.718250
| Global Round : 0 | Local Epoch : 0 | [6300/10242 (61%)]	Loss: 0.622028
| Global Round : 0 | Local Epoch : 0 | [6400/10242 (62%)]	Loss: 0.699936
| Global Round : 0 | Local Epoch : 0 | [6500/10242 (63%)]	Loss: 0.655608
| Global Round : 0 | Local Epoch : 0 | [6600/10242 (64%)]	Loss: 0.661698
| Global Round : 0 | Local Epoch : 0 | [6700/10242 (65%)]	Loss: 0.700433
| Global Round : 0 | Local Epoch : 0 | [6800/10242 (66%)]	Loss: 0.645136
| Global Round : 0 | Local Epoch : 0 | [6900/10242 (67%)]	Loss: 0.609087
| Global Round : 0 | Local Epoch : 0 | [7000/10242 (68%)]	Loss: 0.620020
| Global Round : 0 | Local Epoch : 0 | [7100/10242 (69%)]	Loss: 0.815529
| Global Round : 0 | Local Epoch : 0 | [7200/10242 (70%)]	Loss: 0.684724
| Global Round : 0 | Local Epoch : 0 | [7300/10242 (71%)]	Loss: 0.666854
| Global Round : 0 | Local Epoch : 0 | [7400/10242 (72%)]	Loss: 0.621504
| Global Round : 0 | Local Epoch : 0 | [7500/10242 (73%)]	Loss: 0.727522
| Global Round : 0 | Local Epoch : 0 | [7600/10242 (74%)]	Loss: 0.840898
| Global Round : 0 | Local Epoch : 0 | [7700/10242 (75%)]	Loss: 0.665640
| Global Round : 0 | Local Epoch : 0 | [7800/10242 (76%)]	Loss: 0.573746
| Global Round : 0 | Local Epoch : 0 | [7900/10242 (77%)]	Loss: 0.650443
| Global Round : 0 | Local Epoch : 0 | [8000/10242 (78%)]	Loss: 0.582171
| Global Round : 0 | Local Epoch : 0 | [8100/10242 (79%)]	Loss: 0.676300
| Global Round : 0 | Local Epoch : 0 | [8200/10242 (80%)]	Loss: 0.658151
| Global Round : 0 | Local Epoch : 0 | [8300/10242 (81%)]	Loss: 0.604033
| Global Round : 0 | Local Epoch : 0 | [8400/10242 (82%)]	Loss: 0.586992
| Global Round : 0 | Local Epoch : 0 | [8500/10242 (83%)]	Loss: 0.685154
| Global Round : 0 | Local Epoch : 0 | [8600/10242 (84%)]	Loss: 0.572628
| Global Round : 0 | Local Epoch : 0 | [8700/10242 (85%)]	Loss: 0.559485
| Global Round : 0 | Local Epoch : 0 | [8800/10242 (86%)]	Loss: 0.685535
| Global Round : 0 | Local Epoch : 0 | [8900/10242 (87%)]	Loss: 0.570595
| Global Round : 0 | Local Epoch : 0 | [9000/10242 (88%)]	Loss: 0.582175
| Global Round : 0 | Local Epoch : 0 | [9100/10242 (89%)]	Loss: 0.513912
| Global Round : 0 | Local Epoch : 0 | [9200/10242 (90%)]	Loss: 0.700845
| Global Round : 0 | Local Epoch : 0 | [9300/10242 (91%)]	Loss: 0.604685
| Global Round : 0 | Local Epoch : 0 | [9400/10242 (92%)]	Loss: 0.646037
| Global Round : 0 | Local Epoch : 0 | [9500/10242 (93%)]	Loss: 0.695699
| Global Round : 0 | Local Epoch : 0 | [9600/10242 (94%)]	Loss: 0.690002
| Global Round : 0 | Local Epoch : 0 | [9700/10242 (95%)]	Loss: 0.610528
| Global Round : 0 | Local Epoch : 0 | [9800/10242 (96%)]	Loss: 0.794977
| Global Round : 0 | Local Epoch : 0 | [9900/10242 (97%)]	Loss: 0.627246
| Global Round : 0 | Local Epoch : 0 | [10000/10242 (98%)]	Loss: 0.483560
| Global Round : 0 | Local Epoch : 0 | [10100/10242 (99%)]	Loss: 0.748938
| Global Round : 0 | Local Epoch : 0 | [10200/10242 (100%)]	Loss: 0.693391
| Global Round : 0 | Local Epoch : 1 | [0/10242 (0%)]	Loss: 0.595442
| Global Round : 0 | Local Epoch : 1 | [100/10242 (1%)]	Loss: 0.666217
| Global Round : 0 | Local Epoch : 1 | [200/10242 (2%)]	Loss: 0.546663
| Global Round : 0 | Local Epoch : 1 | [300/10242 (3%)]	Loss: 0.556228
| Global Round : 0 | Local Epoch : 1 | [400/10242 (4%)]	Loss: 0.664268
| Global Round : 0 | Local Epoch : 1 | [500/10242 (5%)]	Loss: 0.676776
| Global Round : 0 | Local Epoch : 1 | [600/10242 (6%)]	Loss: 0.666937
| Global Round : 0 | Local Epoch : 1 | [700/10242 (7%)]	Loss: 0.493904
| Global Round : 0 | Local Epoch : 1 | [800/10242 (8%)]	Loss: 0.675814
| Global Round : 0 | Local Epoch : 1 | [900/10242 (9%)]	Loss: 0.797983
| Global Round : 0 | Local Epoch : 1 | [1000/10242 (10%)]	Loss: 0.448540
| Global Round : 0 | Local Epoch : 1 | [1100/10242 (11%)]	Loss: 0.824261
| Global Round : 0 | Local Epoch : 1 | [1200/10242 (12%)]	Loss: 0.894592
| Global Round : 0 | Local Epoch : 1 | [1300/10242 (13%)]	Loss: 0.464072
| Global Round : 0 | Local Epoch : 1 | [1400/10242 (14%)]	Loss: 0.454329
| Global Round : 0 | Local Epoch : 1 | [1500/10242 (15%)]	Loss: 0.857842
| Global Round : 0 | Local Epoch : 1 | [1600/10242 (16%)]	Loss: 0.577528
| Global Round : 0 | Local Epoch : 1 | [1700/10242 (17%)]	Loss: 0.464885
| Global Round : 0 | Local Epoch : 1 | [1800/10242 (18%)]	Loss: 0.574848
| Global Round : 0 | Local Epoch : 1 | [1900/10242 (19%)]	Loss: 0.468195
| Global Round : 0 | Local Epoch : 1 | [2000/10242 (20%)]	Loss: 0.804050
| Global Round : 0 | Local Epoch : 1 | [2100/10242 (20%)]	Loss: 0.557115
| Global Round : 0 | Local Epoch : 1 | [2200/10242 (21%)]	Loss: 0.523670
| Global Round : 0 | Local Epoch : 1 | [2300/10242 (22%)]	Loss: 0.705171
| Global Round : 0 | Local Epoch : 1 | [2400/10242 (23%)]	Loss: 0.489412
| Global Round : 0 | Local Epoch : 1 | [2500/10242 (24%)]	Loss: 0.713563
| Global Round : 0 | Local Epoch : 1 | [2600/10242 (25%)]	Loss: 0.489198
| Global Round : 0 | Local Epoch : 1 | [2700/10242 (26%)]	Loss: 0.533524
| Global Round : 0 | Local Epoch : 1 | [2800/10242 (27%)]	Loss: 0.518750
| Global Round : 0 | Local Epoch : 1 | [2900/10242 (28%)]	Loss: 0.754643
| Global Round : 0 | Local Epoch : 1 | [3000/10242 (29%)]	Loss: 0.442065
| Global Round : 0 | Local Epoch : 1 | [3100/10242 (30%)]	Loss: 0.536145
| Global Round : 0 | Local Epoch : 1 | [3200/10242 (31%)]	Loss: 0.446041
| Global Round : 0 | Local Epoch : 1 | [3300/10242 (32%)]	Loss: 0.514339
| Global Round : 0 | Local Epoch : 1 | [3400/10242 (33%)]	Loss: 0.377323
| Global Round : 0 | Local Epoch : 1 | [3500/10242 (34%)]	Loss: 0.456829
| Global Round : 0 | Local Epoch : 1 | [3600/10242 (35%)]	Loss: 0.591863
| Global Round : 0 | Local Epoch : 1 | [3700/10242 (36%)]	Loss: 0.810610
| Global Round : 0 | Local Epoch : 1 | [3800/10242 (37%)]	Loss: 0.646040
| Global Round : 0 | Local Epoch : 1 | [3900/10242 (38%)]	Loss: 0.583567
| Global Round : 0 | Local Epoch : 1 | [4000/10242 (39%)]	Loss: 0.324137
| Global Round : 0 | Local Epoch : 1 | [4100/10242 (40%)]	Loss: 0.383495
| Global Round : 0 | Local Epoch : 1 | [4200/10242 (41%)]	Loss: 0.440454
| Global Round : 0 | Local Epoch : 1 | [4300/10242 (42%)]	Loss: 0.567657
| Global Round : 0 | Local Epoch : 1 | [4400/10242 (43%)]	Loss: 0.608893
| Global Round : 0 | Local Epoch : 1 | [4500/10242 (44%)]	Loss: 0.662468
| Global Round : 0 | Local Epoch : 1 | [4600/10242 (45%)]	Loss: 0.426092
| Global Round : 0 | Local Epoch : 1 | [4700/10242 (46%)]	Loss: 0.436976
| Global Round : 0 | Local Epoch : 1 | [4800/10242 (47%)]	Loss: 0.712166
| Global Round : 0 | Local Epoch : 1 | [4900/10242 (48%)]	Loss: 0.499713
| Global Round : 0 | Local Epoch : 1 | [5000/10242 (49%)]	Loss: 0.565431
| Global Round : 0 | Local Epoch : 1 | [5100/10242 (50%)]	Loss: 0.570237
| Global Round : 0 | Local Epoch : 1 | [5200/10242 (51%)]	Loss: 0.570240
| Global Round : 0 | Local Epoch : 1 | [5300/10242 (52%)]	Loss: 0.679024
| Global Round : 0 | Local Epoch : 1 | [5400/10242 (53%)]	Loss: 0.690766
| Global Round : 0 | Local Epoch : 1 | [5500/10242 (54%)]	Loss: 0.676012
| Global Round : 0 | Local Epoch : 1 | [5600/10242 (55%)]	Loss: 0.476428
| Global Round : 0 | Local Epoch : 1 | [5700/10242 (56%)]	Loss: 0.895656
| Global Round : 0 | Local Epoch : 1 | [5800/10242 (57%)]	Loss: 0.621444
| Global Round : 0 | Local Epoch : 1 | [5900/10242 (58%)]	Loss: 0.659679
| Global Round : 0 | Local Epoch : 1 | [6000/10242 (59%)]	Loss: 0.507502
| Global Round : 0 | Local Epoch : 1 | [6100/10242 (60%)]	Loss: 0.509988
| Global Round : 0 | Local Epoch : 1 | [6200/10242 (60%)]	Loss: 0.512717
| Global Round : 0 | Local Epoch : 1 | [6300/10242 (61%)]	Loss: 0.591246
| Global Round : 0 | Local Epoch : 1 | [6400/10242 (62%)]	Loss: 0.836777
| Global Round : 0 | Local Epoch : 1 | [6500/10242 (63%)]	Loss: 0.357149
| Global Round : 0 | Local Epoch : 1 | [6600/10242 (64%)]	Loss: 0.367920
| Global Round : 0 | Local Epoch : 1 | [6700/10242 (65%)]	Loss: 0.582042
| Global Round : 0 | Local Epoch : 1 | [6800/10242 (66%)]	Loss: 0.584793
| Global Round : 0 | Local Epoch : 1 | [6900/10242 (67%)]	Loss: 0.477204
| Global Round : 0 | Local Epoch : 1 | [7000/10242 (68%)]	Loss: 0.406345
| Global Round : 0 | Local Epoch : 1 | [7100/10242 (69%)]	Loss: 0.860311
| Global Round : 0 | Local Epoch : 1 | [7200/10242 (70%)]	Loss: 0.296359
| Global Round : 0 | Local Epoch : 1 | [7300/10242 (71%)]	Loss: 0.481503
| Global Round : 0 | Local Epoch : 1 | [7400/10242 (72%)]	Loss: 0.630311
| Global Round : 0 | Local Epoch : 1 | [7500/10242 (73%)]	Loss: 0.569057
| Global Round : 0 | Local Epoch : 1 | [7600/10242 (74%)]	Loss: 0.550633
| Global Round : 0 | Local Epoch : 1 | [7700/10242 (75%)]	Loss: 0.634103
| Global Round : 0 | Local Epoch : 1 | [7800/10242 (76%)]	Loss: 0.572237
| Global Round : 0 | Local Epoch : 1 | [7900/10242 (77%)]	Loss: 0.504012
| Global Round : 0 | Local Epoch : 1 | [8000/10242 (78%)]	Loss: 0.762932
| Global Round : 0 | Local Epoch : 1 | [8100/10242 (79%)]	Loss: 0.788912
| Global Round : 0 | Local Epoch : 1 | [8200/10242 (80%)]	Loss: 0.491564
| Global Round : 0 | Local Epoch : 1 | [8300/10242 (81%)]	Loss: 0.752701
| Global Round : 0 | Local Epoch : 1 | [8400/10242 (82%)]	Loss: 0.402242
| Global Round : 0 | Local Epoch : 1 | [8500/10242 (83%)]	Loss: 0.463142
| Global Round : 0 | Local Epoch : 1 | [8600/10242 (84%)]	Loss: 0.671296
| Global Round : 0 | Local Epoch : 1 | [8700/10242 (85%)]	Loss: 0.121359
| Global Round : 0 | Local Epoch : 1 | [8800/10242 (86%)]	Loss: 0.457861
| Global Round : 0 | Local Epoch : 1 | [8900/10242 (87%)]	Loss: 0.600458
| Global Round : 0 | Local Epoch : 1 | [9000/10242 (88%)]	Loss: 0.534528
| Global Round : 0 | Local Epoch : 1 | [9100/10242 (89%)]	Loss: 0.593836
| Global Round : 0 | Local Epoch : 1 | [9200/10242 (90%)]	Loss: 0.716566
| Global Round : 0 | Local Epoch : 1 | [9300/10242 (91%)]	Loss: 0.522841
| Global Round : 0 | Local Epoch : 1 | [9400/10242 (92%)]	Loss: 0.275898
| Global Round : 0 | Local Epoch : 1 | [9500/10242 (93%)]	Loss: 0.596925
| Global Round : 0 | Local Epoch : 1 | [9600/10242 (94%)]	Loss: 0.662506
| Global Round : 0 | Local Epoch : 1 | [9700/10242 (95%)]	Loss: 0.438630
| Global Round : 0 | Local Epoch : 1 | [9800/10242 (96%)]	Loss: 0.659644
| Global Round : 0 | Local Epoch : 1 | [9900/10242 (97%)]	Loss: 0.498815
| Global Round : 0 | Local Epoch : 1 | [10000/10242 (98%)]	Loss: 0.500617
| Global Round : 0 | Local Epoch : 1 | [10100/10242 (99%)]	Loss: 0.375243
| Global Round : 0 | Local Epoch : 1 | [10200/10242 (100%)]	Loss: 0.385352
| Global Round : 0 | Local Epoch : 2 | [0/10242 (0%)]	Loss: 0.369269
| Global Round : 0 | Local Epoch : 2 | [100/10242 (1%)]	Loss: 0.440356
| Global Round : 0 | Local Epoch : 2 | [200/10242 (2%)]	Loss: 0.425818
| Global Round : 0 | Local Epoch : 2 | [300/10242 (3%)]	Loss: 0.996147
| Global Round : 0 | Local Epoch : 2 | [400/10242 (4%)]	Loss: 0.555841
| Global Round : 0 | Local Epoch : 2 | [500/10242 (5%)]	Loss: 0.441119
| Global Round : 0 | Local Epoch : 2 | [600/10242 (6%)]	Loss: 0.424686
| Global Round : 0 | Local Epoch : 2 | [700/10242 (7%)]	Loss: 0.466998
| Global Round : 0 | Local Epoch : 2 | [800/10242 (8%)]	Loss: 0.473290
| Global Round : 0 | Local Epoch : 2 | [900/10242 (9%)]	Loss: 0.604579
| Global Round : 0 | Local Epoch : 2 | [1000/10242 (10%)]	Loss: 0.815258
| Global Round : 0 | Local Epoch : 2 | [1100/10242 (11%)]	Loss: 0.522819
| Global Round : 0 | Local Epoch : 2 | [1200/10242 (12%)]	Loss: 0.388455
| Global Round : 0 | Local Epoch : 2 | [1300/10242 (13%)]	Loss: 0.543553
| Global Round : 0 | Local Epoch : 2 | [1400/10242 (14%)]	Loss: 0.504243
| Global Round : 0 | Local Epoch : 2 | [1500/10242 (15%)]	Loss: 0.552288
| Global Round : 0 | Local Epoch : 2 | [1600/10242 (16%)]	Loss: 0.466452
| Global Round : 0 | Local Epoch : 2 | [1700/10242 (17%)]	Loss: 0.725705
| Global Round : 0 | Local Epoch : 2 | [1800/10242 (18%)]	Loss: 0.696124
| Global Round : 0 | Local Epoch : 2 | [1900/10242 (19%)]	Loss: 0.566879
| Global Round : 0 | Local Epoch : 2 | [2000/10242 (20%)]	Loss: 0.571358
| Global Round : 0 | Local Epoch : 2 | [2100/10242 (20%)]	Loss: 0.325038
| Global Round : 0 | Local Epoch : 2 | [2200/10242 (21%)]	Loss: 0.434974
| Global Round : 0 | Local Epoch : 2 | [2300/10242 (22%)]	Loss: 0.410478
| Global Round : 0 | Local Epoch : 2 | [2400/10242 (23%)]	Loss: 0.314248
| Global Round : 0 | Local Epoch : 2 | [2500/10242 (24%)]	Loss: 1.017938
| Global Round : 0 | Local Epoch : 2 | [2600/10242 (25%)]	Loss: 0.482744
| Global Round : 0 | Local Epoch : 2 | [2700/10242 (26%)]	Loss: 0.334101
| Global Round : 0 | Local Epoch : 2 | [2800/10242 (27%)]	Loss: 0.417848
| Global Round : 0 | Local Epoch : 2 | [2900/10242 (28%)]	Loss: 0.528347
| Global Round : 0 | Local Epoch : 2 | [3000/10242 (29%)]	Loss: 0.502955
| Global Round : 0 | Local Epoch : 2 | [3100/10242 (30%)]	Loss: 0.344351
| Global Round : 0 | Local Epoch : 2 | [3200/10242 (31%)]	Loss: 0.223522
| Global Round : 0 | Local Epoch : 2 | [3300/10242 (32%)]	Loss: 0.535024
| Global Round : 0 | Local Epoch : 2 | [3400/10242 (33%)]	Loss: 0.505324
| Global Round : 0 | Local Epoch : 2 | [3500/10242 (34%)]	Loss: 0.352842
| Global Round : 0 | Local Epoch : 2 | [3600/10242 (35%)]	Loss: 0.500973
| Global Round : 0 | Local Epoch : 2 | [3700/10242 (36%)]	Loss: 0.406258
| Global Round : 0 | Local Epoch : 2 | [3800/10242 (37%)]	Loss: 0.774380
| Global Round : 0 | Local Epoch : 2 | [3900/10242 (38%)]	Loss: 0.383376
| Global Round : 0 | Local Epoch : 2 | [4000/10242 (39%)]	Loss: 0.560326
| Global Round : 0 | Local Epoch : 2 | [4100/10242 (40%)]	Loss: 0.581216
| Global Round : 0 | Local Epoch : 2 | [4200/10242 (41%)]	Loss: 0.416057
| Global Round : 0 | Local Epoch : 2 | [4300/10242 (42%)]	Loss: 0.313254
| Global Round : 0 | Local Epoch : 2 | [4400/10242 (43%)]	Loss: 0.621911
| Global Round : 0 | Local Epoch : 2 | [4500/10242 (44%)]	Loss: 0.502638
| Global Round : 0 | Local Epoch : 2 | [4600/10242 (45%)]	Loss: 0.378470
| Global Round : 0 | Local Epoch : 2 | [4700/10242 (46%)]	Loss: 0.461872
| Global Round : 0 | Local Epoch : 2 | [4800/10242 (47%)]	Loss: 0.487916
| Global Round : 0 | Local Epoch : 2 | [4900/10242 (48%)]	Loss: 0.372385
| Global Round : 0 | Local Epoch : 2 | [5000/10242 (49%)]	Loss: 0.469460
| Global Round : 0 | Local Epoch : 2 | [5100/10242 (50%)]	Loss: 0.448979
| Global Round : 0 | Local Epoch : 2 | [5200/10242 (51%)]	Loss: 0.430635
| Global Round : 0 | Local Epoch : 2 | [5300/10242 (52%)]	Loss: 0.307533
| Global Round : 0 | Local Epoch : 2 | [5400/10242 (53%)]	Loss: 0.333416
| Global Round : 0 | Local Epoch : 2 | [5500/10242 (54%)]	Loss: 0.172689
| Global Round : 0 | Local Epoch : 2 | [5600/10242 (55%)]	Loss: 0.263340
| Global Round : 0 | Local Epoch : 2 | [5700/10242 (56%)]	Loss: 0.456784
| Global Round : 0 | Local Epoch : 2 | [5800/10242 (57%)]	Loss: 1.144208
| Global Round : 0 | Local Epoch : 2 | [5900/10242 (58%)]	Loss: 0.572095
| Global Round : 0 | Local Epoch : 2 | [6000/10242 (59%)]	Loss: 0.420821
| Global Round : 0 | Local Epoch : 2 | [6100/10242 (60%)]	Loss: 0.278115
| Global Round : 0 | Local Epoch : 2 | [6200/10242 (60%)]	Loss: 0.299832
| Global Round : 0 | Local Epoch : 2 | [6300/10242 (61%)]	Loss: 0.411600
| Global Round : 0 | Local Epoch : 2 | [6400/10242 (62%)]	Loss: 0.356733
| Global Round : 0 | Local Epoch : 2 | [6500/10242 (63%)]	Loss: 0.362910
| Global Round : 0 | Local Epoch : 2 | [6600/10242 (64%)]	Loss: 0.463906
| Global Round : 0 | Local Epoch : 2 | [6700/10242 (65%)]	Loss: 0.801400
| Global Round : 0 | Local Epoch : 2 | [6800/10242 (66%)]	Loss: 0.497530
| Global Round : 0 | Local Epoch : 2 | [6900/10242 (67%)]	Loss: 0.665297
| Global Round : 0 | Local Epoch : 2 | [7000/10242 (68%)]	Loss: 0.485531
| Global Round : 0 | Local Epoch : 2 | [7100/10242 (69%)]	Loss: 0.382784
| Global Round : 0 | Local Epoch : 2 | [7200/10242 (70%)]	Loss: 0.516791
| Global Round : 0 | Local Epoch : 2 | [7300/10242 (71%)]	Loss: 0.396156
| Global Round : 0 | Local Epoch : 2 | [7400/10242 (72%)]	Loss: 0.784975
| Global Round : 0 | Local Epoch : 2 | [7500/10242 (73%)]	Loss: 0.456396
| Global Round : 0 | Local Epoch : 2 | [7600/10242 (74%)]	Loss: 0.444888
| Global Round : 0 | Local Epoch : 2 | [7700/10242 (75%)]	Loss: 0.432140
| Global Round : 0 | Local Epoch : 2 | [7800/10242 (76%)]	Loss: 0.555279
| Global Round : 0 | Local Epoch : 2 | [7900/10242 (77%)]	Loss: 0.568388
| Global Round : 0 | Local Epoch : 2 | [8000/10242 (78%)]	Loss: 1.304770
| Global Round : 0 | Local Epoch : 2 | [8100/10242 (79%)]	Loss: 0.405483
| Global Round : 0 | Local Epoch : 2 | [8200/10242 (80%)]	Loss: 0.359311
| Global Round : 0 | Local Epoch : 2 | [8300/10242 (81%)]	Loss: 0.505114
| Global Round : 0 | Local Epoch : 2 | [8400/10242 (82%)]	Loss: 0.353673
| Global Round : 0 | Local Epoch : 2 | [8500/10242 (83%)]	Loss: 0.483434
| Global Round : 0 | Local Epoch : 2 | [8600/10242 (84%)]	Loss: 0.487769
| Global Round : 0 | Local Epoch : 2 | [8700/10242 (85%)]	Loss: 0.617971
| Global Round : 0 | Local Epoch : 2 | [8800/10242 (86%)]	Loss: 0.393699
| Global Round : 0 | Local Epoch : 2 | [8900/10242 (87%)]	Loss: 0.405252
| Global Round : 0 | Local Epoch : 2 | [9000/10242 (88%)]	Loss: 0.293708
| Global Round : 0 | Local Epoch : 2 | [9100/10242 (89%)]	Loss: 0.405195
| Global Round : 0 | Local Epoch : 2 | [9200/10242 (90%)]	Loss: 0.706475
| Global Round : 0 | Local Epoch : 2 | [9300/10242 (91%)]	Loss: 0.459637
| Global Round : 0 | Local Epoch : 2 | [9400/10242 (92%)]	Loss: 0.203209
| Global Round : 0 | Local Epoch : 2 | [9500/10242 (93%)]	Loss: 0.740881
| Global Round : 0 | Local Epoch : 2 | [9600/10242 (94%)]	Loss: 0.761493
| Global Round : 0 | Local Epoch : 2 | [9700/10242 (95%)]	Loss: 0.568469
| Global Round : 0 | Local Epoch : 2 | [9800/10242 (96%)]	Loss: 0.387166
| Global Round : 0 | Local Epoch : 2 | [9900/10242 (97%)]	Loss: 0.322989
| Global Round : 0 | Local Epoch : 2 | [10000/10242 (98%)]	Loss: 0.339111
| Global Round : 0 | Local Epoch : 2 | [10100/10242 (99%)]	Loss: 0.435246
| Global Round : 0 | Local Epoch : 2 | [10200/10242 (100%)]	Loss: 0.221645
| Global Round : 0 | Local Epoch : 3 | [0/10242 (0%)]	Loss: 0.497699
| Global Round : 0 | Local Epoch : 3 | [100/10242 (1%)]	Loss: 0.770973
| Global Round : 0 | Local Epoch : 3 | [200/10242 (2%)]	Loss: 0.538339
| Global Round : 0 | Local Epoch : 3 | [300/10242 (3%)]	Loss: 0.327816
| Global Round : 0 | Local Epoch : 3 | [400/10242 (4%)]	Loss: 0.398355
| Global Round : 0 | Local Epoch : 3 | [500/10242 (5%)]	Loss: 0.644986
| Global Round : 0 | Local Epoch : 3 | [600/10242 (6%)]	Loss: 0.565546
| Global Round : 0 | Local Epoch : 3 | [700/10242 (7%)]	Loss: 0.690353
| Global Round : 0 | Local Epoch : 3 | [800/10242 (8%)]	Loss: 0.492243
| Global Round : 0 | Local Epoch : 3 | [900/10242 (9%)]	Loss: 0.505624
| Global Round : 0 | Local Epoch : 3 | [1000/10242 (10%)]	Loss: 0.261721
| Global Round : 0 | Local Epoch : 3 | [1100/10242 (11%)]	Loss: 0.362930
| Global Round : 0 | Local Epoch : 3 | [1200/10242 (12%)]	Loss: 0.598601
| Global Round : 0 | Local Epoch : 3 | [1300/10242 (13%)]	Loss: 0.232738
| Global Round : 0 | Local Epoch : 3 | [1400/10242 (14%)]	Loss: 0.344128
| Global Round : 0 | Local Epoch : 3 | [1500/10242 (15%)]	Loss: 0.263434
| Global Round : 0 | Local Epoch : 3 | [1600/10242 (16%)]	Loss: 0.388324
| Global Round : 0 | Local Epoch : 3 | [1700/10242 (17%)]	Loss: 0.293263
| Global Round : 0 | Local Epoch : 3 | [1800/10242 (18%)]	Loss: 0.260715
| Global Round : 0 | Local Epoch : 3 | [1900/10242 (19%)]	Loss: 0.269267
| Global Round : 0 | Local Epoch : 3 | [2000/10242 (20%)]	Loss: 0.786501
| Global Round : 0 | Local Epoch : 3 | [2100/10242 (20%)]	Loss: 0.415857
| Global Round : 0 | Local Epoch : 3 | [2200/10242 (21%)]	Loss: 0.393256
| Global Round : 0 | Local Epoch : 3 | [2300/10242 (22%)]	Loss: 0.418199
| Global Round : 0 | Local Epoch : 3 | [2400/10242 (23%)]	Loss: 1.019248
| Global Round : 0 | Local Epoch : 3 | [2500/10242 (24%)]	Loss: 0.285560
| Global Round : 0 | Local Epoch : 3 | [2600/10242 (25%)]	Loss: 0.286076
| Global Round : 0 | Local Epoch : 3 | [2700/10242 (26%)]	Loss: 0.592317
| Global Round : 0 | Local Epoch : 3 | [2800/10242 (27%)]	Loss: 0.292731
| Global Round : 0 | Local Epoch : 3 | [2900/10242 (28%)]	Loss: 0.239743
| Global Round : 0 | Local Epoch : 3 | [3000/10242 (29%)]	Loss: 0.556766
| Global Round : 0 | Local Epoch : 3 | [3100/10242 (30%)]	Loss: 0.448129
| Global Round : 0 | Local Epoch : 3 | [3200/10242 (31%)]	Loss: 0.648185
| Global Round : 0 | Local Epoch : 3 | [3300/10242 (32%)]	Loss: 0.709750
| Global Round : 0 | Local Epoch : 3 | [3400/10242 (33%)]	Loss: 0.515943
| Global Round : 0 | Local Epoch : 3 | [3500/10242 (34%)]	Loss: 0.369610
| Global Round : 0 | Local Epoch : 3 | [3600/10242 (35%)]	Loss: 0.491914
| Global Round : 0 | Local Epoch : 3 | [3700/10242 (36%)]	Loss: 0.456711
| Global Round : 0 | Local Epoch : 3 | [3800/10242 (37%)]	Loss: 0.427679
| Global Round : 0 | Local Epoch : 3 | [3900/10242 (38%)]	Loss: 0.857882
| Global Round : 0 | Local Epoch : 3 | [4000/10242 (39%)]	Loss: 0.193769
| Global Round : 0 | Local Epoch : 3 | [4100/10242 (40%)]	Loss: 0.537963
| Global Round : 0 | Local Epoch : 3 | [4200/10242 (41%)]	Loss: 0.306459
| Global Round : 0 | Local Epoch : 3 | [4300/10242 (42%)]	Loss: 0.190543
| Global Round : 0 | Local Epoch : 3 | [4400/10242 (43%)]	Loss: 0.357979
| Global Round : 0 | Local Epoch : 3 | [4500/10242 (44%)]	Loss: 0.263073
| Global Round : 0 | Local Epoch : 3 | [4600/10242 (45%)]	Loss: 0.424065
| Global Round : 0 | Local Epoch : 3 | [4700/10242 (46%)]	Loss: 0.350721
| Global Round : 0 | Local Epoch : 3 | [4800/10242 (47%)]	Loss: 0.266332
| Global Round : 0 | Local Epoch : 3 | [4900/10242 (48%)]	Loss: 0.846101
| Global Round : 0 | Local Epoch : 3 | [5000/10242 (49%)]	Loss: 0.332863
| Global Round : 0 | Local Epoch : 3 | [5100/10242 (50%)]	Loss: 0.766870
| Global Round : 0 | Local Epoch : 3 | [5200/10242 (51%)]	Loss: 0.358934
| Global Round : 0 | Local Epoch : 3 | [5300/10242 (52%)]	Loss: 0.360455
| Global Round : 0 | Local Epoch : 3 | [5400/10242 (53%)]	Loss: 0.231957
| Global Round : 0 | Local Epoch : 3 | [5500/10242 (54%)]	Loss: 0.444082
| Global Round : 0 | Local Epoch : 3 | [5600/10242 (55%)]	Loss: 0.338383
| Global Round : 0 | Local Epoch : 3 | [5700/10242 (56%)]	Loss: 0.694182
| Global Round : 0 | Local Epoch : 3 | [5800/10242 (57%)]	Loss: 0.620642
| Global Round : 0 | Local Epoch : 3 | [5900/10242 (58%)]	Loss: 0.636049
| Global Round : 0 | Local Epoch : 3 | [6000/10242 (59%)]	Loss: 0.380620
| Global Round : 0 | Local Epoch : 3 | [6100/10242 (60%)]	Loss: 0.312492
| Global Round : 0 | Local Epoch : 3 | [6200/10242 (60%)]	Loss: 0.927040
| Global Round : 0 | Local Epoch : 3 | [6300/10242 (61%)]	Loss: 0.401997
| Global Round : 0 | Local Epoch : 3 | [6400/10242 (62%)]	Loss: 0.440802
| Global Round : 0 | Local Epoch : 3 | [6500/10242 (63%)]	Loss: 0.372122
| Global Round : 0 | Local Epoch : 3 | [6600/10242 (64%)]	Loss: 0.246855
| Global Round : 0 | Local Epoch : 3 | [6700/10242 (65%)]	Loss: 0.650490
| Global Round : 0 | Local Epoch : 3 | [6800/10242 (66%)]	Loss: 0.296381
| Global Round : 0 | Local Epoch : 3 | [6900/10242 (67%)]	Loss: 0.148430
| Global Round : 0 | Local Epoch : 3 | [7000/10242 (68%)]	Loss: 0.247740
| Global Round : 0 | Local Epoch : 3 | [7100/10242 (69%)]	Loss: 0.325163
| Global Round : 0 | Local Epoch : 3 | [7200/10242 (70%)]	Loss: 0.390248
| Global Round : 0 | Local Epoch : 3 | [7300/10242 (71%)]	Loss: 0.632380
| Global Round : 0 | Local Epoch : 3 | [7400/10242 (72%)]	Loss: 0.508812
| Global Round : 0 | Local Epoch : 3 | [7500/10242 (73%)]	Loss: 0.194017
| Global Round : 0 | Local Epoch : 3 | [7600/10242 (74%)]	Loss: 0.307754
| Global Round : 0 | Local Epoch : 3 | [7700/10242 (75%)]	Loss: 0.406918
| Global Round : 0 | Local Epoch : 3 | [7800/10242 (76%)]	Loss: 0.481355
| Global Round : 0 | Local Epoch : 3 | [7900/10242 (77%)]	Loss: 0.434891
| Global Round : 0 | Local Epoch : 3 | [8000/10242 (78%)]	Loss: 0.575621
| Global Round : 0 | Local Epoch : 3 | [8100/10242 (79%)]	Loss: 0.307035
| Global Round : 0 | Local Epoch : 3 | [8200/10242 (80%)]	Loss: 0.425270
| Global Round : 0 | Local Epoch : 3 | [8300/10242 (81%)]	Loss: 0.839146
| Global Round : 0 | Local Epoch : 3 | [8400/10242 (82%)]	Loss: 0.581811
| Global Round : 0 | Local Epoch : 3 | [8500/10242 (83%)]	Loss: 0.382066
| Global Round : 0 | Local Epoch : 3 | [8600/10242 (84%)]	Loss: 0.488800
| Global Round : 0 | Local Epoch : 3 | [8700/10242 (85%)]	Loss: 0.286334
| Global Round : 0 | Local Epoch : 3 | [8800/10242 (86%)]	Loss: 0.328158
| Global Round : 0 | Local Epoch : 3 | [8900/10242 (87%)]	Loss: 0.789262
| Global Round : 0 | Local Epoch : 3 | [9000/10242 (88%)]	Loss: 0.291553
| Global Round : 0 | Local Epoch : 3 | [9100/10242 (89%)]	Loss: 0.385560
| Global Round : 0 | Local Epoch : 3 | [9200/10242 (90%)]	Loss: 0.401776
| Global Round : 0 | Local Epoch : 3 | [9300/10242 (91%)]	Loss: 0.403406
| Global Round : 0 | Local Epoch : 3 | [9400/10242 (92%)]	Loss: 0.431044
| Global Round : 0 | Local Epoch : 3 | [9500/10242 (93%)]	Loss: 0.854851
| Global Round : 0 | Local Epoch : 3 | [9600/10242 (94%)]	Loss: 0.297703
| Global Round : 0 | Local Epoch : 3 | [9700/10242 (95%)]	Loss: 0.362359
| Global Round : 0 | Local Epoch : 3 | [9800/10242 (96%)]	Loss: 0.165878
| Global Round : 0 | Local Epoch : 3 | [9900/10242 (97%)]	Loss: 0.257964
| Global Round : 0 | Local Epoch : 3 | [10000/10242 (98%)]	Loss: 0.360062
| Global Round : 0 | Local Epoch : 3 | [10100/10242 (99%)]	Loss: 0.297585
| Global Round : 0 | Local Epoch : 3 | [10200/10242 (100%)]	Loss: 0.266791
| Global Round : 0 | Local Epoch : 4 | [0/10242 (0%)]	Loss: 0.352422
| Global Round : 0 | Local Epoch : 4 | [100/10242 (1%)]	Loss: 0.542367
| Global Round : 0 | Local Epoch : 4 | [200/10242 (2%)]	Loss: 0.085252
| Global Round : 0 | Local Epoch : 4 | [300/10242 (3%)]	Loss: 0.118607
| Global Round : 0 | Local Epoch : 4 | [400/10242 (4%)]	Loss: 0.215481
| Global Round : 0 | Local Epoch : 4 | [500/10242 (5%)]	Loss: 0.310257
| Global Round : 0 | Local Epoch : 4 | [600/10242 (6%)]	Loss: 0.388830
| Global Round : 0 | Local Epoch : 4 | [700/10242 (7%)]	Loss: 0.278964
| Global Round : 0 | Local Epoch : 4 | [800/10242 (8%)]	Loss: 0.448185
| Global Round : 0 | Local Epoch : 4 | [900/10242 (9%)]	Loss: 0.520411
| Global Round : 0 | Local Epoch : 4 | [1000/10242 (10%)]	Loss: 0.271054
| Global Round : 0 | Local Epoch : 4 | [1100/10242 (11%)]	Loss: 0.260116
| Global Round : 0 | Local Epoch : 4 | [1200/10242 (12%)]	Loss: 0.272101
| Global Round : 0 | Local Epoch : 4 | [1300/10242 (13%)]	Loss: 0.589602
| Global Round : 0 | Local Epoch : 4 | [1400/10242 (14%)]	Loss: 0.302003
| Global Round : 0 | Local Epoch : 4 | [1500/10242 (15%)]	Loss: 0.321168
| Global Round : 0 | Local Epoch : 4 | [1600/10242 (16%)]	Loss: 0.507949
| Global Round : 0 | Local Epoch : 4 | [1700/10242 (17%)]	Loss: 0.297913
| Global Round : 0 | Local Epoch : 4 | [1800/10242 (18%)]	Loss: 0.334348
| Global Round : 0 | Local Epoch : 4 | [1900/10242 (19%)]	Loss: 0.738355
| Global Round : 0 | Local Epoch : 4 | [2000/10242 (20%)]	Loss: 0.352756
| Global Round : 0 | Local Epoch : 4 | [2100/10242 (20%)]	Loss: 0.366899
| Global Round : 0 | Local Epoch : 4 | [2200/10242 (21%)]	Loss: 0.338541
| Global Round : 0 | Local Epoch : 4 | [2300/10242 (22%)]	Loss: 0.315416
| Global Round : 0 | Local Epoch : 4 | [2400/10242 (23%)]	Loss: 0.236443
| Global Round : 0 | Local Epoch : 4 | [2500/10242 (24%)]	Loss: 0.329825
| Global Round : 0 | Local Epoch : 4 | [2600/10242 (25%)]	Loss: 0.266207
| Global Round : 0 | Local Epoch : 4 | [2700/10242 (26%)]	Loss: 0.702132
| Global Round : 0 | Local Epoch : 4 | [2800/10242 (27%)]	Loss: 0.440885
| Global Round : 0 | Local Epoch : 4 | [2900/10242 (28%)]	Loss: 0.157793
| Global Round : 0 | Local Epoch : 4 | [3000/10242 (29%)]	Loss: 0.807605
| Global Round : 0 | Local Epoch : 4 | [3100/10242 (30%)]	Loss: 0.208821
| Global Round : 0 | Local Epoch : 4 | [3200/10242 (31%)]	Loss: 0.277110
| Global Round : 0 | Local Epoch : 4 | [3300/10242 (32%)]	Loss: 0.236557
| Global Round : 0 | Local Epoch : 4 | [3400/10242 (33%)]	Loss: 0.318954
| Global Round : 0 | Local Epoch : 4 | [3500/10242 (34%)]	Loss: 0.346202
| Global Round : 0 | Local Epoch : 4 | [3600/10242 (35%)]	Loss: 0.142475
| Global Round : 0 | Local Epoch : 4 | [3700/10242 (36%)]	Loss: 0.203027
| Global Round : 0 | Local Epoch : 4 | [3800/10242 (37%)]	Loss: 0.504804
| Global Round : 0 | Local Epoch : 4 | [3900/10242 (38%)]	Loss: 0.279975
| Global Round : 0 | Local Epoch : 4 | [4000/10242 (39%)]	Loss: 0.841947
| Global Round : 0 | Local Epoch : 4 | [4100/10242 (40%)]	Loss: 0.149058
| Global Round : 0 | Local Epoch : 4 | [4200/10242 (41%)]	Loss: 0.433726
| Global Round : 0 | Local Epoch : 4 | [4300/10242 (42%)]	Loss: 0.157838
| Global Round : 0 | Local Epoch : 4 | [4400/10242 (43%)]	Loss: 0.393123
| Global Round : 0 | Local Epoch : 4 | [4500/10242 (44%)]	Loss: 0.107008
| Global Round : 0 | Local Epoch : 4 | [4600/10242 (45%)]	Loss: 0.356429
| Global Round : 0 | Local Epoch : 4 | [4700/10242 (46%)]	Loss: 0.597305
| Global Round : 0 | Local Epoch : 4 | [4800/10242 (47%)]	Loss: 0.464833
| Global Round : 0 | Local Epoch : 4 | [4900/10242 (48%)]	Loss: 0.219200
| Global Round : 0 | Local Epoch : 4 | [5000/10242 (49%)]	Loss: 0.154863
| Global Round : 0 | Local Epoch : 4 | [5100/10242 (50%)]	Loss: 0.458508
| Global Round : 0 | Local Epoch : 4 | [5200/10242 (51%)]	Loss: 0.159131
| Global Round : 0 | Local Epoch : 4 | [5300/10242 (52%)]	Loss: 0.377535
| Global Round : 0 | Local Epoch : 4 | [5400/10242 (53%)]	Loss: 0.308072
| Global Round : 0 | Local Epoch : 4 | [5500/10242 (54%)]	Loss: 0.155319
| Global Round : 0 | Local Epoch : 4 | [5600/10242 (55%)]	Loss: 0.513509
| Global Round : 0 | Local Epoch : 4 | [5700/10242 (56%)]	Loss: 0.378104
| Global Round : 0 | Local Epoch : 4 | [5800/10242 (57%)]	Loss: 0.283652
| Global Round : 0 | Local Epoch : 4 | [5900/10242 (58%)]	Loss: 0.265038
| Global Round : 0 | Local Epoch : 4 | [6000/10242 (59%)]	Loss: 0.492601
| Global Round : 0 | Local Epoch : 4 | [6100/10242 (60%)]	Loss: 0.214295
| Global Round : 0 | Local Epoch : 4 | [6200/10242 (60%)]	Loss: 0.325146
| Global Round : 0 | Local Epoch : 4 | [6300/10242 (61%)]	Loss: 0.591658
| Global Round : 0 | Local Epoch : 4 | [6400/10242 (62%)]	Loss: 0.329171
| Global Round : 0 | Local Epoch : 4 | [6500/10242 (63%)]	Loss: 0.348108
| Global Round : 0 | Local Epoch : 4 | [6600/10242 (64%)]	Loss: 0.159711
| Global Round : 0 | Local Epoch : 4 | [6700/10242 (65%)]	Loss: 0.227267
| Global Round : 0 | Local Epoch : 4 | [6800/10242 (66%)]	Loss: 0.415262
| Global Round : 0 | Local Epoch : 4 | [6900/10242 (67%)]	Loss: 0.816119
| Global Round : 0 | Local Epoch : 4 | [7000/10242 (68%)]	Loss: 0.537658
| Global Round : 0 | Local Epoch : 4 | [7100/10242 (69%)]	Loss: 0.687496
| Global Round : 0 | Local Epoch : 4 | [7200/10242 (70%)]	Loss: 0.708385
| Global Round : 0 | Local Epoch : 4 | [7300/10242 (71%)]	Loss: 0.354453
| Global Round : 0 | Local Epoch : 4 | [7400/10242 (72%)]	Loss: 0.335471
| Global Round : 0 | Local Epoch : 4 | [7500/10242 (73%)]	Loss: 0.603809
| Global Round : 0 | Local Epoch : 4 | [7600/10242 (74%)]	Loss: 0.329770
| Global Round : 0 | Local Epoch : 4 | [7700/10242 (75%)]	Loss: 0.292782
| Global Round : 0 | Local Epoch : 4 | [7800/10242 (76%)]	Loss: 0.220742
| Global Round : 0 | Local Epoch : 4 | [7900/10242 (77%)]	Loss: 0.614408
| Global Round : 0 | Local Epoch : 4 | [8000/10242 (78%)]	Loss: 0.641078
| Global Round : 0 | Local Epoch : 4 | [8100/10242 (79%)]	Loss: 0.178128
| Global Round : 0 | Local Epoch : 4 | [8200/10242 (80%)]	Loss: 0.140878
| Global Round : 0 | Local Epoch : 4 | [8300/10242 (81%)]	Loss: 0.367774
| Global Round : 0 | Local Epoch : 4 | [8400/10242 (82%)]	Loss: 0.231646
| Global Round : 0 | Local Epoch : 4 | [8500/10242 (83%)]	Loss: 0.423527
| Global Round : 0 | Local Epoch : 4 | [8600/10242 (84%)]	Loss: 0.464517
| Global Round : 0 | Local Epoch : 4 | [8700/10242 (85%)]	Loss: 0.511793
| Global Round : 0 | Local Epoch : 4 | [8800/10242 (86%)]	Loss: 0.291608
| Global Round : 0 | Local Epoch : 4 | [8900/10242 (87%)]	Loss: 0.593333
| Global Round : 0 | Local Epoch : 4 | [9000/10242 (88%)]	Loss: 0.528483
| Global Round : 0 | Local Epoch : 4 | [9100/10242 (89%)]	Loss: 0.169830
| Global Round : 0 | Local Epoch : 4 | [9200/10242 (90%)]	Loss: 0.243305
| Global Round : 0 | Local Epoch : 4 | [9300/10242 (91%)]	Loss: 0.211524
| Global Round : 0 | Local Epoch : 4 | [9400/10242 (92%)]	Loss: 0.734050
| Global Round : 0 | Local Epoch : 4 | [9500/10242 (93%)]	Loss: 0.317306
| Global Round : 0 | Local Epoch : 4 | [9600/10242 (94%)]	Loss: 0.834653
| Global Round : 0 | Local Epoch : 4 | [9700/10242 (95%)]	Loss: 0.207564
| Global Round : 0 | Local Epoch : 4 | [9800/10242 (96%)]	Loss: 1.092337
| Global Round : 0 | Local Epoch : 4 | [9900/10242 (97%)]	Loss: 0.196795
| Global Round : 0 | Local Epoch : 4 | [10000/10242 (98%)]	Loss: 0.317521
| Global Round : 0 | Local Epoch : 4 | [10100/10242 (99%)]	Loss: 0.427310
| Global Round : 0 | Local Epoch : 4 | [10200/10242 (100%)]	Loss: 0.193987
----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.83      0.89        71
         DME       0.82      0.95      0.88        57

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.82      0.86        61
         DME       0.85      0.93      0.89        67

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.83      0.86        70
         DME       0.81      0.88      0.84        58

    accuracy                           0.85       128
   macro avg       0.85      0.85      0.85       128
weighted avg       0.85      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.76      0.83        72
         DME       0.75      0.91      0.82        56

    accuracy                           0.83       128
   macro avg       0.83      0.84      0.83       128
weighted avg       0.84      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.90        65
         DME       0.87      0.95      0.91        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.81      0.87        73
         DME       0.79      0.95      0.86        55

    accuracy                           0.87       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.82      0.86        73
         DME       0.79      0.89      0.84        55

    accuracy                           0.85       128
   macro avg       0.85      0.86      0.85       128
weighted avg       0.86      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.94      0.91        67
         DME       0.93      0.85      0.89        61

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.82      0.88        73
         DME       0.80      0.93      0.86        55

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.82      0.88        68
         DME       0.83      0.95      0.88        60

    accuracy                           0.88       128
   macro avg       0.89      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
         DME       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.83      0.89        71
      DRUSEN       0.82      0.95      0.88        57

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.82      0.86        61
      DRUSEN       0.85      0.93      0.89        67

    accuracy                           0.88       128
   macro avg       0.88      0.87      0.87       128
weighted avg       0.88      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.83      0.86        70
      DRUSEN       0.81      0.88      0.84        58

    accuracy                           0.85       128
   macro avg       0.85      0.85      0.85       128
weighted avg       0.85      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.76      0.83        72
      DRUSEN       0.75      0.91      0.82        56

    accuracy                           0.83       128
   macro avg       0.83      0.84      0.83       128
weighted avg       0.84      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.90        65
      DRUSEN       0.87      0.95      0.91        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.81      0.87        73
      DRUSEN       0.79      0.95      0.86        55

    accuracy                           0.87       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.82      0.86        73
      DRUSEN       0.79      0.89      0.84        55

    accuracy                           0.85       128
   macro avg       0.85      0.86      0.85       128
weighted avg       0.86      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.94      0.91        67
      DRUSEN       0.93      0.85      0.89        61

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.82      0.88        73
      DRUSEN       0.80      0.93      0.86        55

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.82      0.88        68
      DRUSEN       0.83      0.95      0.88        60

    accuracy                           0.88       128
   macro avg       0.89      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
      DRUSEN       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

Training accuracy [0.8711943793911007]

 | Global Training Round : 2 |

----------------
user chosen 2
----------------
----------------
| Global Round : 1 | Local Epoch : 0 | [0/10237 (0%)]	Loss: 1.048619
| Global Round : 1 | Local Epoch : 0 | [100/10237 (1%)]	Loss: 0.411820
| Global Round : 1 | Local Epoch : 0 | [200/10237 (2%)]	Loss: 0.705131
| Global Round : 1 | Local Epoch : 0 | [300/10237 (3%)]	Loss: 0.379564
| Global Round : 1 | Local Epoch : 0 | [400/10237 (4%)]	Loss: 0.249695
| Global Round : 1 | Local Epoch : 0 | [500/10237 (5%)]	Loss: 0.111727
| Global Round : 1 | Local Epoch : 0 | [600/10237 (6%)]	Loss: 0.225375
| Global Round : 1 | Local Epoch : 0 | [700/10237 (7%)]	Loss: 0.590404
| Global Round : 1 | Local Epoch : 0 | [800/10237 (8%)]	Loss: 0.438489
| Global Round : 1 | Local Epoch : 0 | [900/10237 (9%)]	Loss: 0.429986
| Global Round : 1 | Local Epoch : 0 | [1000/10237 (10%)]	Loss: 0.359446
| Global Round : 1 | Local Epoch : 0 | [1100/10237 (11%)]	Loss: 0.267824
| Global Round : 1 | Local Epoch : 0 | [1200/10237 (12%)]	Loss: 0.763213
| Global Round : 1 | Local Epoch : 0 | [1300/10237 (13%)]	Loss: 0.364470
| Global Round : 1 | Local Epoch : 0 | [1400/10237 (14%)]	Loss: 0.377194
| Global Round : 1 | Local Epoch : 0 | [1500/10237 (15%)]	Loss: 0.225429
| Global Round : 1 | Local Epoch : 0 | [1600/10237 (16%)]	Loss: 0.253211
| Global Round : 1 | Local Epoch : 0 | [1700/10237 (17%)]	Loss: 0.388000
| Global Round : 1 | Local Epoch : 0 | [1800/10237 (18%)]	Loss: 0.611371
| Global Round : 1 | Local Epoch : 0 | [1900/10237 (19%)]	Loss: 0.082099
| Global Round : 1 | Local Epoch : 0 | [2000/10237 (20%)]	Loss: 0.427822
| Global Round : 1 | Local Epoch : 0 | [2100/10237 (21%)]	Loss: 0.320959
| Global Round : 1 | Local Epoch : 0 | [2200/10237 (21%)]	Loss: 0.349999
| Global Round : 1 | Local Epoch : 0 | [2300/10237 (22%)]	Loss: 0.338965
| Global Round : 1 | Local Epoch : 0 | [2400/10237 (23%)]	Loss: 0.585385
| Global Round : 1 | Local Epoch : 0 | [2500/10237 (24%)]	Loss: 0.410452
| Global Round : 1 | Local Epoch : 0 | [2600/10237 (25%)]	Loss: 0.216181
| Global Round : 1 | Local Epoch : 0 | [2700/10237 (26%)]	Loss: 0.733720
| Global Round : 1 | Local Epoch : 0 | [2800/10237 (27%)]	Loss: 0.561905
| Global Round : 1 | Local Epoch : 0 | [2900/10237 (28%)]	Loss: 0.263931
| Global Round : 1 | Local Epoch : 0 | [3000/10237 (29%)]	Loss: 0.464073
| Global Round : 1 | Local Epoch : 0 | [3100/10237 (30%)]	Loss: 0.321757
| Global Round : 1 | Local Epoch : 0 | [3200/10237 (31%)]	Loss: 0.429691
| Global Round : 1 | Local Epoch : 0 | [3300/10237 (32%)]	Loss: 0.156004
| Global Round : 1 | Local Epoch : 0 | [3400/10237 (33%)]	Loss: 0.435945
| Global Round : 1 | Local Epoch : 0 | [3500/10237 (34%)]	Loss: 0.356447
| Global Round : 1 | Local Epoch : 0 | [3600/10237 (35%)]	Loss: 0.419743
| Global Round : 1 | Local Epoch : 0 | [3700/10237 (36%)]	Loss: 0.283985
| Global Round : 1 | Local Epoch : 0 | [3800/10237 (37%)]	Loss: 0.242640
| Global Round : 1 | Local Epoch : 0 | [3900/10237 (38%)]	Loss: 0.341493
| Global Round : 1 | Local Epoch : 0 | [4000/10237 (39%)]	Loss: 1.074119
| Global Round : 1 | Local Epoch : 0 | [4100/10237 (40%)]	Loss: 0.118745
| Global Round : 1 | Local Epoch : 0 | [4200/10237 (41%)]	Loss: 0.550346
| Global Round : 1 | Local Epoch : 0 | [4300/10237 (42%)]	Loss: 0.195953
| Global Round : 1 | Local Epoch : 0 | [4400/10237 (43%)]	Loss: 0.260896
| Global Round : 1 | Local Epoch : 0 | [4500/10237 (44%)]	Loss: 0.726964
| Global Round : 1 | Local Epoch : 0 | [4600/10237 (45%)]	Loss: 0.494284
| Global Round : 1 | Local Epoch : 0 | [4700/10237 (46%)]	Loss: 0.625458
| Global Round : 1 | Local Epoch : 0 | [4800/10237 (47%)]	Loss: 0.193745
| Global Round : 1 | Local Epoch : 0 | [4900/10237 (48%)]	Loss: 0.704719
| Global Round : 1 | Local Epoch : 0 | [5000/10237 (49%)]	Loss: 0.867800
| Global Round : 1 | Local Epoch : 0 | [5100/10237 (50%)]	Loss: 0.394609
| Global Round : 1 | Local Epoch : 0 | [5200/10237 (51%)]	Loss: 0.488054
| Global Round : 1 | Local Epoch : 0 | [5300/10237 (52%)]	Loss: 0.456183
| Global Round : 1 | Local Epoch : 0 | [5400/10237 (53%)]	Loss: 0.760595
| Global Round : 1 | Local Epoch : 0 | [5500/10237 (54%)]	Loss: 0.395042
| Global Round : 1 | Local Epoch : 0 | [5600/10237 (55%)]	Loss: 0.307245
| Global Round : 1 | Local Epoch : 0 | [5700/10237 (56%)]	Loss: 0.679631
| Global Round : 1 | Local Epoch : 0 | [5800/10237 (57%)]	Loss: 0.241801
| Global Round : 1 | Local Epoch : 0 | [5900/10237 (58%)]	Loss: 0.397761
| Global Round : 1 | Local Epoch : 0 | [6000/10237 (59%)]	Loss: 0.331579
| Global Round : 1 | Local Epoch : 0 | [6100/10237 (60%)]	Loss: 0.326102
| Global Round : 1 | Local Epoch : 0 | [6200/10237 (61%)]	Loss: 0.190702
| Global Round : 1 | Local Epoch : 0 | [6300/10237 (62%)]	Loss: 0.955308
| Global Round : 1 | Local Epoch : 0 | [6400/10237 (62%)]	Loss: 1.076709
| Global Round : 1 | Local Epoch : 0 | [6500/10237 (63%)]	Loss: 0.345583
| Global Round : 1 | Local Epoch : 0 | [6600/10237 (64%)]	Loss: 0.486691
| Global Round : 1 | Local Epoch : 0 | [6700/10237 (65%)]	Loss: 0.619990
| Global Round : 1 | Local Epoch : 0 | [6800/10237 (66%)]	Loss: 0.141122
| Global Round : 1 | Local Epoch : 0 | [6900/10237 (67%)]	Loss: 0.378951
| Global Round : 1 | Local Epoch : 0 | [7000/10237 (68%)]	Loss: 0.223487
| Global Round : 1 | Local Epoch : 0 | [7100/10237 (69%)]	Loss: 0.108637
| Global Round : 1 | Local Epoch : 0 | [7200/10237 (70%)]	Loss: 0.479475
| Global Round : 1 | Local Epoch : 0 | [7300/10237 (71%)]	Loss: 0.411626
| Global Round : 1 | Local Epoch : 0 | [7400/10237 (72%)]	Loss: 0.398990
| Global Round : 1 | Local Epoch : 0 | [7500/10237 (73%)]	Loss: 0.615525
| Global Round : 1 | Local Epoch : 0 | [7600/10237 (74%)]	Loss: 0.397997
| Global Round : 1 | Local Epoch : 0 | [7700/10237 (75%)]	Loss: 0.381339
| Global Round : 1 | Local Epoch : 0 | [7800/10237 (76%)]	Loss: 0.470691
| Global Round : 1 | Local Epoch : 0 | [7900/10237 (77%)]	Loss: 0.330580
| Global Round : 1 | Local Epoch : 0 | [8000/10237 (78%)]	Loss: 0.392045
| Global Round : 1 | Local Epoch : 0 | [8100/10237 (79%)]	Loss: 0.125799
| Global Round : 1 | Local Epoch : 0 | [8200/10237 (80%)]	Loss: 0.163615
| Global Round : 1 | Local Epoch : 0 | [8300/10237 (81%)]	Loss: 1.039575
| Global Round : 1 | Local Epoch : 0 | [8400/10237 (82%)]	Loss: 0.319414
| Global Round : 1 | Local Epoch : 0 | [8500/10237 (83%)]	Loss: 0.244166
| Global Round : 1 | Local Epoch : 0 | [8600/10237 (84%)]	Loss: 0.245069
| Global Round : 1 | Local Epoch : 0 | [8700/10237 (85%)]	Loss: 0.513245
| Global Round : 1 | Local Epoch : 0 | [8800/10237 (86%)]	Loss: 0.270634
| Global Round : 1 | Local Epoch : 0 | [8900/10237 (87%)]	Loss: 0.195705
| Global Round : 1 | Local Epoch : 0 | [9000/10237 (88%)]	Loss: 0.696794
| Global Round : 1 | Local Epoch : 0 | [9100/10237 (89%)]	Loss: 0.304832
| Global Round : 1 | Local Epoch : 0 | [9200/10237 (90%)]	Loss: 0.285729
| Global Round : 1 | Local Epoch : 0 | [9300/10237 (91%)]	Loss: 0.279730
| Global Round : 1 | Local Epoch : 0 | [9400/10237 (92%)]	Loss: 0.207414
| Global Round : 1 | Local Epoch : 0 | [9500/10237 (93%)]	Loss: 0.791086
| Global Round : 1 | Local Epoch : 0 | [9600/10237 (94%)]	Loss: 0.423738
| Global Round : 1 | Local Epoch : 0 | [9700/10237 (95%)]	Loss: 0.463307
| Global Round : 1 | Local Epoch : 0 | [9800/10237 (96%)]	Loss: 0.678614
| Global Round : 1 | Local Epoch : 0 | [9900/10237 (97%)]	Loss: 0.390208
| Global Round : 1 | Local Epoch : 0 | [10000/10237 (98%)]	Loss: 0.099702
| Global Round : 1 | Local Epoch : 0 | [10100/10237 (99%)]	Loss: 0.178783
| Global Round : 1 | Local Epoch : 0 | [10200/10237 (100%)]	Loss: 0.137762
| Global Round : 1 | Local Epoch : 1 | [0/10237 (0%)]	Loss: 0.183405
| Global Round : 1 | Local Epoch : 1 | [100/10237 (1%)]	Loss: 0.243434
| Global Round : 1 | Local Epoch : 1 | [200/10237 (2%)]	Loss: 0.217242
| Global Round : 1 | Local Epoch : 1 | [300/10237 (3%)]	Loss: 0.312030
| Global Round : 1 | Local Epoch : 1 | [400/10237 (4%)]	Loss: 0.316873
| Global Round : 1 | Local Epoch : 1 | [500/10237 (5%)]	Loss: 0.481865
| Global Round : 1 | Local Epoch : 1 | [600/10237 (6%)]	Loss: 0.381074
| Global Round : 1 | Local Epoch : 1 | [700/10237 (7%)]	Loss: 0.321534
| Global Round : 1 | Local Epoch : 1 | [800/10237 (8%)]	Loss: 0.606163
| Global Round : 1 | Local Epoch : 1 | [900/10237 (9%)]	Loss: 0.386863
| Global Round : 1 | Local Epoch : 1 | [1000/10237 (10%)]	Loss: 0.509778
| Global Round : 1 | Local Epoch : 1 | [1100/10237 (11%)]	Loss: 0.306333
| Global Round : 1 | Local Epoch : 1 | [1200/10237 (12%)]	Loss: 0.201103
| Global Round : 1 | Local Epoch : 1 | [1300/10237 (13%)]	Loss: 0.364418
| Global Round : 1 | Local Epoch : 1 | [1400/10237 (14%)]	Loss: 0.253944
| Global Round : 1 | Local Epoch : 1 | [1500/10237 (15%)]	Loss: 0.357718
| Global Round : 1 | Local Epoch : 1 | [1600/10237 (16%)]	Loss: 0.353061
| Global Round : 1 | Local Epoch : 1 | [1700/10237 (17%)]	Loss: 0.324830
| Global Round : 1 | Local Epoch : 1 | [1800/10237 (18%)]	Loss: 0.226605
| Global Round : 1 | Local Epoch : 1 | [1900/10237 (19%)]	Loss: 0.348987
| Global Round : 1 | Local Epoch : 1 | [2000/10237 (20%)]	Loss: 0.911102
| Global Round : 1 | Local Epoch : 1 | [2100/10237 (21%)]	Loss: 0.541486
| Global Round : 1 | Local Epoch : 1 | [2200/10237 (21%)]	Loss: 1.129731
| Global Round : 1 | Local Epoch : 1 | [2300/10237 (22%)]	Loss: 0.507454
| Global Round : 1 | Local Epoch : 1 | [2400/10237 (23%)]	Loss: 0.505860
| Global Round : 1 | Local Epoch : 1 | [2500/10237 (24%)]	Loss: 0.262329
| Global Round : 1 | Local Epoch : 1 | [2600/10237 (25%)]	Loss: 0.599285
| Global Round : 1 | Local Epoch : 1 | [2700/10237 (26%)]	Loss: 0.194789
| Global Round : 1 | Local Epoch : 1 | [2800/10237 (27%)]	Loss: 0.478214
| Global Round : 1 | Local Epoch : 1 | [2900/10237 (28%)]	Loss: 0.354075
| Global Round : 1 | Local Epoch : 1 | [3000/10237 (29%)]	Loss: 1.377554
| Global Round : 1 | Local Epoch : 1 | [3100/10237 (30%)]	Loss: 0.366040
| Global Round : 1 | Local Epoch : 1 | [3200/10237 (31%)]	Loss: 0.761172
| Global Round : 1 | Local Epoch : 1 | [3300/10237 (32%)]	Loss: 0.332350
| Global Round : 1 | Local Epoch : 1 | [3400/10237 (33%)]	Loss: 0.222784
| Global Round : 1 | Local Epoch : 1 | [3500/10237 (34%)]	Loss: 0.327113
| Global Round : 1 | Local Epoch : 1 | [3600/10237 (35%)]	Loss: 0.536816
| Global Round : 1 | Local Epoch : 1 | [3700/10237 (36%)]	Loss: 0.225237
| Global Round : 1 | Local Epoch : 1 | [3800/10237 (37%)]	Loss: 0.400324
| Global Round : 1 | Local Epoch : 1 | [3900/10237 (38%)]	Loss: 0.281414
| Global Round : 1 | Local Epoch : 1 | [4000/10237 (39%)]	Loss: 0.095999
| Global Round : 1 | Local Epoch : 1 | [4100/10237 (40%)]	Loss: 0.486621
| Global Round : 1 | Local Epoch : 1 | [4200/10237 (41%)]	Loss: 0.412614
| Global Round : 1 | Local Epoch : 1 | [4300/10237 (42%)]	Loss: 0.577317
| Global Round : 1 | Local Epoch : 1 | [4400/10237 (43%)]	Loss: 0.287736
| Global Round : 1 | Local Epoch : 1 | [4500/10237 (44%)]	Loss: 0.183403
| Global Round : 1 | Local Epoch : 1 | [4600/10237 (45%)]	Loss: 0.666738
| Global Round : 1 | Local Epoch : 1 | [4700/10237 (46%)]	Loss: 0.476043
| Global Round : 1 | Local Epoch : 1 | [4800/10237 (47%)]	Loss: 0.405234
| Global Round : 1 | Local Epoch : 1 | [4900/10237 (48%)]	Loss: 0.419256
| Global Round : 1 | Local Epoch : 1 | [5000/10237 (49%)]	Loss: 0.431567
| Global Round : 1 | Local Epoch : 1 | [5100/10237 (50%)]	Loss: 0.631020
| Global Round : 1 | Local Epoch : 1 | [5200/10237 (51%)]	Loss: 0.152201
| Global Round : 1 | Local Epoch : 1 | [5300/10237 (52%)]	Loss: 0.365022
| Global Round : 1 | Local Epoch : 1 | [5400/10237 (53%)]	Loss: 0.311799
| Global Round : 1 | Local Epoch : 1 | [5500/10237 (54%)]	Loss: 0.288427
| Global Round : 1 | Local Epoch : 1 | [5600/10237 (55%)]	Loss: 0.512363
| Global Round : 1 | Local Epoch : 1 | [5700/10237 (56%)]	Loss: 0.289158
| Global Round : 1 | Local Epoch : 1 | [5800/10237 (57%)]	Loss: 0.495931
| Global Round : 1 | Local Epoch : 1 | [5900/10237 (58%)]	Loss: 0.586772
| Global Round : 1 | Local Epoch : 1 | [6000/10237 (59%)]	Loss: 0.190541
| Global Round : 1 | Local Epoch : 1 | [6100/10237 (60%)]	Loss: 0.659477
| Global Round : 1 | Local Epoch : 1 | [6200/10237 (61%)]	Loss: 0.212561
| Global Round : 1 | Local Epoch : 1 | [6300/10237 (62%)]	Loss: 0.290063
| Global Round : 1 | Local Epoch : 1 | [6400/10237 (62%)]	Loss: 0.464759
| Global Round : 1 | Local Epoch : 1 | [6500/10237 (63%)]	Loss: 0.424620
| Global Round : 1 | Local Epoch : 1 | [6600/10237 (64%)]	Loss: 0.971255
| Global Round : 1 | Local Epoch : 1 | [6700/10237 (65%)]	Loss: 0.405687
| Global Round : 1 | Local Epoch : 1 | [6800/10237 (66%)]	Loss: 0.356569
| Global Round : 1 | Local Epoch : 1 | [6900/10237 (67%)]	Loss: 0.458700
| Global Round : 1 | Local Epoch : 1 | [7000/10237 (68%)]	Loss: 0.281100
| Global Round : 1 | Local Epoch : 1 | [7100/10237 (69%)]	Loss: 0.444883
| Global Round : 1 | Local Epoch : 1 | [7200/10237 (70%)]	Loss: 0.374968
| Global Round : 1 | Local Epoch : 1 | [7300/10237 (71%)]	Loss: 0.309007
| Global Round : 1 | Local Epoch : 1 | [7400/10237 (72%)]	Loss: 0.160561
| Global Round : 1 | Local Epoch : 1 | [7500/10237 (73%)]	Loss: 0.682775
| Global Round : 1 | Local Epoch : 1 | [7600/10237 (74%)]	Loss: 0.575234
| Global Round : 1 | Local Epoch : 1 | [7700/10237 (75%)]	Loss: 0.382642
| Global Round : 1 | Local Epoch : 1 | [7800/10237 (76%)]	Loss: 0.234752
| Global Round : 1 | Local Epoch : 1 | [7900/10237 (77%)]	Loss: 0.510126
| Global Round : 1 | Local Epoch : 1 | [8000/10237 (78%)]	Loss: 0.565603
| Global Round : 1 | Local Epoch : 1 | [8100/10237 (79%)]	Loss: 0.203818
| Global Round : 1 | Local Epoch : 1 | [8200/10237 (80%)]	Loss: 0.272098
| Global Round : 1 | Local Epoch : 1 | [8300/10237 (81%)]	Loss: 0.339702
| Global Round : 1 | Local Epoch : 1 | [8400/10237 (82%)]	Loss: 0.298468
| Global Round : 1 | Local Epoch : 1 | [8500/10237 (83%)]	Loss: 0.406021
| Global Round : 1 | Local Epoch : 1 | [8600/10237 (84%)]	Loss: 0.123000
| Global Round : 1 | Local Epoch : 1 | [8700/10237 (85%)]	Loss: 0.458704
| Global Round : 1 | Local Epoch : 1 | [8800/10237 (86%)]	Loss: 0.340600
| Global Round : 1 | Local Epoch : 1 | [8900/10237 (87%)]	Loss: 0.237706
| Global Round : 1 | Local Epoch : 1 | [9000/10237 (88%)]	Loss: 0.233017
| Global Round : 1 | Local Epoch : 1 | [9100/10237 (89%)]	Loss: 0.240061
| Global Round : 1 | Local Epoch : 1 | [9200/10237 (90%)]	Loss: 0.428858
| Global Round : 1 | Local Epoch : 1 | [9300/10237 (91%)]	Loss: 0.400206
| Global Round : 1 | Local Epoch : 1 | [9400/10237 (92%)]	Loss: 0.414853
| Global Round : 1 | Local Epoch : 1 | [9500/10237 (93%)]	Loss: 0.205633
| Global Round : 1 | Local Epoch : 1 | [9600/10237 (94%)]	Loss: 0.110221
| Global Round : 1 | Local Epoch : 1 | [9700/10237 (95%)]	Loss: 0.672820
| Global Round : 1 | Local Epoch : 1 | [9800/10237 (96%)]	Loss: 0.228736
| Global Round : 1 | Local Epoch : 1 | [9900/10237 (97%)]	Loss: 0.445836
| Global Round : 1 | Local Epoch : 1 | [10000/10237 (98%)]	Loss: 0.169164
| Global Round : 1 | Local Epoch : 1 | [10100/10237 (99%)]	Loss: 0.447963
| Global Round : 1 | Local Epoch : 1 | [10200/10237 (100%)]	Loss: 0.212823
| Global Round : 1 | Local Epoch : 2 | [0/10237 (0%)]	Loss: 0.220029
| Global Round : 1 | Local Epoch : 2 | [100/10237 (1%)]	Loss: 0.505491
| Global Round : 1 | Local Epoch : 2 | [200/10237 (2%)]	Loss: 0.693598
| Global Round : 1 | Local Epoch : 2 | [300/10237 (3%)]	Loss: 0.222977
| Global Round : 1 | Local Epoch : 2 | [400/10237 (4%)]	Loss: 0.545970
| Global Round : 1 | Local Epoch : 2 | [500/10237 (5%)]	Loss: 0.294636
| Global Round : 1 | Local Epoch : 2 | [600/10237 (6%)]	Loss: 0.358544
| Global Round : 1 | Local Epoch : 2 | [700/10237 (7%)]	Loss: 0.281150
| Global Round : 1 | Local Epoch : 2 | [800/10237 (8%)]	Loss: 0.428517
| Global Round : 1 | Local Epoch : 2 | [900/10237 (9%)]	Loss: 0.220401
| Global Round : 1 | Local Epoch : 2 | [1000/10237 (10%)]	Loss: 0.332570
| Global Round : 1 | Local Epoch : 2 | [1100/10237 (11%)]	Loss: 0.344946
| Global Round : 1 | Local Epoch : 2 | [1200/10237 (12%)]	Loss: 0.211022
| Global Round : 1 | Local Epoch : 2 | [1300/10237 (13%)]	Loss: 0.426383
| Global Round : 1 | Local Epoch : 2 | [1400/10237 (14%)]	Loss: 0.243515
| Global Round : 1 | Local Epoch : 2 | [1500/10237 (15%)]	Loss: 0.560540
| Global Round : 1 | Local Epoch : 2 | [1600/10237 (16%)]	Loss: 0.351231
| Global Round : 1 | Local Epoch : 2 | [1700/10237 (17%)]	Loss: 0.150863
| Global Round : 1 | Local Epoch : 2 | [1800/10237 (18%)]	Loss: 0.678304
| Global Round : 1 | Local Epoch : 2 | [1900/10237 (19%)]	Loss: 0.307118
| Global Round : 1 | Local Epoch : 2 | [2000/10237 (20%)]	Loss: 0.317817
| Global Round : 1 | Local Epoch : 2 | [2100/10237 (21%)]	Loss: 0.134168
| Global Round : 1 | Local Epoch : 2 | [2200/10237 (21%)]	Loss: 0.582482
| Global Round : 1 | Local Epoch : 2 | [2300/10237 (22%)]	Loss: 0.185312
| Global Round : 1 | Local Epoch : 2 | [2400/10237 (23%)]	Loss: 0.248605
| Global Round : 1 | Local Epoch : 2 | [2500/10237 (24%)]	Loss: 0.397806
| Global Round : 1 | Local Epoch : 2 | [2600/10237 (25%)]	Loss: 0.323936
| Global Round : 1 | Local Epoch : 2 | [2700/10237 (26%)]	Loss: 0.459187
| Global Round : 1 | Local Epoch : 2 | [2800/10237 (27%)]	Loss: 0.490855
| Global Round : 1 | Local Epoch : 2 | [2900/10237 (28%)]	Loss: 0.269333
| Global Round : 1 | Local Epoch : 2 | [3000/10237 (29%)]	Loss: 0.202340
| Global Round : 1 | Local Epoch : 2 | [3100/10237 (30%)]	Loss: 0.410520
| Global Round : 1 | Local Epoch : 2 | [3200/10237 (31%)]	Loss: 0.285371
| Global Round : 1 | Local Epoch : 2 | [3300/10237 (32%)]	Loss: 0.138442
| Global Round : 1 | Local Epoch : 2 | [3400/10237 (33%)]	Loss: 0.218843
| Global Round : 1 | Local Epoch : 2 | [3500/10237 (34%)]	Loss: 0.192412
| Global Round : 1 | Local Epoch : 2 | [3600/10237 (35%)]	Loss: 0.539262
| Global Round : 1 | Local Epoch : 2 | [3700/10237 (36%)]	Loss: 0.295739
| Global Round : 1 | Local Epoch : 2 | [3800/10237 (37%)]	Loss: 0.082763
| Global Round : 1 | Local Epoch : 2 | [3900/10237 (38%)]	Loss: 0.326066
| Global Round : 1 | Local Epoch : 2 | [4000/10237 (39%)]	Loss: 0.210318
| Global Round : 1 | Local Epoch : 2 | [4100/10237 (40%)]	Loss: 0.530242
| Global Round : 1 | Local Epoch : 2 | [4200/10237 (41%)]	Loss: 0.452110
| Global Round : 1 | Local Epoch : 2 | [4300/10237 (42%)]	Loss: 0.574055
| Global Round : 1 | Local Epoch : 2 | [4400/10237 (43%)]	Loss: 0.301825
| Global Round : 1 | Local Epoch : 2 | [4500/10237 (44%)]	Loss: 0.221156
| Global Round : 1 | Local Epoch : 2 | [4600/10237 (45%)]	Loss: 0.256057
| Global Round : 1 | Local Epoch : 2 | [4700/10237 (46%)]	Loss: 0.467357
| Global Round : 1 | Local Epoch : 2 | [4800/10237 (47%)]	Loss: 0.140407
| Global Round : 1 | Local Epoch : 2 | [4900/10237 (48%)]	Loss: 0.999832
| Global Round : 1 | Local Epoch : 2 | [5000/10237 (49%)]	Loss: 0.862121
| Global Round : 1 | Local Epoch : 2 | [5100/10237 (50%)]	Loss: 0.250010
| Global Round : 1 | Local Epoch : 2 | [5200/10237 (51%)]	Loss: 0.232434
| Global Round : 1 | Local Epoch : 2 | [5300/10237 (52%)]	Loss: 0.117694
| Global Round : 1 | Local Epoch : 2 | [5400/10237 (53%)]	Loss: 0.399571
| Global Round : 1 | Local Epoch : 2 | [5500/10237 (54%)]	Loss: 0.281481
| Global Round : 1 | Local Epoch : 2 | [5600/10237 (55%)]	Loss: 0.155208
| Global Round : 1 | Local Epoch : 2 | [5700/10237 (56%)]	Loss: 0.404474
| Global Round : 1 | Local Epoch : 2 | [5800/10237 (57%)]	Loss: 0.423289
| Global Round : 1 | Local Epoch : 2 | [5900/10237 (58%)]	Loss: 0.299655
| Global Round : 1 | Local Epoch : 2 | [6000/10237 (59%)]	Loss: 0.432396
| Global Round : 1 | Local Epoch : 2 | [6100/10237 (60%)]	Loss: 0.523271
| Global Round : 1 | Local Epoch : 2 | [6200/10237 (61%)]	Loss: 0.236610
| Global Round : 1 | Local Epoch : 2 | [6300/10237 (62%)]	Loss: 0.120219
| Global Round : 1 | Local Epoch : 2 | [6400/10237 (62%)]	Loss: 0.204447
| Global Round : 1 | Local Epoch : 2 | [6500/10237 (63%)]	Loss: 0.327347
| Global Round : 1 | Local Epoch : 2 | [6600/10237 (64%)]	Loss: 0.237186
| Global Round : 1 | Local Epoch : 2 | [6700/10237 (65%)]	Loss: 0.223428
| Global Round : 1 | Local Epoch : 2 | [6800/10237 (66%)]	Loss: 0.372066
| Global Round : 1 | Local Epoch : 2 | [6900/10237 (67%)]	Loss: 0.197853
| Global Round : 1 | Local Epoch : 2 | [7000/10237 (68%)]	Loss: 0.313716
| Global Round : 1 | Local Epoch : 2 | [7100/10237 (69%)]	Loss: 0.149406
| Global Round : 1 | Local Epoch : 2 | [7200/10237 (70%)]	Loss: 0.626340
| Global Round : 1 | Local Epoch : 2 | [7300/10237 (71%)]	Loss: 0.257693
| Global Round : 1 | Local Epoch : 2 | [7400/10237 (72%)]	Loss: 0.136721
| Global Round : 1 | Local Epoch : 2 | [7500/10237 (73%)]	Loss: 0.702291
| Global Round : 1 | Local Epoch : 2 | [7600/10237 (74%)]	Loss: 0.719141
| Global Round : 1 | Local Epoch : 2 | [7700/10237 (75%)]	Loss: 0.590149
| Global Round : 1 | Local Epoch : 2 | [7800/10237 (76%)]	Loss: 0.277081
| Global Round : 1 | Local Epoch : 2 | [7900/10237 (77%)]	Loss: 0.311631
| Global Round : 1 | Local Epoch : 2 | [8000/10237 (78%)]	Loss: 0.416810
| Global Round : 1 | Local Epoch : 2 | [8100/10237 (79%)]	Loss: 0.505044
| Global Round : 1 | Local Epoch : 2 | [8200/10237 (80%)]	Loss: 0.189595
| Global Round : 1 | Local Epoch : 2 | [8300/10237 (81%)]	Loss: 0.270943
| Global Round : 1 | Local Epoch : 2 | [8400/10237 (82%)]	Loss: 0.285248
| Global Round : 1 | Local Epoch : 2 | [8500/10237 (83%)]	Loss: 0.251511
| Global Round : 1 | Local Epoch : 2 | [8600/10237 (84%)]	Loss: 0.673821
| Global Round : 1 | Local Epoch : 2 | [8700/10237 (85%)]	Loss: 0.159678
| Global Round : 1 | Local Epoch : 2 | [8800/10237 (86%)]	Loss: 0.195473
| Global Round : 1 | Local Epoch : 2 | [8900/10237 (87%)]	Loss: 0.102660
| Global Round : 1 | Local Epoch : 2 | [9000/10237 (88%)]	Loss: 0.087228
| Global Round : 1 | Local Epoch : 2 | [9100/10237 (89%)]	Loss: 0.167351
| Global Round : 1 | Local Epoch : 2 | [9200/10237 (90%)]	Loss: 0.508586
| Global Round : 1 | Local Epoch : 2 | [9300/10237 (91%)]	Loss: 0.564305
| Global Round : 1 | Local Epoch : 2 | [9400/10237 (92%)]	Loss: 0.551864
| Global Round : 1 | Local Epoch : 2 | [9500/10237 (93%)]	Loss: 0.464325
| Global Round : 1 | Local Epoch : 2 | [9600/10237 (94%)]	Loss: 0.395253
| Global Round : 1 | Local Epoch : 2 | [9700/10237 (95%)]	Loss: 0.158201
| Global Round : 1 | Local Epoch : 2 | [9800/10237 (96%)]	Loss: 0.334174
| Global Round : 1 | Local Epoch : 2 | [9900/10237 (97%)]	Loss: 0.167891
| Global Round : 1 | Local Epoch : 2 | [10000/10237 (98%)]	Loss: 0.643014
| Global Round : 1 | Local Epoch : 2 | [10100/10237 (99%)]	Loss: 0.954634
| Global Round : 1 | Local Epoch : 2 | [10200/10237 (100%)]	Loss: 0.441542
| Global Round : 1 | Local Epoch : 3 | [0/10237 (0%)]	Loss: 0.132428
| Global Round : 1 | Local Epoch : 3 | [100/10237 (1%)]	Loss: 0.217432
| Global Round : 1 | Local Epoch : 3 | [200/10237 (2%)]	Loss: 0.072745
| Global Round : 1 | Local Epoch : 3 | [300/10237 (3%)]	Loss: 0.304244
| Global Round : 1 | Local Epoch : 3 | [400/10237 (4%)]	Loss: 0.122956
| Global Round : 1 | Local Epoch : 3 | [500/10237 (5%)]	Loss: 0.188932
| Global Round : 1 | Local Epoch : 3 | [600/10237 (6%)]	Loss: 0.247293
| Global Round : 1 | Local Epoch : 3 | [700/10237 (7%)]	Loss: 0.325069
| Global Round : 1 | Local Epoch : 3 | [800/10237 (8%)]	Loss: 0.212796
| Global Round : 1 | Local Epoch : 3 | [900/10237 (9%)]	Loss: 0.226369
| Global Round : 1 | Local Epoch : 3 | [1000/10237 (10%)]	Loss: 0.082709
| Global Round : 1 | Local Epoch : 3 | [1100/10237 (11%)]	Loss: 0.460463
| Global Round : 1 | Local Epoch : 3 | [1200/10237 (12%)]	Loss: 0.251461
| Global Round : 1 | Local Epoch : 3 | [1300/10237 (13%)]	Loss: 0.383685
| Global Round : 1 | Local Epoch : 3 | [1400/10237 (14%)]	Loss: 0.109423
| Global Round : 1 | Local Epoch : 3 | [1500/10237 (15%)]	Loss: 0.296301
| Global Round : 1 | Local Epoch : 3 | [1600/10237 (16%)]	Loss: 0.601715
| Global Round : 1 | Local Epoch : 3 | [1700/10237 (17%)]	Loss: 0.280640
| Global Round : 1 | Local Epoch : 3 | [1800/10237 (18%)]	Loss: 0.179214
| Global Round : 1 | Local Epoch : 3 | [1900/10237 (19%)]	Loss: 0.333486
| Global Round : 1 | Local Epoch : 3 | [2000/10237 (20%)]	Loss: 0.276308
| Global Round : 1 | Local Epoch : 3 | [2100/10237 (21%)]	Loss: 0.441046
| Global Round : 1 | Local Epoch : 3 | [2200/10237 (21%)]	Loss: 0.470677
| Global Round : 1 | Local Epoch : 3 | [2300/10237 (22%)]	Loss: 0.201167
| Global Round : 1 | Local Epoch : 3 | [2400/10237 (23%)]	Loss: 0.409253
| Global Round : 1 | Local Epoch : 3 | [2500/10237 (24%)]	Loss: 0.289813
| Global Round : 1 | Local Epoch : 3 | [2600/10237 (25%)]	Loss: 0.588935
| Global Round : 1 | Local Epoch : 3 | [2700/10237 (26%)]	Loss: 0.183897
| Global Round : 1 | Local Epoch : 3 | [2800/10237 (27%)]	Loss: 0.397430
| Global Round : 1 | Local Epoch : 3 | [2900/10237 (28%)]	Loss: 0.268288
| Global Round : 1 | Local Epoch : 3 | [3000/10237 (29%)]	Loss: 0.540689
| Global Round : 1 | Local Epoch : 3 | [3100/10237 (30%)]	Loss: 0.280028
| Global Round : 1 | Local Epoch : 3 | [3200/10237 (31%)]	Loss: 0.101795
| Global Round : 1 | Local Epoch : 3 | [3300/10237 (32%)]	Loss: 0.200898
| Global Round : 1 | Local Epoch : 3 | [3400/10237 (33%)]	Loss: 0.061457
| Global Round : 1 | Local Epoch : 3 | [3500/10237 (34%)]	Loss: 0.190233
| Global Round : 1 | Local Epoch : 3 | [3600/10237 (35%)]	Loss: 0.386544
| Global Round : 1 | Local Epoch : 3 | [3700/10237 (36%)]	Loss: 0.267298
| Global Round : 1 | Local Epoch : 3 | [3800/10237 (37%)]	Loss: 0.560189
| Global Round : 1 | Local Epoch : 3 | [3900/10237 (38%)]	Loss: 0.446984
| Global Round : 1 | Local Epoch : 3 | [4000/10237 (39%)]	Loss: 0.015436
| Global Round : 1 | Local Epoch : 3 | [4100/10237 (40%)]	Loss: 0.306148
| Global Round : 1 | Local Epoch : 3 | [4200/10237 (41%)]	Loss: 0.229177
| Global Round : 1 | Local Epoch : 3 | [4300/10237 (42%)]	Loss: 0.138456
| Global Round : 1 | Local Epoch : 3 | [4400/10237 (43%)]	Loss: 0.263357
| Global Round : 1 | Local Epoch : 3 | [4500/10237 (44%)]	Loss: 0.489203
| Global Round : 1 | Local Epoch : 3 | [4600/10237 (45%)]	Loss: 0.387942
| Global Round : 1 | Local Epoch : 3 | [4700/10237 (46%)]	Loss: 0.564760
| Global Round : 1 | Local Epoch : 3 | [4800/10237 (47%)]	Loss: 0.373471
| Global Round : 1 | Local Epoch : 3 | [4900/10237 (48%)]	Loss: 0.079303
| Global Round : 1 | Local Epoch : 3 | [5000/10237 (49%)]	Loss: 0.345318
| Global Round : 1 | Local Epoch : 3 | [5100/10237 (50%)]	Loss: 0.459671
| Global Round : 1 | Local Epoch : 3 | [5200/10237 (51%)]	Loss: 0.176442
| Global Round : 1 | Local Epoch : 3 | [5300/10237 (52%)]	Loss: 0.292716
| Global Round : 1 | Local Epoch : 3 | [5400/10237 (53%)]	Loss: 0.117122
| Global Round : 1 | Local Epoch : 3 | [5500/10237 (54%)]	Loss: 0.516308
| Global Round : 1 | Local Epoch : 3 | [5600/10237 (55%)]	Loss: 0.099887
| Global Round : 1 | Local Epoch : 3 | [5700/10237 (56%)]	Loss: 0.111928
| Global Round : 1 | Local Epoch : 3 | [5800/10237 (57%)]	Loss: 0.222390
| Global Round : 1 | Local Epoch : 3 | [5900/10237 (58%)]	Loss: 0.289082
| Global Round : 1 | Local Epoch : 3 | [6000/10237 (59%)]	Loss: 0.734791
| Global Round : 1 | Local Epoch : 3 | [6100/10237 (60%)]	Loss: 0.176962
| Global Round : 1 | Local Epoch : 3 | [6200/10237 (61%)]	Loss: 0.041249
| Global Round : 1 | Local Epoch : 3 | [6300/10237 (62%)]	Loss: 0.135008
| Global Round : 1 | Local Epoch : 3 | [6400/10237 (62%)]	Loss: 0.275362
| Global Round : 1 | Local Epoch : 3 | [6500/10237 (63%)]	Loss: 0.150769
| Global Round : 1 | Local Epoch : 3 | [6600/10237 (64%)]	Loss: 0.090486
| Global Round : 1 | Local Epoch : 3 | [6700/10237 (65%)]	Loss: 0.505513
| Global Round : 1 | Local Epoch : 3 | [6800/10237 (66%)]	Loss: 0.283471
| Global Round : 1 | Local Epoch : 3 | [6900/10237 (67%)]	Loss: 0.078764
| Global Round : 1 | Local Epoch : 3 | [7000/10237 (68%)]	Loss: 0.261490
| Global Round : 1 | Local Epoch : 3 | [7100/10237 (69%)]	Loss: 0.115509
| Global Round : 1 | Local Epoch : 3 | [7200/10237 (70%)]	Loss: 0.505616
| Global Round : 1 | Local Epoch : 3 | [7300/10237 (71%)]	Loss: 0.319243
| Global Round : 1 | Local Epoch : 3 | [7400/10237 (72%)]	Loss: 0.388424
| Global Round : 1 | Local Epoch : 3 | [7500/10237 (73%)]	Loss: 0.080785
| Global Round : 1 | Local Epoch : 3 | [7600/10237 (74%)]	Loss: 0.235753
| Global Round : 1 | Local Epoch : 3 | [7700/10237 (75%)]	Loss: 0.093785
| Global Round : 1 | Local Epoch : 3 | [7800/10237 (76%)]	Loss: 0.223439
| Global Round : 1 | Local Epoch : 3 | [7900/10237 (77%)]	Loss: 0.196053
| Global Round : 1 | Local Epoch : 3 | [8000/10237 (78%)]	Loss: 0.237380
| Global Round : 1 | Local Epoch : 3 | [8100/10237 (79%)]	Loss: 0.115595
| Global Round : 1 | Local Epoch : 3 | [8200/10237 (80%)]	Loss: 0.282435
| Global Round : 1 | Local Epoch : 3 | [8300/10237 (81%)]	Loss: 0.382136
| Global Round : 1 | Local Epoch : 3 | [8400/10237 (82%)]	Loss: 0.092148
| Global Round : 1 | Local Epoch : 3 | [8500/10237 (83%)]	Loss: 0.226566
| Global Round : 1 | Local Epoch : 3 | [8600/10237 (84%)]	Loss: 0.628286
| Global Round : 1 | Local Epoch : 3 | [8700/10237 (85%)]	Loss: 0.646497
| Global Round : 1 | Local Epoch : 3 | [8800/10237 (86%)]	Loss: 0.097760
| Global Round : 1 | Local Epoch : 3 | [8900/10237 (87%)]	Loss: 0.398539
| Global Round : 1 | Local Epoch : 3 | [9000/10237 (88%)]	Loss: 0.137949
| Global Round : 1 | Local Epoch : 3 | [9100/10237 (89%)]	Loss: 0.391862
| Global Round : 1 | Local Epoch : 3 | [9200/10237 (90%)]	Loss: 0.118249
| Global Round : 1 | Local Epoch : 3 | [9300/10237 (91%)]	Loss: 0.224849
| Global Round : 1 | Local Epoch : 3 | [9400/10237 (92%)]	Loss: 0.226523
| Global Round : 1 | Local Epoch : 3 | [9500/10237 (93%)]	Loss: 0.598805
| Global Round : 1 | Local Epoch : 3 | [9600/10237 (94%)]	Loss: 0.145934
| Global Round : 1 | Local Epoch : 3 | [9700/10237 (95%)]	Loss: 0.375338
| Global Round : 1 | Local Epoch : 3 | [9800/10237 (96%)]	Loss: 0.053417
| Global Round : 1 | Local Epoch : 3 | [9900/10237 (97%)]	Loss: 0.187277
| Global Round : 1 | Local Epoch : 3 | [10000/10237 (98%)]	Loss: 0.151572
| Global Round : 1 | Local Epoch : 3 | [10100/10237 (99%)]	Loss: 0.223516
| Global Round : 1 | Local Epoch : 3 | [10200/10237 (100%)]	Loss: 1.167885
| Global Round : 1 | Local Epoch : 4 | [0/10237 (0%)]	Loss: 0.092796
| Global Round : 1 | Local Epoch : 4 | [100/10237 (1%)]	Loss: 0.177665
| Global Round : 1 | Local Epoch : 4 | [200/10237 (2%)]	Loss: 0.393805
| Global Round : 1 | Local Epoch : 4 | [300/10237 (3%)]	Loss: 0.266636
| Global Round : 1 | Local Epoch : 4 | [400/10237 (4%)]	Loss: 0.331010
| Global Round : 1 | Local Epoch : 4 | [500/10237 (5%)]	Loss: 0.127625
| Global Round : 1 | Local Epoch : 4 | [600/10237 (6%)]	Loss: 0.272172
| Global Round : 1 | Local Epoch : 4 | [700/10237 (7%)]	Loss: 0.157737
| Global Round : 1 | Local Epoch : 4 | [800/10237 (8%)]	Loss: 0.232064
| Global Round : 1 | Local Epoch : 4 | [900/10237 (9%)]	Loss: 0.417755
| Global Round : 1 | Local Epoch : 4 | [1000/10237 (10%)]	Loss: 0.208764
| Global Round : 1 | Local Epoch : 4 | [1100/10237 (11%)]	Loss: 0.109098
| Global Round : 1 | Local Epoch : 4 | [1200/10237 (12%)]	Loss: 0.115312
| Global Round : 1 | Local Epoch : 4 | [1300/10237 (13%)]	Loss: 0.277662
| Global Round : 1 | Local Epoch : 4 | [1400/10237 (14%)]	Loss: 0.046497
| Global Round : 1 | Local Epoch : 4 | [1500/10237 (15%)]	Loss: 0.288204
| Global Round : 1 | Local Epoch : 4 | [1600/10237 (16%)]	Loss: 0.148918
| Global Round : 1 | Local Epoch : 4 | [1700/10237 (17%)]	Loss: 0.555947
| Global Round : 1 | Local Epoch : 4 | [1800/10237 (18%)]	Loss: 0.488863
| Global Round : 1 | Local Epoch : 4 | [1900/10237 (19%)]	Loss: 0.154316
| Global Round : 1 | Local Epoch : 4 | [2000/10237 (20%)]	Loss: 0.048700
| Global Round : 1 | Local Epoch : 4 | [2100/10237 (21%)]	Loss: 0.358420
| Global Round : 1 | Local Epoch : 4 | [2200/10237 (21%)]	Loss: 0.743714
| Global Round : 1 | Local Epoch : 4 | [2300/10237 (22%)]	Loss: 0.445954
| Global Round : 1 | Local Epoch : 4 | [2400/10237 (23%)]	Loss: 0.125511
| Global Round : 1 | Local Epoch : 4 | [2500/10237 (24%)]	Loss: 0.118895
| Global Round : 1 | Local Epoch : 4 | [2600/10237 (25%)]	Loss: 0.232806
| Global Round : 1 | Local Epoch : 4 | [2700/10237 (26%)]	Loss: 0.372794
| Global Round : 1 | Local Epoch : 4 | [2800/10237 (27%)]	Loss: 0.662463
| Global Round : 1 | Local Epoch : 4 | [2900/10237 (28%)]	Loss: 0.035014
| Global Round : 1 | Local Epoch : 4 | [3000/10237 (29%)]	Loss: 0.349174
| Global Round : 1 | Local Epoch : 4 | [3100/10237 (30%)]	Loss: 0.363406
| Global Round : 1 | Local Epoch : 4 | [3200/10237 (31%)]	Loss: 0.032842
| Global Round : 1 | Local Epoch : 4 | [3300/10237 (32%)]	Loss: 0.090074
| Global Round : 1 | Local Epoch : 4 | [3400/10237 (33%)]	Loss: 0.096887
| Global Round : 1 | Local Epoch : 4 | [3500/10237 (34%)]	Loss: 0.254455
| Global Round : 1 | Local Epoch : 4 | [3600/10237 (35%)]	Loss: 0.292518
| Global Round : 1 | Local Epoch : 4 | [3700/10237 (36%)]	Loss: 0.319717
| Global Round : 1 | Local Epoch : 4 | [3800/10237 (37%)]	Loss: 0.123042
| Global Round : 1 | Local Epoch : 4 | [3900/10237 (38%)]	Loss: 0.286200
| Global Round : 1 | Local Epoch : 4 | [4000/10237 (39%)]	Loss: 0.406693
| Global Round : 1 | Local Epoch : 4 | [4100/10237 (40%)]	Loss: 0.235526
| Global Round : 1 | Local Epoch : 4 | [4200/10237 (41%)]	Loss: 0.134794
| Global Round : 1 | Local Epoch : 4 | [4300/10237 (42%)]	Loss: 0.406809
| Global Round : 1 | Local Epoch : 4 | [4400/10237 (43%)]	Loss: 0.146768
| Global Round : 1 | Local Epoch : 4 | [4500/10237 (44%)]	Loss: 0.259966
| Global Round : 1 | Local Epoch : 4 | [4600/10237 (45%)]	Loss: 0.113922
| Global Round : 1 | Local Epoch : 4 | [4700/10237 (46%)]	Loss: 0.223326
| Global Round : 1 | Local Epoch : 4 | [4800/10237 (47%)]	Loss: 0.111016
| Global Round : 1 | Local Epoch : 4 | [4900/10237 (48%)]	Loss: 0.517642
| Global Round : 1 | Local Epoch : 4 | [5000/10237 (49%)]	Loss: 0.257294
| Global Round : 1 | Local Epoch : 4 | [5100/10237 (50%)]	Loss: 0.267320
| Global Round : 1 | Local Epoch : 4 | [5200/10237 (51%)]	Loss: 0.148399
| Global Round : 1 | Local Epoch : 4 | [5300/10237 (52%)]	Loss: 0.136590
| Global Round : 1 | Local Epoch : 4 | [5400/10237 (53%)]	Loss: 0.276970
| Global Round : 1 | Local Epoch : 4 | [5500/10237 (54%)]	Loss: 0.124636
| Global Round : 1 | Local Epoch : 4 | [5600/10237 (55%)]	Loss: 0.100594
| Global Round : 1 | Local Epoch : 4 | [5700/10237 (56%)]	Loss: 0.161952
| Global Round : 1 | Local Epoch : 4 | [5800/10237 (57%)]	Loss: 0.337011
| Global Round : 1 | Local Epoch : 4 | [5900/10237 (58%)]	Loss: 0.102006
| Global Round : 1 | Local Epoch : 4 | [6000/10237 (59%)]	Loss: 0.203622
| Global Round : 1 | Local Epoch : 4 | [6100/10237 (60%)]	Loss: 0.081088
| Global Round : 1 | Local Epoch : 4 | [6200/10237 (61%)]	Loss: 0.536157
| Global Round : 1 | Local Epoch : 4 | [6300/10237 (62%)]	Loss: 0.048486
| Global Round : 1 | Local Epoch : 4 | [6400/10237 (62%)]	Loss: 0.350747
| Global Round : 1 | Local Epoch : 4 | [6500/10237 (63%)]	Loss: 0.847639
| Global Round : 1 | Local Epoch : 4 | [6600/10237 (64%)]	Loss: 0.358395
| Global Round : 1 | Local Epoch : 4 | [6700/10237 (65%)]	Loss: 0.483008
| Global Round : 1 | Local Epoch : 4 | [6800/10237 (66%)]	Loss: 0.189644
| Global Round : 1 | Local Epoch : 4 | [6900/10237 (67%)]	Loss: 0.120542
| Global Round : 1 | Local Epoch : 4 | [7000/10237 (68%)]	Loss: 0.221165
| Global Round : 1 | Local Epoch : 4 | [7100/10237 (69%)]	Loss: 0.498010
| Global Round : 1 | Local Epoch : 4 | [7200/10237 (70%)]	Loss: 0.241479
| Global Round : 1 | Local Epoch : 4 | [7300/10237 (71%)]	Loss: 0.135814
| Global Round : 1 | Local Epoch : 4 | [7400/10237 (72%)]	Loss: 0.245294
| Global Round : 1 | Local Epoch : 4 | [7500/10237 (73%)]	Loss: 0.193733
| Global Round : 1 | Local Epoch : 4 | [7600/10237 (74%)]	Loss: 0.263320
| Global Round : 1 | Local Epoch : 4 | [7700/10237 (75%)]	Loss: 0.325290
| Global Round : 1 | Local Epoch : 4 | [7800/10237 (76%)]	Loss: 0.200386
| Global Round : 1 | Local Epoch : 4 | [7900/10237 (77%)]	Loss: 0.184603
| Global Round : 1 | Local Epoch : 4 | [8000/10237 (78%)]	Loss: 0.162310
| Global Round : 1 | Local Epoch : 4 | [8100/10237 (79%)]	Loss: 0.173279
| Global Round : 1 | Local Epoch : 4 | [8200/10237 (80%)]	Loss: 0.406254
| Global Round : 1 | Local Epoch : 4 | [8300/10237 (81%)]	Loss: 0.127042
| Global Round : 1 | Local Epoch : 4 | [8400/10237 (82%)]	Loss: 0.081335
| Global Round : 1 | Local Epoch : 4 | [8500/10237 (83%)]	Loss: 0.360469
| Global Round : 1 | Local Epoch : 4 | [8600/10237 (84%)]	Loss: 0.553192
| Global Round : 1 | Local Epoch : 4 | [8700/10237 (85%)]	Loss: 0.851365
| Global Round : 1 | Local Epoch : 4 | [8800/10237 (86%)]	Loss: 0.623608
| Global Round : 1 | Local Epoch : 4 | [8900/10237 (87%)]	Loss: 0.326408
| Global Round : 1 | Local Epoch : 4 | [9000/10237 (88%)]	Loss: 0.420817
| Global Round : 1 | Local Epoch : 4 | [9100/10237 (89%)]	Loss: 0.255866
| Global Round : 1 | Local Epoch : 4 | [9200/10237 (90%)]	Loss: 0.162854
| Global Round : 1 | Local Epoch : 4 | [9300/10237 (91%)]	Loss: 0.505719
| Global Round : 1 | Local Epoch : 4 | [9400/10237 (92%)]	Loss: 0.159070
| Global Round : 1 | Local Epoch : 4 | [9500/10237 (93%)]	Loss: 0.235091
| Global Round : 1 | Local Epoch : 4 | [9600/10237 (94%)]	Loss: 0.791134
| Global Round : 1 | Local Epoch : 4 | [9700/10237 (95%)]	Loss: 0.078878
| Global Round : 1 | Local Epoch : 4 | [9800/10237 (96%)]	Loss: 0.033793
| Global Round : 1 | Local Epoch : 4 | [9900/10237 (97%)]	Loss: 0.584227
| Global Round : 1 | Local Epoch : 4 | [10000/10237 (98%)]	Loss: 0.076239
| Global Round : 1 | Local Epoch : 4 | [10100/10237 (99%)]	Loss: 0.142190
| Global Round : 1 | Local Epoch : 4 | [10200/10237 (100%)]	Loss: 0.375993
----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.83      0.83        58
         DME       0.86      0.86      0.86        70

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.94      0.91        54
         DME       0.96      0.91      0.93        74

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.85      0.89        55
         DME       0.90      0.95      0.92        73

    accuracy                           0.91       128
   macro avg       0.91      0.90      0.90       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.92      0.86        64
         DME       0.91      0.77      0.83        64

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.90      0.90        61
         DME       0.91      0.91      0.91        67

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.75      0.92      0.83        50
         DME       0.94      0.81      0.87        78

    accuracy                           0.85       128
   macro avg       0.85      0.86      0.85       128
weighted avg       0.87      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.97      0.91        65
         DME       0.96      0.84      0.90        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.93      0.86        69
         DME       0.90      0.75      0.81        59

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.92      0.89        59
         DME       0.92      0.88      0.90        69

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.93      0.90        67
         DME       0.91      0.85      0.88        61

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.83      0.83      0.83        58
      DRUSEN       0.86      0.86      0.86        70

    accuracy                           0.84       128
   macro avg       0.84      0.84      0.84       128
weighted avg       0.84      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.94      0.91        54
      DRUSEN       0.96      0.91      0.93        74

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.85      0.89        55
      DRUSEN       0.90      0.95      0.92        73

    accuracy                           0.91       128
   macro avg       0.91      0.90      0.90       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.80      0.92      0.86        64
      DRUSEN       0.91      0.77      0.83        64

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.90      0.90        61
      DRUSEN       0.91      0.91      0.91        67

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.75      0.92      0.83        50
      DRUSEN       0.94      0.81      0.87        78

    accuracy                           0.85       128
   macro avg       0.85      0.86      0.85       128
weighted avg       0.87      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.97      0.91        65
      DRUSEN       0.96      0.84      0.90        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.81      0.93      0.86        69
      DRUSEN       0.90      0.75      0.81        59

    accuracy                           0.84       128
   macro avg       0.85      0.84      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.92      0.89        59
      DRUSEN       0.92      0.88      0.90        69

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.93      0.90        67
      DRUSEN       0.91      0.85      0.88        61

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

Training accuracy [0.8711943793911007, 0.88125]
 
Avg Training Stats after 2 global rounds:
Training Loss : 0.423883196509268
Train Accuracy: 88.12% 


 | Global Training Round : 3 |

----------------
user chosen 1
----------------
----------------
| Global Round : 2 | Local Epoch : 0 | [0/10242 (0%)]	Loss: 0.177903
| Global Round : 2 | Local Epoch : 0 | [100/10242 (1%)]	Loss: 0.258670
| Global Round : 2 | Local Epoch : 0 | [200/10242 (2%)]	Loss: 0.390257
| Global Round : 2 | Local Epoch : 0 | [300/10242 (3%)]	Loss: 0.559473
| Global Round : 2 | Local Epoch : 0 | [400/10242 (4%)]	Loss: 0.298563
| Global Round : 2 | Local Epoch : 0 | [500/10242 (5%)]	Loss: 0.649995
| Global Round : 2 | Local Epoch : 0 | [600/10242 (6%)]	Loss: 0.307676
| Global Round : 2 | Local Epoch : 0 | [700/10242 (7%)]	Loss: 0.503485
| Global Round : 2 | Local Epoch : 0 | [800/10242 (8%)]	Loss: 0.179912
| Global Round : 2 | Local Epoch : 0 | [900/10242 (9%)]	Loss: 0.492913
| Global Round : 2 | Local Epoch : 0 | [1000/10242 (10%)]	Loss: 0.436917
| Global Round : 2 | Local Epoch : 0 | [1100/10242 (11%)]	Loss: 0.194558
| Global Round : 2 | Local Epoch : 0 | [1200/10242 (12%)]	Loss: 0.744769
| Global Round : 2 | Local Epoch : 0 | [1300/10242 (13%)]	Loss: 0.180756
| Global Round : 2 | Local Epoch : 0 | [1400/10242 (14%)]	Loss: 0.377656
| Global Round : 2 | Local Epoch : 0 | [1500/10242 (15%)]	Loss: 0.427442
| Global Round : 2 | Local Epoch : 0 | [1600/10242 (16%)]	Loss: 1.160930
| Global Round : 2 | Local Epoch : 0 | [1700/10242 (17%)]	Loss: 0.124374
| Global Round : 2 | Local Epoch : 0 | [1800/10242 (18%)]	Loss: 0.205214
| Global Round : 2 | Local Epoch : 0 | [1900/10242 (19%)]	Loss: 0.105260
| Global Round : 2 | Local Epoch : 0 | [2000/10242 (20%)]	Loss: 0.151023
| Global Round : 2 | Local Epoch : 0 | [2100/10242 (20%)]	Loss: 0.352184
| Global Round : 2 | Local Epoch : 0 | [2200/10242 (21%)]	Loss: 0.363036
| Global Round : 2 | Local Epoch : 0 | [2300/10242 (22%)]	Loss: 0.154290
| Global Round : 2 | Local Epoch : 0 | [2400/10242 (23%)]	Loss: 0.679605
| Global Round : 2 | Local Epoch : 0 | [2500/10242 (24%)]	Loss: 0.379040
| Global Round : 2 | Local Epoch : 0 | [2600/10242 (25%)]	Loss: 0.131951
| Global Round : 2 | Local Epoch : 0 | [2700/10242 (26%)]	Loss: 0.276236
| Global Round : 2 | Local Epoch : 0 | [2800/10242 (27%)]	Loss: 0.120770
| Global Round : 2 | Local Epoch : 0 | [2900/10242 (28%)]	Loss: 0.341629
| Global Round : 2 | Local Epoch : 0 | [3000/10242 (29%)]	Loss: 0.154165
| Global Round : 2 | Local Epoch : 0 | [3100/10242 (30%)]	Loss: 0.267676
| Global Round : 2 | Local Epoch : 0 | [3200/10242 (31%)]	Loss: 0.611685
| Global Round : 2 | Local Epoch : 0 | [3300/10242 (32%)]	Loss: 0.179384
| Global Round : 2 | Local Epoch : 0 | [3400/10242 (33%)]	Loss: 0.159455
| Global Round : 2 | Local Epoch : 0 | [3500/10242 (34%)]	Loss: 0.269758
| Global Round : 2 | Local Epoch : 0 | [3600/10242 (35%)]	Loss: 0.345877
| Global Round : 2 | Local Epoch : 0 | [3700/10242 (36%)]	Loss: 0.139307
| Global Round : 2 | Local Epoch : 0 | [3800/10242 (37%)]	Loss: 0.353808
| Global Round : 2 | Local Epoch : 0 | [3900/10242 (38%)]	Loss: 0.073004
| Global Round : 2 | Local Epoch : 0 | [4000/10242 (39%)]	Loss: 0.333959
| Global Round : 2 | Local Epoch : 0 | [4100/10242 (40%)]	Loss: 0.303287
| Global Round : 2 | Local Epoch : 0 | [4200/10242 (41%)]	Loss: 0.335773
| Global Round : 2 | Local Epoch : 0 | [4300/10242 (42%)]	Loss: 0.508282
| Global Round : 2 | Local Epoch : 0 | [4400/10242 (43%)]	Loss: 0.058767
| Global Round : 2 | Local Epoch : 0 | [4500/10242 (44%)]	Loss: 0.271282
| Global Round : 2 | Local Epoch : 0 | [4600/10242 (45%)]	Loss: 0.245294
| Global Round : 2 | Local Epoch : 0 | [4700/10242 (46%)]	Loss: 0.096879
| Global Round : 2 | Local Epoch : 0 | [4800/10242 (47%)]	Loss: 0.300902
| Global Round : 2 | Local Epoch : 0 | [4900/10242 (48%)]	Loss: 0.483736
| Global Round : 2 | Local Epoch : 0 | [5000/10242 (49%)]	Loss: 0.149492
| Global Round : 2 | Local Epoch : 0 | [5100/10242 (50%)]	Loss: 0.198161
| Global Round : 2 | Local Epoch : 0 | [5200/10242 (51%)]	Loss: 0.154260
| Global Round : 2 | Local Epoch : 0 | [5300/10242 (52%)]	Loss: 0.233146
| Global Round : 2 | Local Epoch : 0 | [5400/10242 (53%)]	Loss: 0.197205
| Global Round : 2 | Local Epoch : 0 | [5500/10242 (54%)]	Loss: 0.191937
| Global Round : 2 | Local Epoch : 0 | [5600/10242 (55%)]	Loss: 0.446232
| Global Round : 2 | Local Epoch : 0 | [5700/10242 (56%)]	Loss: 0.115173
| Global Round : 2 | Local Epoch : 0 | [5800/10242 (57%)]	Loss: 0.069269
| Global Round : 2 | Local Epoch : 0 | [5900/10242 (58%)]	Loss: 0.328012
| Global Round : 2 | Local Epoch : 0 | [6000/10242 (59%)]	Loss: 0.401324
| Global Round : 2 | Local Epoch : 0 | [6100/10242 (60%)]	Loss: 1.116216
| Global Round : 2 | Local Epoch : 0 | [6200/10242 (60%)]	Loss: 0.250413
| Global Round : 2 | Local Epoch : 0 | [6300/10242 (61%)]	Loss: 0.065713
| Global Round : 2 | Local Epoch : 0 | [6400/10242 (62%)]	Loss: 0.253317
| Global Round : 2 | Local Epoch : 0 | [6500/10242 (63%)]	Loss: 0.405879
| Global Round : 2 | Local Epoch : 0 | [6600/10242 (64%)]	Loss: 0.056215
| Global Round : 2 | Local Epoch : 0 | [6700/10242 (65%)]	Loss: 0.062991
| Global Round : 2 | Local Epoch : 0 | [6800/10242 (66%)]	Loss: 0.079283
| Global Round : 2 | Local Epoch : 0 | [6900/10242 (67%)]	Loss: 0.890898
| Global Round : 2 | Local Epoch : 0 | [7000/10242 (68%)]	Loss: 0.232407
| Global Round : 2 | Local Epoch : 0 | [7100/10242 (69%)]	Loss: 0.231914
| Global Round : 2 | Local Epoch : 0 | [7200/10242 (70%)]	Loss: 0.166359
| Global Round : 2 | Local Epoch : 0 | [7300/10242 (71%)]	Loss: 0.148263
| Global Round : 2 | Local Epoch : 0 | [7400/10242 (72%)]	Loss: 0.228164
| Global Round : 2 | Local Epoch : 0 | [7500/10242 (73%)]	Loss: 0.421742
| Global Round : 2 | Local Epoch : 0 | [7600/10242 (74%)]	Loss: 0.363438
| Global Round : 2 | Local Epoch : 0 | [7700/10242 (75%)]	Loss: 0.342038
| Global Round : 2 | Local Epoch : 0 | [7800/10242 (76%)]	Loss: 0.337633
| Global Round : 2 | Local Epoch : 0 | [7900/10242 (77%)]	Loss: 0.203229
| Global Round : 2 | Local Epoch : 0 | [8000/10242 (78%)]	Loss: 0.653531
| Global Round : 2 | Local Epoch : 0 | [8100/10242 (79%)]	Loss: 0.294162
| Global Round : 2 | Local Epoch : 0 | [8200/10242 (80%)]	Loss: 0.430129
| Global Round : 2 | Local Epoch : 0 | [8300/10242 (81%)]	Loss: 0.577975
| Global Round : 2 | Local Epoch : 0 | [8400/10242 (82%)]	Loss: 0.176045
| Global Round : 2 | Local Epoch : 0 | [8500/10242 (83%)]	Loss: 0.191879
| Global Round : 2 | Local Epoch : 0 | [8600/10242 (84%)]	Loss: 0.266192
| Global Round : 2 | Local Epoch : 0 | [8700/10242 (85%)]	Loss: 0.106612
| Global Round : 2 | Local Epoch : 0 | [8800/10242 (86%)]	Loss: 0.063247
| Global Round : 2 | Local Epoch : 0 | [8900/10242 (87%)]	Loss: 0.460652
| Global Round : 2 | Local Epoch : 0 | [9000/10242 (88%)]	Loss: 0.177694
| Global Round : 2 | Local Epoch : 0 | [9100/10242 (89%)]	Loss: 0.452546
| Global Round : 2 | Local Epoch : 0 | [9200/10242 (90%)]	Loss: 0.174981
| Global Round : 2 | Local Epoch : 0 | [9300/10242 (91%)]	Loss: 0.303298
| Global Round : 2 | Local Epoch : 0 | [9400/10242 (92%)]	Loss: 0.281654
| Global Round : 2 | Local Epoch : 0 | [9500/10242 (93%)]	Loss: 0.310863
| Global Round : 2 | Local Epoch : 0 | [9600/10242 (94%)]	Loss: 0.364329
| Global Round : 2 | Local Epoch : 0 | [9700/10242 (95%)]	Loss: 0.353880
| Global Round : 2 | Local Epoch : 0 | [9800/10242 (96%)]	Loss: 0.375264
| Global Round : 2 | Local Epoch : 0 | [9900/10242 (97%)]	Loss: 0.279600
| Global Round : 2 | Local Epoch : 0 | [10000/10242 (98%)]	Loss: 0.104856
| Global Round : 2 | Local Epoch : 0 | [10100/10242 (99%)]	Loss: 0.437990
| Global Round : 2 | Local Epoch : 0 | [10200/10242 (100%)]	Loss: 0.213116
| Global Round : 2 | Local Epoch : 1 | [0/10242 (0%)]	Loss: 0.288750
| Global Round : 2 | Local Epoch : 1 | [100/10242 (1%)]	Loss: 0.211125
| Global Round : 2 | Local Epoch : 1 | [200/10242 (2%)]	Loss: 0.172715
| Global Round : 2 | Local Epoch : 1 | [300/10242 (3%)]	Loss: 0.378123
| Global Round : 2 | Local Epoch : 1 | [400/10242 (4%)]	Loss: 0.156307
| Global Round : 2 | Local Epoch : 1 | [500/10242 (5%)]	Loss: 0.213645
| Global Round : 2 | Local Epoch : 1 | [600/10242 (6%)]	Loss: 0.081968
| Global Round : 2 | Local Epoch : 1 | [700/10242 (7%)]	Loss: 0.397122
| Global Round : 2 | Local Epoch : 1 | [800/10242 (8%)]	Loss: 0.139996
| Global Round : 2 | Local Epoch : 1 | [900/10242 (9%)]	Loss: 0.077299
| Global Round : 2 | Local Epoch : 1 | [1000/10242 (10%)]	Loss: 0.348414
| Global Round : 2 | Local Epoch : 1 | [1100/10242 (11%)]	Loss: 0.293461
| Global Round : 2 | Local Epoch : 1 | [1200/10242 (12%)]	Loss: 0.106393
| Global Round : 2 | Local Epoch : 1 | [1300/10242 (13%)]	Loss: 0.590646
| Global Round : 2 | Local Epoch : 1 | [1400/10242 (14%)]	Loss: 0.253530
| Global Round : 2 | Local Epoch : 1 | [1500/10242 (15%)]	Loss: 0.254253
| Global Round : 2 | Local Epoch : 1 | [1600/10242 (16%)]	Loss: 0.151093
| Global Round : 2 | Local Epoch : 1 | [1700/10242 (17%)]	Loss: 0.387484
| Global Round : 2 | Local Epoch : 1 | [1800/10242 (18%)]	Loss: 0.105534
| Global Round : 2 | Local Epoch : 1 | [1900/10242 (19%)]	Loss: 0.358064
| Global Round : 2 | Local Epoch : 1 | [2000/10242 (20%)]	Loss: 0.070896
| Global Round : 2 | Local Epoch : 1 | [2100/10242 (20%)]	Loss: 0.249615
| Global Round : 2 | Local Epoch : 1 | [2200/10242 (21%)]	Loss: 0.152655
| Global Round : 2 | Local Epoch : 1 | [2300/10242 (22%)]	Loss: 0.257725
| Global Round : 2 | Local Epoch : 1 | [2400/10242 (23%)]	Loss: 0.104798
| Global Round : 2 | Local Epoch : 1 | [2500/10242 (24%)]	Loss: 0.394586
| Global Round : 2 | Local Epoch : 1 | [2600/10242 (25%)]	Loss: 0.182597
| Global Round : 2 | Local Epoch : 1 | [2700/10242 (26%)]	Loss: 0.107858
| Global Round : 2 | Local Epoch : 1 | [2800/10242 (27%)]	Loss: 1.116143
| Global Round : 2 | Local Epoch : 1 | [2900/10242 (28%)]	Loss: 0.189451
| Global Round : 2 | Local Epoch : 1 | [3000/10242 (29%)]	Loss: 0.383156
| Global Round : 2 | Local Epoch : 1 | [3100/10242 (30%)]	Loss: 0.078210
| Global Round : 2 | Local Epoch : 1 | [3200/10242 (31%)]	Loss: 0.369231
| Global Round : 2 | Local Epoch : 1 | [3300/10242 (32%)]	Loss: 0.219360
| Global Round : 2 | Local Epoch : 1 | [3400/10242 (33%)]	Loss: 0.358701
| Global Round : 2 | Local Epoch : 1 | [3500/10242 (34%)]	Loss: 0.284741
| Global Round : 2 | Local Epoch : 1 | [3600/10242 (35%)]	Loss: 0.464932
| Global Round : 2 | Local Epoch : 1 | [3700/10242 (36%)]	Loss: 0.299584
| Global Round : 2 | Local Epoch : 1 | [3800/10242 (37%)]	Loss: 0.348978
| Global Round : 2 | Local Epoch : 1 | [3900/10242 (38%)]	Loss: 0.239731
| Global Round : 2 | Local Epoch : 1 | [4000/10242 (39%)]	Loss: 0.107761
| Global Round : 2 | Local Epoch : 1 | [4100/10242 (40%)]	Loss: 0.112782
| Global Round : 2 | Local Epoch : 1 | [4200/10242 (41%)]	Loss: 0.497711
| Global Round : 2 | Local Epoch : 1 | [4300/10242 (42%)]	Loss: 0.042125
| Global Round : 2 | Local Epoch : 1 | [4400/10242 (43%)]	Loss: 0.083141
| Global Round : 2 | Local Epoch : 1 | [4500/10242 (44%)]	Loss: 0.304243
| Global Round : 2 | Local Epoch : 1 | [4600/10242 (45%)]	Loss: 0.098407
| Global Round : 2 | Local Epoch : 1 | [4700/10242 (46%)]	Loss: 0.025515
| Global Round : 2 | Local Epoch : 1 | [4800/10242 (47%)]	Loss: 0.136423
| Global Round : 2 | Local Epoch : 1 | [4900/10242 (48%)]	Loss: 0.226754
| Global Round : 2 | Local Epoch : 1 | [5000/10242 (49%)]	Loss: 0.179352
| Global Round : 2 | Local Epoch : 1 | [5100/10242 (50%)]	Loss: 0.309482
| Global Round : 2 | Local Epoch : 1 | [5200/10242 (51%)]	Loss: 0.280453
| Global Round : 2 | Local Epoch : 1 | [5300/10242 (52%)]	Loss: 0.234845
| Global Round : 2 | Local Epoch : 1 | [5400/10242 (53%)]	Loss: 0.144761
| Global Round : 2 | Local Epoch : 1 | [5500/10242 (54%)]	Loss: 0.227157
| Global Round : 2 | Local Epoch : 1 | [5600/10242 (55%)]	Loss: 0.169220
| Global Round : 2 | Local Epoch : 1 | [5700/10242 (56%)]	Loss: 0.369317
| Global Round : 2 | Local Epoch : 1 | [5800/10242 (57%)]	Loss: 0.155612
| Global Round : 2 | Local Epoch : 1 | [5900/10242 (58%)]	Loss: 0.090834
| Global Round : 2 | Local Epoch : 1 | [6000/10242 (59%)]	Loss: 0.420773
| Global Round : 2 | Local Epoch : 1 | [6100/10242 (60%)]	Loss: 0.215704
| Global Round : 2 | Local Epoch : 1 | [6200/10242 (60%)]	Loss: 0.287167
| Global Round : 2 | Local Epoch : 1 | [6300/10242 (61%)]	Loss: 0.128058
| Global Round : 2 | Local Epoch : 1 | [6400/10242 (62%)]	Loss: 0.076939
| Global Round : 2 | Local Epoch : 1 | [6500/10242 (63%)]	Loss: 0.235691
| Global Round : 2 | Local Epoch : 1 | [6600/10242 (64%)]	Loss: 0.180456
| Global Round : 2 | Local Epoch : 1 | [6700/10242 (65%)]	Loss: 0.157570
| Global Round : 2 | Local Epoch : 1 | [6800/10242 (66%)]	Loss: 0.200144
| Global Round : 2 | Local Epoch : 1 | [6900/10242 (67%)]	Loss: 0.279395
| Global Round : 2 | Local Epoch : 1 | [7000/10242 (68%)]	Loss: 0.335414
| Global Round : 2 | Local Epoch : 1 | [7100/10242 (69%)]	Loss: 0.251395
| Global Round : 2 | Local Epoch : 1 | [7200/10242 (70%)]	Loss: 0.279710
| Global Round : 2 | Local Epoch : 1 | [7300/10242 (71%)]	Loss: 0.064745
| Global Round : 2 | Local Epoch : 1 | [7400/10242 (72%)]	Loss: 0.220755
| Global Round : 2 | Local Epoch : 1 | [7500/10242 (73%)]	Loss: 0.221633
| Global Round : 2 | Local Epoch : 1 | [7600/10242 (74%)]	Loss: 0.212984
| Global Round : 2 | Local Epoch : 1 | [7700/10242 (75%)]	Loss: 0.067862
| Global Round : 2 | Local Epoch : 1 | [7800/10242 (76%)]	Loss: 0.188156
| Global Round : 2 | Local Epoch : 1 | [7900/10242 (77%)]	Loss: 0.113534
| Global Round : 2 | Local Epoch : 1 | [8000/10242 (78%)]	Loss: 0.268197
| Global Round : 2 | Local Epoch : 1 | [8100/10242 (79%)]	Loss: 0.316339
| Global Round : 2 | Local Epoch : 1 | [8200/10242 (80%)]	Loss: 0.459568
| Global Round : 2 | Local Epoch : 1 | [8300/10242 (81%)]	Loss: 0.173986
| Global Round : 2 | Local Epoch : 1 | [8400/10242 (82%)]	Loss: 0.205472
| Global Round : 2 | Local Epoch : 1 | [8500/10242 (83%)]	Loss: 0.174240
| Global Round : 2 | Local Epoch : 1 | [8600/10242 (84%)]	Loss: 0.640119
| Global Round : 2 | Local Epoch : 1 | [8700/10242 (85%)]	Loss: 0.387889
| Global Round : 2 | Local Epoch : 1 | [8800/10242 (86%)]	Loss: 0.141842
| Global Round : 2 | Local Epoch : 1 | [8900/10242 (87%)]	Loss: 0.684283
| Global Round : 2 | Local Epoch : 1 | [9000/10242 (88%)]	Loss: 0.037985
| Global Round : 2 | Local Epoch : 1 | [9100/10242 (89%)]	Loss: 0.057689
| Global Round : 2 | Local Epoch : 1 | [9200/10242 (90%)]	Loss: 0.253772
| Global Round : 2 | Local Epoch : 1 | [9300/10242 (91%)]	Loss: 0.188293
| Global Round : 2 | Local Epoch : 1 | [9400/10242 (92%)]	Loss: 0.143007
| Global Round : 2 | Local Epoch : 1 | [9500/10242 (93%)]	Loss: 0.109236
| Global Round : 2 | Local Epoch : 1 | [9600/10242 (94%)]	Loss: 0.533097
| Global Round : 2 | Local Epoch : 1 | [9700/10242 (95%)]	Loss: 0.102483
| Global Round : 2 | Local Epoch : 1 | [9800/10242 (96%)]	Loss: 0.082844
| Global Round : 2 | Local Epoch : 1 | [9900/10242 (97%)]	Loss: 0.326432
| Global Round : 2 | Local Epoch : 1 | [10000/10242 (98%)]	Loss: 0.197925
| Global Round : 2 | Local Epoch : 1 | [10100/10242 (99%)]	Loss: 0.153892
| Global Round : 2 | Local Epoch : 1 | [10200/10242 (100%)]	Loss: 0.148115
| Global Round : 2 | Local Epoch : 2 | [0/10242 (0%)]	Loss: 0.206558
| Global Round : 2 | Local Epoch : 2 | [100/10242 (1%)]	Loss: 0.083468
| Global Round : 2 | Local Epoch : 2 | [200/10242 (2%)]	Loss: 0.257829
| Global Round : 2 | Local Epoch : 2 | [300/10242 (3%)]	Loss: 0.399858
| Global Round : 2 | Local Epoch : 2 | [400/10242 (4%)]	Loss: 0.262982
| Global Round : 2 | Local Epoch : 2 | [500/10242 (5%)]	Loss: 0.299100
| Global Round : 2 | Local Epoch : 2 | [600/10242 (6%)]	Loss: 0.137828
| Global Round : 2 | Local Epoch : 2 | [700/10242 (7%)]	Loss: 0.066975
| Global Round : 2 | Local Epoch : 2 | [800/10242 (8%)]	Loss: 0.109608
| Global Round : 2 | Local Epoch : 2 | [900/10242 (9%)]	Loss: 0.256413
| Global Round : 2 | Local Epoch : 2 | [1000/10242 (10%)]	Loss: 0.151810
| Global Round : 2 | Local Epoch : 2 | [1100/10242 (11%)]	Loss: 0.115822
| Global Round : 2 | Local Epoch : 2 | [1200/10242 (12%)]	Loss: 0.107117
| Global Round : 2 | Local Epoch : 2 | [1300/10242 (13%)]	Loss: 0.082555
| Global Round : 2 | Local Epoch : 2 | [1400/10242 (14%)]	Loss: 0.245554
| Global Round : 2 | Local Epoch : 2 | [1500/10242 (15%)]	Loss: 0.292287
| Global Round : 2 | Local Epoch : 2 | [1600/10242 (16%)]	Loss: 0.193705
| Global Round : 2 | Local Epoch : 2 | [1700/10242 (17%)]	Loss: 0.241285
| Global Round : 2 | Local Epoch : 2 | [1800/10242 (18%)]	Loss: 0.200275
| Global Round : 2 | Local Epoch : 2 | [1900/10242 (19%)]	Loss: 0.085026
| Global Round : 2 | Local Epoch : 2 | [2000/10242 (20%)]	Loss: 0.212246
| Global Round : 2 | Local Epoch : 2 | [2100/10242 (20%)]	Loss: 0.472902
| Global Round : 2 | Local Epoch : 2 | [2200/10242 (21%)]	Loss: 0.472817
| Global Round : 2 | Local Epoch : 2 | [2300/10242 (22%)]	Loss: 0.373038
| Global Round : 2 | Local Epoch : 2 | [2400/10242 (23%)]	Loss: 0.432684
| Global Round : 2 | Local Epoch : 2 | [2500/10242 (24%)]	Loss: 0.103692
| Global Round : 2 | Local Epoch : 2 | [2600/10242 (25%)]	Loss: 0.375699
| Global Round : 2 | Local Epoch : 2 | [2700/10242 (26%)]	Loss: 0.131212
| Global Round : 2 | Local Epoch : 2 | [2800/10242 (27%)]	Loss: 0.107353
| Global Round : 2 | Local Epoch : 2 | [2900/10242 (28%)]	Loss: 0.107187
| Global Round : 2 | Local Epoch : 2 | [3000/10242 (29%)]	Loss: 0.201993
| Global Round : 2 | Local Epoch : 2 | [3100/10242 (30%)]	Loss: 0.235278
| Global Round : 2 | Local Epoch : 2 | [3200/10242 (31%)]	Loss: 0.420877
| Global Round : 2 | Local Epoch : 2 | [3300/10242 (32%)]	Loss: 0.212419
| Global Round : 2 | Local Epoch : 2 | [3400/10242 (33%)]	Loss: 0.407067
| Global Round : 2 | Local Epoch : 2 | [3500/10242 (34%)]	Loss: 0.070735
| Global Round : 2 | Local Epoch : 2 | [3600/10242 (35%)]	Loss: 0.180801
| Global Round : 2 | Local Epoch : 2 | [3700/10242 (36%)]	Loss: 0.073098
| Global Round : 2 | Local Epoch : 2 | [3800/10242 (37%)]	Loss: 0.047298
| Global Round : 2 | Local Epoch : 2 | [3900/10242 (38%)]	Loss: 0.099897
| Global Round : 2 | Local Epoch : 2 | [4000/10242 (39%)]	Loss: 0.171485
| Global Round : 2 | Local Epoch : 2 | [4100/10242 (40%)]	Loss: 0.361995
| Global Round : 2 | Local Epoch : 2 | [4200/10242 (41%)]	Loss: 0.202992
| Global Round : 2 | Local Epoch : 2 | [4300/10242 (42%)]	Loss: 0.157828
| Global Round : 2 | Local Epoch : 2 | [4400/10242 (43%)]	Loss: 0.114954
| Global Round : 2 | Local Epoch : 2 | [4500/10242 (44%)]	Loss: 0.236893
| Global Round : 2 | Local Epoch : 2 | [4600/10242 (45%)]	Loss: 0.075604
| Global Round : 2 | Local Epoch : 2 | [4700/10242 (46%)]	Loss: 0.272069
| Global Round : 2 | Local Epoch : 2 | [4800/10242 (47%)]	Loss: 0.177043
| Global Round : 2 | Local Epoch : 2 | [4900/10242 (48%)]	Loss: 0.203387
| Global Round : 2 | Local Epoch : 2 | [5000/10242 (49%)]	Loss: 0.134479
| Global Round : 2 | Local Epoch : 2 | [5100/10242 (50%)]	Loss: 0.317662
| Global Round : 2 | Local Epoch : 2 | [5200/10242 (51%)]	Loss: 0.443097
| Global Round : 2 | Local Epoch : 2 | [5300/10242 (52%)]	Loss: 0.358190
| Global Round : 2 | Local Epoch : 2 | [5400/10242 (53%)]	Loss: 0.475091
| Global Round : 2 | Local Epoch : 2 | [5500/10242 (54%)]	Loss: 0.066060
| Global Round : 2 | Local Epoch : 2 | [5600/10242 (55%)]	Loss: 0.189989
| Global Round : 2 | Local Epoch : 2 | [5700/10242 (56%)]	Loss: 0.154609
| Global Round : 2 | Local Epoch : 2 | [5800/10242 (57%)]	Loss: 0.342222
| Global Round : 2 | Local Epoch : 2 | [5900/10242 (58%)]	Loss: 0.150810
| Global Round : 2 | Local Epoch : 2 | [6000/10242 (59%)]	Loss: 0.244824
| Global Round : 2 | Local Epoch : 2 | [6100/10242 (60%)]	Loss: 0.131746
| Global Round : 2 | Local Epoch : 2 | [6200/10242 (60%)]	Loss: 0.391596
| Global Round : 2 | Local Epoch : 2 | [6300/10242 (61%)]	Loss: 0.457639
| Global Round : 2 | Local Epoch : 2 | [6400/10242 (62%)]	Loss: 0.236287
| Global Round : 2 | Local Epoch : 2 | [6500/10242 (63%)]	Loss: 0.313216
| Global Round : 2 | Local Epoch : 2 | [6600/10242 (64%)]	Loss: 0.147615
| Global Round : 2 | Local Epoch : 2 | [6700/10242 (65%)]	Loss: 0.127576
| Global Round : 2 | Local Epoch : 2 | [6800/10242 (66%)]	Loss: 0.392926
| Global Round : 2 | Local Epoch : 2 | [6900/10242 (67%)]	Loss: 0.388839
| Global Round : 2 | Local Epoch : 2 | [7000/10242 (68%)]	Loss: 0.396209
| Global Round : 2 | Local Epoch : 2 | [7100/10242 (69%)]	Loss: 0.239934
| Global Round : 2 | Local Epoch : 2 | [7200/10242 (70%)]	Loss: 0.355371
| Global Round : 2 | Local Epoch : 2 | [7300/10242 (71%)]	Loss: 0.270993
| Global Round : 2 | Local Epoch : 2 | [7400/10242 (72%)]	Loss: 0.283939
| Global Round : 2 | Local Epoch : 2 | [7500/10242 (73%)]	Loss: 0.200110
| Global Round : 2 | Local Epoch : 2 | [7600/10242 (74%)]	Loss: 0.113392
| Global Round : 2 | Local Epoch : 2 | [7700/10242 (75%)]	Loss: 0.185352
| Global Round : 2 | Local Epoch : 2 | [7800/10242 (76%)]	Loss: 0.297445
| Global Round : 2 | Local Epoch : 2 | [7900/10242 (77%)]	Loss: 0.131835
| Global Round : 2 | Local Epoch : 2 | [8000/10242 (78%)]	Loss: 0.248647
| Global Round : 2 | Local Epoch : 2 | [8100/10242 (79%)]	Loss: 0.422323
| Global Round : 2 | Local Epoch : 2 | [8200/10242 (80%)]	Loss: 0.454684
| Global Round : 2 | Local Epoch : 2 | [8300/10242 (81%)]	Loss: 0.185603
| Global Round : 2 | Local Epoch : 2 | [8400/10242 (82%)]	Loss: 0.266474
| Global Round : 2 | Local Epoch : 2 | [8500/10242 (83%)]	Loss: 0.189280
| Global Round : 2 | Local Epoch : 2 | [8600/10242 (84%)]	Loss: 0.218029
| Global Round : 2 | Local Epoch : 2 | [8700/10242 (85%)]	Loss: 0.517599
| Global Round : 2 | Local Epoch : 2 | [8800/10242 (86%)]	Loss: 0.130182
| Global Round : 2 | Local Epoch : 2 | [8900/10242 (87%)]	Loss: 0.327741
| Global Round : 2 | Local Epoch : 2 | [9000/10242 (88%)]	Loss: 0.497399
| Global Round : 2 | Local Epoch : 2 | [9100/10242 (89%)]	Loss: 0.229373
| Global Round : 2 | Local Epoch : 2 | [9200/10242 (90%)]	Loss: 0.081417
| Global Round : 2 | Local Epoch : 2 | [9300/10242 (91%)]	Loss: 0.234902
| Global Round : 2 | Local Epoch : 2 | [9400/10242 (92%)]	Loss: 0.110427
| Global Round : 2 | Local Epoch : 2 | [9500/10242 (93%)]	Loss: 0.068682
| Global Round : 2 | Local Epoch : 2 | [9600/10242 (94%)]	Loss: 0.150048
| Global Round : 2 | Local Epoch : 2 | [9700/10242 (95%)]	Loss: 0.060560
| Global Round : 2 | Local Epoch : 2 | [9800/10242 (96%)]	Loss: 0.082052
| Global Round : 2 | Local Epoch : 2 | [9900/10242 (97%)]	Loss: 0.159708
| Global Round : 2 | Local Epoch : 2 | [10000/10242 (98%)]	Loss: 0.158903
| Global Round : 2 | Local Epoch : 2 | [10100/10242 (99%)]	Loss: 0.136088
| Global Round : 2 | Local Epoch : 2 | [10200/10242 (100%)]	Loss: 0.283344
| Global Round : 2 | Local Epoch : 3 | [0/10242 (0%)]	Loss: 2.109521
| Global Round : 2 | Local Epoch : 3 | [100/10242 (1%)]	Loss: 0.396496
| Global Round : 2 | Local Epoch : 3 | [200/10242 (2%)]	Loss: 0.607686
| Global Round : 2 | Local Epoch : 3 | [300/10242 (3%)]	Loss: 0.231138
| Global Round : 2 | Local Epoch : 3 | [400/10242 (4%)]	Loss: 0.326020
| Global Round : 2 | Local Epoch : 3 | [500/10242 (5%)]	Loss: 0.210586
| Global Round : 2 | Local Epoch : 3 | [600/10242 (6%)]	Loss: 0.179595
| Global Round : 2 | Local Epoch : 3 | [700/10242 (7%)]	Loss: 0.356173
| Global Round : 2 | Local Epoch : 3 | [800/10242 (8%)]	Loss: 0.165999
| Global Round : 2 | Local Epoch : 3 | [900/10242 (9%)]	Loss: 0.675250
| Global Round : 2 | Local Epoch : 3 | [1000/10242 (10%)]	Loss: 0.326034
| Global Round : 2 | Local Epoch : 3 | [1100/10242 (11%)]	Loss: 0.131929
| Global Round : 2 | Local Epoch : 3 | [1200/10242 (12%)]	Loss: 0.556443
| Global Round : 2 | Local Epoch : 3 | [1300/10242 (13%)]	Loss: 0.119242
| Global Round : 2 | Local Epoch : 3 | [1400/10242 (14%)]	Loss: 0.029811
| Global Round : 2 | Local Epoch : 3 | [1500/10242 (15%)]	Loss: 0.041648
| Global Round : 2 | Local Epoch : 3 | [1600/10242 (16%)]	Loss: 0.218985
| Global Round : 2 | Local Epoch : 3 | [1700/10242 (17%)]	Loss: 0.228799
| Global Round : 2 | Local Epoch : 3 | [1800/10242 (18%)]	Loss: 0.311076
| Global Round : 2 | Local Epoch : 3 | [1900/10242 (19%)]	Loss: 0.252070
| Global Round : 2 | Local Epoch : 3 | [2000/10242 (20%)]	Loss: 0.077058
| Global Round : 2 | Local Epoch : 3 | [2100/10242 (20%)]	Loss: 0.120418
| Global Round : 2 | Local Epoch : 3 | [2200/10242 (21%)]	Loss: 0.170994
| Global Round : 2 | Local Epoch : 3 | [2300/10242 (22%)]	Loss: 0.431596
| Global Round : 2 | Local Epoch : 3 | [2400/10242 (23%)]	Loss: 0.435822
| Global Round : 2 | Local Epoch : 3 | [2500/10242 (24%)]	Loss: 0.065552
| Global Round : 2 | Local Epoch : 3 | [2600/10242 (25%)]	Loss: 0.036393
| Global Round : 2 | Local Epoch : 3 | [2700/10242 (26%)]	Loss: 0.022272
| Global Round : 2 | Local Epoch : 3 | [2800/10242 (27%)]	Loss: 0.303746
| Global Round : 2 | Local Epoch : 3 | [2900/10242 (28%)]	Loss: 0.256953
| Global Round : 2 | Local Epoch : 3 | [3000/10242 (29%)]	Loss: 0.087123
| Global Round : 2 | Local Epoch : 3 | [3100/10242 (30%)]	Loss: 0.216493
| Global Round : 2 | Local Epoch : 3 | [3200/10242 (31%)]	Loss: 0.196453
| Global Round : 2 | Local Epoch : 3 | [3300/10242 (32%)]	Loss: 0.188525
| Global Round : 2 | Local Epoch : 3 | [3400/10242 (33%)]	Loss: 0.168976
| Global Round : 2 | Local Epoch : 3 | [3500/10242 (34%)]	Loss: 0.187815
| Global Round : 2 | Local Epoch : 3 | [3600/10242 (35%)]	Loss: 0.016583
| Global Round : 2 | Local Epoch : 3 | [3700/10242 (36%)]	Loss: 0.087230
| Global Round : 2 | Local Epoch : 3 | [3800/10242 (37%)]	Loss: 0.015347
| Global Round : 2 | Local Epoch : 3 | [3900/10242 (38%)]	Loss: 0.767950
| Global Round : 2 | Local Epoch : 3 | [4000/10242 (39%)]	Loss: 0.346199
| Global Round : 2 | Local Epoch : 3 | [4100/10242 (40%)]	Loss: 0.112468
| Global Round : 2 | Local Epoch : 3 | [4200/10242 (41%)]	Loss: 0.103282
| Global Round : 2 | Local Epoch : 3 | [4300/10242 (42%)]	Loss: 0.123153
| Global Round : 2 | Local Epoch : 3 | [4400/10242 (43%)]	Loss: 0.168276
| Global Round : 2 | Local Epoch : 3 | [4500/10242 (44%)]	Loss: 0.121434
| Global Round : 2 | Local Epoch : 3 | [4600/10242 (45%)]	Loss: 0.152866
| Global Round : 2 | Local Epoch : 3 | [4700/10242 (46%)]	Loss: 0.275744
| Global Round : 2 | Local Epoch : 3 | [4800/10242 (47%)]	Loss: 0.144345
| Global Round : 2 | Local Epoch : 3 | [4900/10242 (48%)]	Loss: 0.429785
| Global Round : 2 | Local Epoch : 3 | [5000/10242 (49%)]	Loss: 0.280619
| Global Round : 2 | Local Epoch : 3 | [5100/10242 (50%)]	Loss: 0.099092
| Global Round : 2 | Local Epoch : 3 | [5200/10242 (51%)]	Loss: 0.161236
| Global Round : 2 | Local Epoch : 3 | [5300/10242 (52%)]	Loss: 0.125144
| Global Round : 2 | Local Epoch : 3 | [5400/10242 (53%)]	Loss: 0.310255
| Global Round : 2 | Local Epoch : 3 | [5500/10242 (54%)]	Loss: 0.068683
| Global Round : 2 | Local Epoch : 3 | [5600/10242 (55%)]	Loss: 0.114823
| Global Round : 2 | Local Epoch : 3 | [5700/10242 (56%)]	Loss: 0.143869
| Global Round : 2 | Local Epoch : 3 | [5800/10242 (57%)]	Loss: 0.179405
| Global Round : 2 | Local Epoch : 3 | [5900/10242 (58%)]	Loss: 0.368444
| Global Round : 2 | Local Epoch : 3 | [6000/10242 (59%)]	Loss: 0.077263
| Global Round : 2 | Local Epoch : 3 | [6100/10242 (60%)]	Loss: 0.177953
| Global Round : 2 | Local Epoch : 3 | [6200/10242 (60%)]	Loss: 0.304897
| Global Round : 2 | Local Epoch : 3 | [6300/10242 (61%)]	Loss: 0.094002
| Global Round : 2 | Local Epoch : 3 | [6400/10242 (62%)]	Loss: 0.254497
| Global Round : 2 | Local Epoch : 3 | [6500/10242 (63%)]	Loss: 0.113706
| Global Round : 2 | Local Epoch : 3 | [6600/10242 (64%)]	Loss: 0.156558
| Global Round : 2 | Local Epoch : 3 | [6700/10242 (65%)]	Loss: 0.053834
| Global Round : 2 | Local Epoch : 3 | [6800/10242 (66%)]	Loss: 0.349626
| Global Round : 2 | Local Epoch : 3 | [6900/10242 (67%)]	Loss: 0.081186
| Global Round : 2 | Local Epoch : 3 | [7000/10242 (68%)]	Loss: 0.175096
| Global Round : 2 | Local Epoch : 3 | [7100/10242 (69%)]	Loss: 0.110923
| Global Round : 2 | Local Epoch : 3 | [7200/10242 (70%)]	Loss: 0.101235
| Global Round : 2 | Local Epoch : 3 | [7300/10242 (71%)]	Loss: 0.347666
| Global Round : 2 | Local Epoch : 3 | [7400/10242 (72%)]	Loss: 0.275506
| Global Round : 2 | Local Epoch : 3 | [7500/10242 (73%)]	Loss: 0.092835
| Global Round : 2 | Local Epoch : 3 | [7600/10242 (74%)]	Loss: 0.404578
| Global Round : 2 | Local Epoch : 3 | [7700/10242 (75%)]	Loss: 0.631785
| Global Round : 2 | Local Epoch : 3 | [7800/10242 (76%)]	Loss: 0.068158
| Global Round : 2 | Local Epoch : 3 | [7900/10242 (77%)]	Loss: 0.153279
| Global Round : 2 | Local Epoch : 3 | [8000/10242 (78%)]	Loss: 0.241127
| Global Round : 2 | Local Epoch : 3 | [8100/10242 (79%)]	Loss: 0.171463
| Global Round : 2 | Local Epoch : 3 | [8200/10242 (80%)]	Loss: 0.126792
| Global Round : 2 | Local Epoch : 3 | [8300/10242 (81%)]	Loss: 0.077492
| Global Round : 2 | Local Epoch : 3 | [8400/10242 (82%)]	Loss: 0.022630
| Global Round : 2 | Local Epoch : 3 | [8500/10242 (83%)]	Loss: 0.055138
| Global Round : 2 | Local Epoch : 3 | [8600/10242 (84%)]	Loss: 0.628731
| Global Round : 2 | Local Epoch : 3 | [8700/10242 (85%)]	Loss: 0.411328
| Global Round : 2 | Local Epoch : 3 | [8800/10242 (86%)]	Loss: 0.158100
| Global Round : 2 | Local Epoch : 3 | [8900/10242 (87%)]	Loss: 0.012893
| Global Round : 2 | Local Epoch : 3 | [9000/10242 (88%)]	Loss: 0.273585
| Global Round : 2 | Local Epoch : 3 | [9100/10242 (89%)]	Loss: 0.103181
| Global Round : 2 | Local Epoch : 3 | [9200/10242 (90%)]	Loss: 0.151055
| Global Round : 2 | Local Epoch : 3 | [9300/10242 (91%)]	Loss: 0.127795
| Global Round : 2 | Local Epoch : 3 | [9400/10242 (92%)]	Loss: 0.029859
| Global Round : 2 | Local Epoch : 3 | [9500/10242 (93%)]	Loss: 0.063832
| Global Round : 2 | Local Epoch : 3 | [9600/10242 (94%)]	Loss: 0.028711
| Global Round : 2 | Local Epoch : 3 | [9700/10242 (95%)]	Loss: 0.055045
| Global Round : 2 | Local Epoch : 3 | [9800/10242 (96%)]	Loss: 0.196572
| Global Round : 2 | Local Epoch : 3 | [9900/10242 (97%)]	Loss: 0.406298
| Global Round : 2 | Local Epoch : 3 | [10000/10242 (98%)]	Loss: 0.058667
| Global Round : 2 | Local Epoch : 3 | [10100/10242 (99%)]	Loss: 0.045286
| Global Round : 2 | Local Epoch : 3 | [10200/10242 (100%)]	Loss: 0.032428
| Global Round : 2 | Local Epoch : 4 | [0/10242 (0%)]	Loss: 0.090282
| Global Round : 2 | Local Epoch : 4 | [100/10242 (1%)]	Loss: 0.044839
| Global Round : 2 | Local Epoch : 4 | [200/10242 (2%)]	Loss: 0.237579
| Global Round : 2 | Local Epoch : 4 | [300/10242 (3%)]	Loss: 0.266338
| Global Round : 2 | Local Epoch : 4 | [400/10242 (4%)]	Loss: 0.161725
| Global Round : 2 | Local Epoch : 4 | [500/10242 (5%)]	Loss: 0.161239
| Global Round : 2 | Local Epoch : 4 | [600/10242 (6%)]	Loss: 0.109902
| Global Round : 2 | Local Epoch : 4 | [700/10242 (7%)]	Loss: 0.112319
| Global Round : 2 | Local Epoch : 4 | [800/10242 (8%)]	Loss: 0.095126
| Global Round : 2 | Local Epoch : 4 | [900/10242 (9%)]	Loss: 0.514722
| Global Round : 2 | Local Epoch : 4 | [1000/10242 (10%)]	Loss: 0.058088
| Global Round : 2 | Local Epoch : 4 | [1100/10242 (11%)]	Loss: 0.125555
| Global Round : 2 | Local Epoch : 4 | [1200/10242 (12%)]	Loss: 0.145380
| Global Round : 2 | Local Epoch : 4 | [1300/10242 (13%)]	Loss: 0.039722
| Global Round : 2 | Local Epoch : 4 | [1400/10242 (14%)]	Loss: 0.175795
| Global Round : 2 | Local Epoch : 4 | [1500/10242 (15%)]	Loss: 0.426376
| Global Round : 2 | Local Epoch : 4 | [1600/10242 (16%)]	Loss: 0.192804
| Global Round : 2 | Local Epoch : 4 | [1700/10242 (17%)]	Loss: 0.380502
| Global Round : 2 | Local Epoch : 4 | [1800/10242 (18%)]	Loss: 0.019098
| Global Round : 2 | Local Epoch : 4 | [1900/10242 (19%)]	Loss: 0.162450
| Global Round : 2 | Local Epoch : 4 | [2000/10242 (20%)]	Loss: 0.170605
| Global Round : 2 | Local Epoch : 4 | [2100/10242 (20%)]	Loss: 0.088164
| Global Round : 2 | Local Epoch : 4 | [2200/10242 (21%)]	Loss: 0.224967
| Global Round : 2 | Local Epoch : 4 | [2300/10242 (22%)]	Loss: 0.230381
| Global Round : 2 | Local Epoch : 4 | [2400/10242 (23%)]	Loss: 0.095751
| Global Round : 2 | Local Epoch : 4 | [2500/10242 (24%)]	Loss: 0.423698
| Global Round : 2 | Local Epoch : 4 | [2600/10242 (25%)]	Loss: 0.138495
| Global Round : 2 | Local Epoch : 4 | [2700/10242 (26%)]	Loss: 0.025054
| Global Round : 2 | Local Epoch : 4 | [2800/10242 (27%)]	Loss: 0.062116
| Global Round : 2 | Local Epoch : 4 | [2900/10242 (28%)]	Loss: 0.089356
| Global Round : 2 | Local Epoch : 4 | [3000/10242 (29%)]	Loss: 0.202354
| Global Round : 2 | Local Epoch : 4 | [3100/10242 (30%)]	Loss: 0.330662
| Global Round : 2 | Local Epoch : 4 | [3200/10242 (31%)]	Loss: 0.173146
| Global Round : 2 | Local Epoch : 4 | [3300/10242 (32%)]	Loss: 0.106632
| Global Round : 2 | Local Epoch : 4 | [3400/10242 (33%)]	Loss: 0.206224
| Global Round : 2 | Local Epoch : 4 | [3500/10242 (34%)]	Loss: 0.071960
| Global Round : 2 | Local Epoch : 4 | [3600/10242 (35%)]	Loss: 0.427617
| Global Round : 2 | Local Epoch : 4 | [3700/10242 (36%)]	Loss: 0.833847
| Global Round : 2 | Local Epoch : 4 | [3800/10242 (37%)]	Loss: 0.117566
| Global Round : 2 | Local Epoch : 4 | [3900/10242 (38%)]	Loss: 0.159972
| Global Round : 2 | Local Epoch : 4 | [4000/10242 (39%)]	Loss: 0.397333
| Global Round : 2 | Local Epoch : 4 | [4100/10242 (40%)]	Loss: 0.148124
| Global Round : 2 | Local Epoch : 4 | [4200/10242 (41%)]	Loss: 0.013284
| Global Round : 2 | Local Epoch : 4 | [4300/10242 (42%)]	Loss: 0.281754
| Global Round : 2 | Local Epoch : 4 | [4400/10242 (43%)]	Loss: 0.104344
| Global Round : 2 | Local Epoch : 4 | [4500/10242 (44%)]	Loss: 0.135737
| Global Round : 2 | Local Epoch : 4 | [4600/10242 (45%)]	Loss: 0.275328
| Global Round : 2 | Local Epoch : 4 | [4700/10242 (46%)]	Loss: 0.078496
| Global Round : 2 | Local Epoch : 4 | [4800/10242 (47%)]	Loss: 0.486183
| Global Round : 2 | Local Epoch : 4 | [4900/10242 (48%)]	Loss: 0.066612
| Global Round : 2 | Local Epoch : 4 | [5000/10242 (49%)]	Loss: 0.007759
| Global Round : 2 | Local Epoch : 4 | [5100/10242 (50%)]	Loss: 0.074299
| Global Round : 2 | Local Epoch : 4 | [5200/10242 (51%)]	Loss: 0.048303
| Global Round : 2 | Local Epoch : 4 | [5300/10242 (52%)]	Loss: 0.140088
| Global Round : 2 | Local Epoch : 4 | [5400/10242 (53%)]	Loss: 0.352846
| Global Round : 2 | Local Epoch : 4 | [5500/10242 (54%)]	Loss: 0.200572
| Global Round : 2 | Local Epoch : 4 | [5600/10242 (55%)]	Loss: 0.070164
| Global Round : 2 | Local Epoch : 4 | [5700/10242 (56%)]	Loss: 0.379272
| Global Round : 2 | Local Epoch : 4 | [5800/10242 (57%)]	Loss: 0.277802
| Global Round : 2 | Local Epoch : 4 | [5900/10242 (58%)]	Loss: 0.426207
| Global Round : 2 | Local Epoch : 4 | [6000/10242 (59%)]	Loss: 0.333578
| Global Round : 2 | Local Epoch : 4 | [6100/10242 (60%)]	Loss: 0.121804
| Global Round : 2 | Local Epoch : 4 | [6200/10242 (60%)]	Loss: 0.070441
| Global Round : 2 | Local Epoch : 4 | [6300/10242 (61%)]	Loss: 0.321814
| Global Round : 2 | Local Epoch : 4 | [6400/10242 (62%)]	Loss: 0.074967
| Global Round : 2 | Local Epoch : 4 | [6500/10242 (63%)]	Loss: 0.220395
| Global Round : 2 | Local Epoch : 4 | [6600/10242 (64%)]	Loss: 0.173551
| Global Round : 2 | Local Epoch : 4 | [6700/10242 (65%)]	Loss: 0.282010
| Global Round : 2 | Local Epoch : 4 | [6800/10242 (66%)]	Loss: 0.058122
| Global Round : 2 | Local Epoch : 4 | [6900/10242 (67%)]	Loss: 0.150047
| Global Round : 2 | Local Epoch : 4 | [7000/10242 (68%)]	Loss: 0.119687
| Global Round : 2 | Local Epoch : 4 | [7100/10242 (69%)]	Loss: 0.026028
| Global Round : 2 | Local Epoch : 4 | [7200/10242 (70%)]	Loss: 0.079774
| Global Round : 2 | Local Epoch : 4 | [7300/10242 (71%)]	Loss: 0.056433
| Global Round : 2 | Local Epoch : 4 | [7400/10242 (72%)]	Loss: 0.182287
| Global Round : 2 | Local Epoch : 4 | [7500/10242 (73%)]	Loss: 0.017744
| Global Round : 2 | Local Epoch : 4 | [7600/10242 (74%)]	Loss: 0.184359
| Global Round : 2 | Local Epoch : 4 | [7700/10242 (75%)]	Loss: 0.045015
| Global Round : 2 | Local Epoch : 4 | [7800/10242 (76%)]	Loss: 0.132360
| Global Round : 2 | Local Epoch : 4 | [7900/10242 (77%)]	Loss: 0.292962
| Global Round : 2 | Local Epoch : 4 | [8000/10242 (78%)]	Loss: 0.138775
| Global Round : 2 | Local Epoch : 4 | [8100/10242 (79%)]	Loss: 0.134484
| Global Round : 2 | Local Epoch : 4 | [8200/10242 (80%)]	Loss: 0.037763
| Global Round : 2 | Local Epoch : 4 | [8300/10242 (81%)]	Loss: 0.587495
| Global Round : 2 | Local Epoch : 4 | [8400/10242 (82%)]	Loss: 0.219370
| Global Round : 2 | Local Epoch : 4 | [8500/10242 (83%)]	Loss: 0.030953
| Global Round : 2 | Local Epoch : 4 | [8600/10242 (84%)]	Loss: 0.256238
| Global Round : 2 | Local Epoch : 4 | [8700/10242 (85%)]	Loss: 0.040154
| Global Round : 2 | Local Epoch : 4 | [8800/10242 (86%)]	Loss: 0.505829
| Global Round : 2 | Local Epoch : 4 | [8900/10242 (87%)]	Loss: 0.142845
| Global Round : 2 | Local Epoch : 4 | [9000/10242 (88%)]	Loss: 0.090696
| Global Round : 2 | Local Epoch : 4 | [9100/10242 (89%)]	Loss: 0.248203
| Global Round : 2 | Local Epoch : 4 | [9200/10242 (90%)]	Loss: 0.184533
| Global Round : 2 | Local Epoch : 4 | [9300/10242 (91%)]	Loss: 0.034800
| Global Round : 2 | Local Epoch : 4 | [9400/10242 (92%)]	Loss: 0.083846
| Global Round : 2 | Local Epoch : 4 | [9500/10242 (93%)]	Loss: 0.019310
| Global Round : 2 | Local Epoch : 4 | [9600/10242 (94%)]	Loss: 0.418948
| Global Round : 2 | Local Epoch : 4 | [9700/10242 (95%)]	Loss: 0.003993
| Global Round : 2 | Local Epoch : 4 | [9800/10242 (96%)]	Loss: 0.253201
| Global Round : 2 | Local Epoch : 4 | [9900/10242 (97%)]	Loss: 0.123783
| Global Round : 2 | Local Epoch : 4 | [10000/10242 (98%)]	Loss: 0.227612
| Global Round : 2 | Local Epoch : 4 | [10100/10242 (99%)]	Loss: 0.150743
| Global Round : 2 | Local Epoch : 4 | [10200/10242 (100%)]	Loss: 0.127832
----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.87      0.88        63
         DME       0.88      0.89      0.89        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.87      0.91        61
         DME       0.89      0.97      0.93        67

    accuracy                           0.92       128
   macro avg       0.93      0.92      0.92       128
weighted avg       0.93      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.91        72
         DME       0.84      0.95      0.89        56

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.86      0.90        65
         DME       0.87      0.94      0.90        63

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.89      0.90        61
         DME       0.90      0.93      0.91        67

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.89      0.91        65
         DME       0.89      0.94      0.91        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.90      0.91        68
         DME       0.89      0.92      0.90        60

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.94      0.93        70
         DME       0.93      0.90      0.91        58

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.90        71
         DME       0.84      0.95      0.89        57

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.89      0.91        62
         DME       0.90      0.94      0.92        66

    accuracy                           0.91       128
   macro avg       0.92      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
         DME       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.87      0.88        63
      DRUSEN       0.88      0.89      0.89        65

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.87      0.91        61
      DRUSEN       0.89      0.97      0.93        67

    accuracy                           0.92       128
   macro avg       0.93      0.92      0.92       128
weighted avg       0.93      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.91        72
      DRUSEN       0.84      0.95      0.89        56

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.86      0.90        65
      DRUSEN       0.87      0.94      0.90        63

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.89      0.90        61
      DRUSEN       0.90      0.93      0.91        67

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.89      0.91        65
      DRUSEN       0.89      0.94      0.91        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.90      0.91        68
      DRUSEN       0.89      0.92      0.90        60

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.94      0.93        70
      DRUSEN       0.93      0.90      0.91        58

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.90        71
      DRUSEN       0.84      0.95      0.89        57

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.89      0.91        62
      DRUSEN       0.90      0.94      0.92        66

    accuracy                           0.91       128
   macro avg       0.92      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
      DRUSEN       0.00      0.00      0.00         0

   micro avg       1.00      1.00      1.00         1
   macro avg       0.50      0.50      0.50         1
weighted avg       1.00      1.00      1.00         1

----------------------

Training accuracy [0.8711943793911007, 0.88125, 0.9063231850117096]
########################

Client 1 Test Statistics

==========================

For client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.96      0.95        74
         DME       0.94      0.91      0.92        54

    accuracy                           0.94       128
   macro avg       0.94      0.93      0.94       128
weighted avg       0.94      0.94      0.94       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.89      0.91        72
         DME       0.87      0.93      0.90        56

    accuracy                           0.91       128
   macro avg       0.90      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.85      0.88        67
         DME       0.85      0.92      0.88        61

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.92      0.93        71
         DME       0.90      0.93      0.91        57

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.88      0.89        66
         DME       0.88      0.90      0.89        62

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.86      0.90        72
         DME       0.84      0.93      0.88        56

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.88      0.90        67
         DME       0.88      0.92      0.90        61

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.87      0.89        77
         DME       0.82      0.88      0.85        51

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.90      0.92        59
         DME       0.92      0.96      0.94        69

    accuracy                           0.93       128
   macro avg       0.93      0.93      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.81      0.87        69
         DME       0.81      0.95      0.87        59

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.87       128
weighted avg       0.89      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.89      0.89        62
         DME       0.90      0.91      0.90        66

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.90      0.91        67
         DME       0.89      0.92      0.90        61

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.86      0.86        66
         DME       0.85      0.85      0.85        62

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.86      0.87        74
         DME       0.82      0.83      0.83        54

    accuracy                           0.85       128
   macro avg       0.85      0.85      0.85       128
weighted avg       0.85      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.86      0.88        71
         DME       0.84      0.89      0.86        57

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.88      0.89        65
         DME       0.88      0.90      0.89        63

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.91      0.93        70
         DME       0.90      0.93      0.92        58

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.91      0.93        68
         DME       0.90      0.93      0.92        60

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.89      0.88        61
         DME       0.89      0.88      0.89        67

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.91      0.91        65
         DME       0.90      0.90      0.90        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.89      0.88        56
         DME       0.92      0.90      0.91        72

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.89      0.92        79
         DME       0.83      0.92      0.87        49

    accuracy                           0.90       128
   macro avg       0.89      0.90      0.89       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.89      0.90        65
         DME       0.89      0.90      0.90        63

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.90      0.91        70
         DME       0.88      0.90      0.89        58

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.90      0.90        60
         DME       0.91      0.91      0.91        65

    accuracy                           0.90       125
   macro avg       0.90      0.90      0.90       125
weighted avg       0.90      0.90      0.90       125

----------------------

==========================

Testing client 1 on client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.86      0.91        80
      DRUSEN       0.80      0.94      0.87        48

    accuracy                           0.89       128
   macro avg       0.88      0.90      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.74      0.81        65
      DRUSEN       0.77      0.90      0.83        63

    accuracy                           0.82       128
   macro avg       0.83      0.82      0.82       128
weighted avg       0.83      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.73      0.82        70
      DRUSEN       0.74      0.95      0.83        58

    accuracy                           0.83       128
   macro avg       0.84      0.84      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.79      0.88        81
      DRUSEN       0.73      0.98      0.84        47

    accuracy                           0.86       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.77      0.83        71
      DRUSEN       0.76      0.89      0.82        57

    accuracy                           0.83       128
   macro avg       0.83      0.83      0.83       128
weighted avg       0.84      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.81      0.88        80
      DRUSEN       0.75      0.96      0.84        48

    accuracy                           0.87       128
   macro avg       0.86      0.89      0.86       128
weighted avg       0.89      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.78      0.85        74
      DRUSEN       0.75      0.91      0.82        54

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.78      0.87        76
      DRUSEN       0.75      0.98      0.85        52

    accuracy                           0.86       128
   macro avg       0.87      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.85      0.90        80
      DRUSEN       0.79      0.94      0.86        48

    accuracy                           0.88       128
   macro avg       0.87      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.79      0.88        81
      DRUSEN       0.73      0.98      0.84        47

    accuracy                           0.86       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.80      0.88        80
      DRUSEN       0.75      0.98      0.85        48

    accuracy                           0.87       128
   macro avg       0.87      0.89      0.86       128
weighted avg       0.90      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.83      0.87        71
      DRUSEN       0.81      0.91      0.86        57

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.86      0.90        76
      DRUSEN       0.81      0.92      0.86        52

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.75      0.83        71
      DRUSEN       0.75      0.95      0.84        57

    accuracy                           0.84       128
   macro avg       0.85      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.82      0.87        72
      DRUSEN       0.80      0.93      0.86        56

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.82      0.88        78
      DRUSEN       0.77      0.94      0.85        50

    accuracy                           0.87       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.91        73
      DRUSEN       0.84      0.95      0.89        55

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.83      0.91        70
      DRUSEN       0.83      1.00      0.91        58

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.83      0.90        76
      DRUSEN       0.80      0.98      0.88        52

    accuracy                           0.89       128
   macro avg       0.89      0.90      0.89       128
weighted avg       0.91      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.87      0.91        82
      DRUSEN       0.80      0.93      0.86        46

    accuracy                           0.89       128
   macro avg       0.88      0.90      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.76      0.86        79
      DRUSEN       0.72      1.00      0.84        49

    accuracy                           0.85       128
   macro avg       0.86      0.88      0.85       128
weighted avg       0.89      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.77      0.86        81
      DRUSEN       0.70      0.96      0.81        47

    accuracy                           0.84       128
   macro avg       0.84      0.86      0.83       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.77      0.86        73
      DRUSEN       0.76      0.98      0.86        55

    accuracy                           0.86       128
   macro avg       0.87      0.87      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.83      0.86        77
      DRUSEN       0.77      0.86      0.81        51

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.80      0.88        76
      DRUSEN       0.77      0.98      0.86        52

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.87       128
weighted avg       0.90      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
      DRUSEN       1.00      1.00      1.00         2

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

----------------------

########################

Client 2 Test Statistics

==========================

For client 2 original classes :  ['NORMAL', 'DRUSEN']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.86      0.91        80
      DRUSEN       0.80      0.94      0.87        48

    accuracy                           0.89       128
   macro avg       0.88      0.90      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.89      0.74      0.81        65
      DRUSEN       0.77      0.90      0.83        63

    accuracy                           0.82       128
   macro avg       0.83      0.82      0.82       128
weighted avg       0.83      0.82      0.82       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.73      0.82        70
      DRUSEN       0.74      0.95      0.83        58

    accuracy                           0.83       128
   macro avg       0.84      0.84      0.83       128
weighted avg       0.85      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.79      0.88        81
      DRUSEN       0.73      0.98      0.84        47

    accuracy                           0.86       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.77      0.83        71
      DRUSEN       0.76      0.89      0.82        57

    accuracy                           0.83       128
   macro avg       0.83      0.83      0.83       128
weighted avg       0.84      0.83      0.83       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.81      0.88        80
      DRUSEN       0.75      0.96      0.84        48

    accuracy                           0.87       128
   macro avg       0.86      0.89      0.86       128
weighted avg       0.89      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.78      0.85        74
      DRUSEN       0.75      0.91      0.82        54

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.78      0.87        76
      DRUSEN       0.75      0.98      0.85        52

    accuracy                           0.86       128
   macro avg       0.87      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.85      0.90        80
      DRUSEN       0.79      0.94      0.86        48

    accuracy                           0.88       128
   macro avg       0.87      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.79      0.88        81
      DRUSEN       0.73      0.98      0.84        47

    accuracy                           0.86       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.80      0.88        80
      DRUSEN       0.75      0.98      0.85        48

    accuracy                           0.87       128
   macro avg       0.87      0.89      0.86       128
weighted avg       0.90      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.83      0.87        71
      DRUSEN       0.81      0.91      0.86        57

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.87      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.86      0.90        76
      DRUSEN       0.81      0.92      0.86        52

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.75      0.83        71
      DRUSEN       0.75      0.95      0.84        57

    accuracy                           0.84       128
   macro avg       0.85      0.85      0.84       128
weighted avg       0.86      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.82      0.87        72
      DRUSEN       0.80      0.93      0.86        56

    accuracy                           0.87       128
   macro avg       0.87      0.87      0.87       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.82      0.88        78
      DRUSEN       0.77      0.94      0.85        50

    accuracy                           0.87       128
   macro avg       0.86      0.88      0.86       128
weighted avg       0.88      0.87      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.86      0.91        73
      DRUSEN       0.84      0.95      0.89        55

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.83      0.91        70
      DRUSEN       0.83      1.00      0.91        58

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.92      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.83      0.90        76
      DRUSEN       0.80      0.98      0.88        52

    accuracy                           0.89       128
   macro avg       0.89      0.90      0.89       128
weighted avg       0.91      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.96      0.87      0.91        82
      DRUSEN       0.80      0.93      0.86        46

    accuracy                           0.89       128
   macro avg       0.88      0.90      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      0.76      0.86        79
      DRUSEN       0.72      1.00      0.84        49

    accuracy                           0.85       128
   macro avg       0.86      0.88      0.85       128
weighted avg       0.89      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.97      0.77      0.86        81
      DRUSEN       0.70      0.96      0.81        47

    accuracy                           0.84       128
   macro avg       0.84      0.86      0.83       128
weighted avg       0.87      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.77      0.86        73
      DRUSEN       0.76      0.98      0.86        55

    accuracy                           0.86       128
   macro avg       0.87      0.87      0.86       128
weighted avg       0.89      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.83      0.86        77
      DRUSEN       0.77      0.86      0.81        51

    accuracy                           0.84       128
   macro avg       0.84      0.85      0.84       128
weighted avg       0.85      0.84      0.84       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.98      0.80      0.88        76
      DRUSEN       0.77      0.98      0.86        52

    accuracy                           0.88       128
   macro avg       0.88      0.89      0.87       128
weighted avg       0.90      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       1.00      1.00      1.00         1
      DRUSEN       1.00      1.00      1.00         2

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

----------------------

==========================

Testing client 2 on client 1 original classes :  ['NORMAL', 'DME']
----------------------

              precision    recall  f1-score   support

      NORMAL       0.93      0.96      0.95        74
         DME       0.94      0.91      0.92        54

    accuracy                           0.94       128
   macro avg       0.94      0.93      0.94       128
weighted avg       0.94      0.94      0.94       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.89      0.91        72
         DME       0.87      0.93      0.90        56

    accuracy                           0.91       128
   macro avg       0.90      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.85      0.88        67
         DME       0.85      0.92      0.88        61

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.89      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.92      0.93        71
         DME       0.90      0.93      0.91        57

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.88      0.89        66
         DME       0.88      0.90      0.89        62

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.86      0.90        72
         DME       0.84      0.93      0.88        56

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.90      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.88      0.90        67
         DME       0.88      0.92      0.90        61

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.87      0.89        77
         DME       0.82      0.88      0.85        51

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.90      0.92        59
         DME       0.92      0.96      0.94        69

    accuracy                           0.93       128
   macro avg       0.93      0.93      0.93       128
weighted avg       0.93      0.93      0.93       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.81      0.87        69
         DME       0.81      0.95      0.87        59

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.87       128
weighted avg       0.89      0.88      0.87       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.89      0.89        62
         DME       0.90      0.91      0.90        66

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.92      0.90      0.91        67
         DME       0.89      0.92      0.90        61

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.86      0.86      0.86        66
         DME       0.85      0.85      0.85        62

    accuracy                           0.86       128
   macro avg       0.86      0.86      0.86       128
weighted avg       0.86      0.86      0.86       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.86      0.87        74
         DME       0.82      0.83      0.83        54

    accuracy                           0.85       128
   macro avg       0.85      0.85      0.85       128
weighted avg       0.85      0.85      0.85       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.86      0.88        71
         DME       0.84      0.89      0.86        57

    accuracy                           0.88       128
   macro avg       0.87      0.88      0.87       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.88      0.89        65
         DME       0.88      0.90      0.89        63

    accuracy                           0.89       128
   macro avg       0.89      0.89      0.89       128
weighted avg       0.89      0.89      0.89       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.91      0.93        70
         DME       0.90      0.93      0.92        58

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.94      0.91      0.93        68
         DME       0.90      0.93      0.92        60

    accuracy                           0.92       128
   macro avg       0.92      0.92      0.92       128
weighted avg       0.92      0.92      0.92       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.87      0.89      0.88        61
         DME       0.89      0.88      0.89        67

    accuracy                           0.88       128
   macro avg       0.88      0.88      0.88       128
weighted avg       0.88      0.88      0.88       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.91      0.91        65
         DME       0.90      0.90      0.90        63

    accuracy                           0.91       128
   macro avg       0.91      0.91      0.91       128
weighted avg       0.91      0.91      0.91       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.88      0.89      0.88        56
         DME       0.92      0.90      0.91        72

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.95      0.89      0.92        79
         DME       0.83      0.92      0.87        49

    accuracy                           0.90       128
   macro avg       0.89      0.90      0.89       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.89      0.90        65
         DME       0.89      0.90      0.90        63

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.91      0.90      0.91        70
         DME       0.88      0.90      0.89        58

    accuracy                           0.90       128
   macro avg       0.90      0.90      0.90       128
weighted avg       0.90      0.90      0.90       128

----------------------

----------------------

              precision    recall  f1-score   support

      NORMAL       0.90      0.90      0.90        60
         DME       0.91      0.91      0.91        65

    accuracy                           0.90       125
   macro avg       0.90      0.90      0.90       125
weighted avg       0.90      0.90      0.90       125

----------------------

Test accuracy on client 1 0.8967782295902409
Test accuracy on client 2 0.862940992819232
========================================

========================================

Test on original client distribution for client 1 : 89.68%
Test on client 2 distribution for client 1 : 86.29%
Test on original client distribution for client 2 : 86.29%
Test on client 1 distribution for client 2 : 89.68%
